{
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/indunil-19/CS4532-Concurrent-Programming-Take-home-Labs/blob/master/hate_speech_xlmr_adapter_based.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training Single Task Adapters\n",
        "For Bert SinBert and XLM-R Models"
      ],
      "metadata": {
        "id": "eoL8-pXx9z7c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "print(\"GPU Device name\")\n",
        "torch.cuda.get_device_name(0)"
      ],
      "metadata": {
        "id": "KSLx_mnliOvH",
        "outputId": "681b0627-75f6-4eb5-dd62-cccf2ddf63fb",
        "execution": {
          "iopub.status.busy": "2023-06-12T05:17:54.112412Z",
          "iopub.execute_input": "2023-06-12T05:17:54.112986Z",
          "iopub.status.idle": "2023-06-12T05:17:57.771877Z",
          "shell.execute_reply.started": "2023-06-12T05:17:54.112951Z",
          "shell.execute_reply": "2023-06-12T05:17:57.770812Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU Device name\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla T4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uEtgD8WdnRJg",
        "outputId": "1518faca-d479-4a63-9ae3-f42dcf000949"
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **Parameters**"
      ],
      "metadata": {
        "id": "CCdvw5JNlygg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "technique = \"Hate-Speech\"\n",
        "experiment_no = \"1\"\n",
        "oversample_dataset = True\n",
        "over_sampling_technique = \"ROS\"\n",
        "sampling_strategy = \"1:0.25:0.25\"\n",
        "validation_size = (1/9)\n",
        "test_size = 0.1\n",
        "split_random_state = 42\n",
        "training_seed = 42 #@param [ 8, 42, 77]\n",
        "NO_OUTPUT_LAYERS = 4\n",
        "id2label={ 0: \"Not offensive\", 1: \"Hate-Inducin\", 2: \"Abusive\"}\n",
        "tag_set = [\"Not offensive\", \"Hate-Inducing\", \"Abusive\"]\n",
        "script=\"Char-Script-1.0\"\n",
        "\n",
        "\n",
        "load_adapter = False #@param {type:\"boolean\"}\n",
        "unfreeze_model = False #@param {type:\"boolean\"}\n",
        "save_adapter = False #@param {type:\"boolean\"}\n",
        "lang_adapter_setting = \"none\" #@param [\"none\", \"stack\", \"parallel\"]\n",
        "adapter_config = \"houlsby\" #@param [\"houlsby\", \"pfeiffer\"]"
      ],
      "metadata": {
        "id": "6LjxhVXklun6",
        "execution": {
          "iopub.status.busy": "2023-06-12T05:17:57.776948Z",
          "iopub.execute_input": "2023-06-12T05:17:57.779660Z",
          "iopub.status.idle": "2023-06-12T05:17:57.789859Z",
          "shell.execute_reply.started": "2023-06-12T05:17:57.779621Z",
          "shell.execute_reply": "2023-06-12T05:17:57.788902Z"
        },
        "trusted": true
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MAX_LEN = 128\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 5e-4\n",
        "EPOCHS = 20"
      ],
      "metadata": {
        "id": "Z5zzz0_5IxVc",
        "execution": {
          "iopub.status.busy": "2023-06-12T05:17:57.794821Z",
          "iopub.execute_input": "2023-06-12T05:17:57.797499Z",
          "iopub.status.idle": "2023-06-12T05:17:57.804477Z",
          "shell.execute_reply.started": "2023-06-12T05:17:57.797465Z",
          "shell.execute_reply": "2023-06-12T05:17:57.803402Z"
        },
        "trusted": true
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# technique=\"hate\"\n",
        "pretrained_adapter_path = \"/content/drive/Shareddrives/Lingua/Final/\"+technique #+ \"_\" + str(random_state)"
      ],
      "metadata": {
        "id": "KanOOHjzWI7b",
        "execution": {
          "iopub.status.busy": "2023-06-12T05:17:57.810836Z",
          "iopub.execute_input": "2023-06-12T05:17:57.813454Z",
          "iopub.status.idle": "2023-06-12T05:17:57.819791Z",
          "shell.execute_reply.started": "2023-06-12T05:17:57.813422Z",
          "shell.execute_reply": "2023-06-12T05:17:57.818706Z"
        },
        "trusted": true
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Installation"
      ],
      "metadata": {
        "id": "3L9gYpCV28OA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U adapter-transformers==3.1.0\n",
        "!pip install datasets\n",
        "!pip install sentencepiece"
      ],
      "metadata": {
        "id": "qL3Sq1HQynCq",
        "outputId": "d17e2dd5-c7cf-4d5d-e956-548f23e4f39f",
        "execution": {
          "iopub.status.busy": "2023-06-12T05:17:57.821554Z",
          "iopub.execute_input": "2023-06-12T05:17:57.822946Z",
          "iopub.status.idle": "2023-06-12T05:18:39.343169Z",
          "shell.execute_reply.started": "2023-06-12T05:17:57.822910Z",
          "shell.execute_reply": "2023-06-12T05:18:39.341908Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: adapter-transformers==3.1.0 in /usr/local/lib/python3.10/dist-packages (3.1.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from adapter-transformers==3.1.0) (3.12.2)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from adapter-transformers==3.1.0) (0.16.4)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from adapter-transformers==3.1.0) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from adapter-transformers==3.1.0) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from adapter-transformers==3.1.0) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from adapter-transformers==3.1.0) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from adapter-transformers==3.1.0) (2.27.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from adapter-transformers==3.1.0) (0.12.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from adapter-transformers==3.1.0) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->adapter-transformers==3.1.0) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.1.0->adapter-transformers==3.1.0) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->adapter-transformers==3.1.0) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->adapter-transformers==3.1.0) (2023.7.22)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->adapter-transformers==3.1.0) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->adapter-transformers==3.1.0) (3.4)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.14.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets) (1.22.4)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (4.65.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.3.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.5)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.16.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.0.12)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (3.12.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets) (4.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (2023.7.22)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (0.1.99)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dependencies"
      ],
      "metadata": {
        "id": "LUHpDE_Gtyen"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mUcFdH0HIxVe"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "import time\n",
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import classification_report\n",
        "from google.colab import drive\n",
        "import io\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from transformers import AutoAdapterModel ,AutoTokenizer, AdapterConfig,AutoConfig, AutoModelWithHeads, TrainingArguments, AdapterTrainer, EvalPrediction, AdamW, get_scheduler, TextClassificationPipeline, EarlyStoppingCallback, Trainer,set_seed\n",
        "from transformers import  AdamW, get_linear_schedule_with_warmup,set_seed\n",
        "from transformers.adapters.composition import Fuse, Stack, Parallel\n",
        "from datasets import load_metric\n",
        "from collections import Counter\n",
        "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN, BorderlineSMOTE\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n"
      ],
      "metadata": {
        "id": "xJZ6z8bJl25l",
        "execution": {
          "iopub.status.busy": "2023-06-12T05:18:39.345281Z",
          "iopub.execute_input": "2023-06-12T05:18:39.345675Z",
          "iopub.status.idle": "2023-06-12T05:18:51.037244Z",
          "shell.execute_reply.started": "2023-06-12T05:18:39.345637Z",
          "shell.execute_reply": "2023-06-12T05:18:51.036320Z"
        },
        "trusted": true
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Preprocessing"
      ],
      "metadata": {
        "id": "EzrDM6Ua-jo_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def apply_oversampling(x, y):\n",
        "  (unique, counts) = np.unique(y, axis=0, return_counts=True)\n",
        "  print(\"Class Distribution Without Oversampling\", counts)\n",
        "\n",
        "  # define oversampling strategy\n",
        "  if (over_sampling_technique == \"\"):\n",
        "    return x, y\n",
        "  elif (over_sampling_technique == \"ROS\"):\n",
        "    if (technique==\"Humor\"):\n",
        "      oversample = RandomOverSampler(sampling_strategy = float(sampling_strategy))\n",
        "    elif (technique==\"Hate-Speech\"):\n",
        "      sampling_ratio = sampling_strategy.split(\":\")\n",
        "      oversample = RandomOverSampler(sampling_strategy = {\n",
        "          0:int(counts[0]*float(sampling_ratio[0])),\n",
        "          1:int(counts[0]*float(sampling_ratio[1])),\n",
        "          2:int(counts[0]*float(sampling_ratio[2]))\n",
        "          })\n",
        "    elif (technique==\"Sentiment\"):\n",
        "      sampling_ratio = sampling_strategy.split(\":\")\n",
        "      oversample = RandomOverSampler(sampling_strategy = {\n",
        "          0:int(counts[1]*float(sampling_ratio[0])),\n",
        "          1:int(counts[1]*float(sampling_ratio[1])),\n",
        "          2:int(counts[1]*float(sampling_ratio[2])),\n",
        "          3:int(counts[1]*float(sampling_ratio[3]))\n",
        "          })\n",
        "  elif (over_sampling_technique == \"ADASYN\"):\n",
        "    oversample = ADASYN(sampling_strategy=\"minority\")\n",
        "  elif (over_sampling_technique == \"SMOTE\"):\n",
        "    oversample = SMOTE()\n",
        "  elif (over_sampling_technique == \"BorderlineSMOTE\"):\n",
        "    oversample = BorderlineSMOTE()\n",
        "\n",
        "  # fit and apply the transform\n",
        "  X_over, y_over = oversample.fit_resample(x, y)\n",
        "\n",
        "  (unique, counts) = np.unique(y_over, axis=0, return_counts=True)\n",
        "  print(\"Class Distribution After Oversampling\", counts)\n",
        "\n",
        "  return X_over, y_over"
      ],
      "metadata": {
        "id": "BB8pw1RDuDaA",
        "execution": {
          "iopub.status.busy": "2023-06-12T05:18:51.038788Z",
          "iopub.execute_input": "2023-06-12T05:18:51.039692Z",
          "iopub.status.idle": "2023-06-12T05:18:51.051653Z",
          "shell.execute_reply.started": "2023-06-12T05:18:51.039655Z",
          "shell.execute_reply": "2023-06-12T05:18:51.050779Z"
        },
        "trusted": true
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"/content/drive/Shareddrives/Lingua/Sinhala-English CMCS Dataset/annotated-script(all).csv\"\n",
        "model_save_path = \"/kaggle/working/\"+technique+\"/\"+experiment_no"
      ],
      "metadata": {
        "id": "0MUpioPlmvMh",
        "execution": {
          "iopub.status.busy": "2023-06-12T05:18:51.056329Z",
          "iopub.execute_input": "2023-06-12T05:18:51.058159Z",
          "iopub.status.idle": "2023-06-12T05:18:51.258329Z",
          "shell.execute_reply.started": "2023-06-12T05:18:51.058117Z",
          "shell.execute_reply": "2023-06-12T05:18:51.257255Z"
        },
        "trusted": true
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(dataset_path)\n",
        "df = df[['Sentence', technique, script]]\n",
        "df.columns = ['Sentence', 'Label', script]\n",
        "\n",
        "df['Label'], uniq = pd.factorize(df['Label'])\n",
        "\n",
        "X, y = df[['Sentence', script]], df[['Label']]\n",
        "stratifying_col = y[\"Label\"]\n",
        "X_rem, X_test, y_rem, y_test = train_test_split(X, y, test_size=test_size, stratify=stratifying_col, random_state=split_random_state)\n",
        "stratifying_col = y_rem[\"Label\"]\n",
        "X_train, X_validation, y_train, y_validation = train_test_split(X_rem, y_rem, test_size=validation_size, stratify=stratifying_col, random_state=split_random_state)"
      ],
      "metadata": {
        "id": "yq5AMmjelqlj",
        "execution": {
          "iopub.status.busy": "2023-06-12T05:18:51.259689Z",
          "iopub.execute_input": "2023-06-12T05:18:51.260749Z",
          "iopub.status.idle": "2023-06-12T05:18:51.387836Z",
          "shell.execute_reply.started": "2023-06-12T05:18:51.260698Z",
          "shell.execute_reply": "2023-06-12T05:18:51.386928Z"
        },
        "trusted": true
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del df, X, y, stratifying_col, X_rem, y_rem"
      ],
      "metadata": {
        "id": "Ppy0Sj5NIxVg",
        "execution": {
          "iopub.status.busy": "2023-06-12T05:18:51.392170Z",
          "iopub.execute_input": "2023-06-12T05:18:51.392455Z",
          "iopub.status.idle": "2023-06-12T05:18:51.397228Z",
          "shell.execute_reply.started": "2023-06-12T05:18:51.392431Z",
          "shell.execute_reply": "2023-06-12T05:18:51.396150Z"
        },
        "trusted": true
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "uniq"
      ],
      "metadata": {
        "id": "oHELisZ0ufPM",
        "outputId": "67bf6bb3-8243-4310-c4a9-2b2e3585e00b",
        "execution": {
          "iopub.status.busy": "2023-06-12T05:18:51.398556Z",
          "iopub.execute_input": "2023-06-12T05:18:51.399147Z",
          "iopub.status.idle": "2023-06-12T05:18:51.411611Z",
          "shell.execute_reply.started": "2023-06-12T05:18:51.399114Z",
          "shell.execute_reply": "2023-06-12T05:18:51.410683Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Not offensive', 'Hate-Inducing', 'Abusive'], dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"X_train : Rows =\", X_train.shape[0], \", Columns = \", X_train.shape[1])\n",
        "print(\"y_train : Rows =\", y_train.shape[0], \", Columns = \", y_train.shape[1])\n",
        "print(\"X_validation : Rows =\", X_validation.shape[0], \", Columns = \", X_validation.shape[1])\n",
        "print(\"y_validation : Rows =\", y_validation.shape[0], \", Columns = \", y_validation.shape[1])\n",
        "print(\"X_test : Rows =\", X_test.shape[0], \", Columns = \", X_test.shape[1])\n",
        "print(\"y_test : Rows =\", y_test.shape[0], \", Columns = \", y_test.shape[1])"
      ],
      "metadata": {
        "id": "dkRs6oJvIxVh",
        "outputId": "31b4dac8-e4ef-4035-f039-5fa08ebf8e65",
        "execution": {
          "iopub.status.busy": "2023-06-12T05:18:51.413132Z",
          "iopub.execute_input": "2023-06-12T05:18:51.413499Z",
          "iopub.status.idle": "2023-06-12T05:18:51.423507Z",
          "shell.execute_reply.started": "2023-06-12T05:18:51.413465Z",
          "shell.execute_reply": "2023-06-12T05:18:51.422518Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train : Rows = 10814 , Columns =  2\n",
            "y_train : Rows = 10814 , Columns =  1\n",
            "X_validation : Rows = 1352 , Columns =  2\n",
            "y_validation : Rows = 1352 , Columns =  1\n",
            "X_test : Rows = 1352 , Columns =  2\n",
            "y_test : Rows = 1352 , Columns =  1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Labels :\",[\"Not offensive\", \"Hate-Inducing\", \"Abusive\"])\n",
        "print(\"Train :\", y_train.groupby('Label').size().tolist())\n",
        "print(\"Validation :\", y_validation.groupby('Label').size().tolist())\n",
        "print(\"Test :\", y_test.groupby('Label').size().tolist())"
      ],
      "metadata": {
        "id": "UaUlvhRwIxVh",
        "outputId": "3b71cf4e-babe-46d9-ebec-6c3cc7af6f2c",
        "execution": {
          "iopub.status.busy": "2023-06-12T05:18:51.424835Z",
          "iopub.execute_input": "2023-06-12T05:18:51.425385Z",
          "iopub.status.idle": "2023-06-12T05:18:51.443127Z",
          "shell.execute_reply.started": "2023-06-12T05:18:51.425324Z",
          "shell.execute_reply": "2023-06-12T05:18:51.441765Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Labels : ['Not offensive', 'Hate-Inducing', 'Abusive']\n",
            "Train : [9810, 278, 726]\n",
            "Validation : [1226, 35, 91]\n",
            "Test : [1226, 35, 91]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def  oversampling(X_train,y_train):\n",
        "  X_train = np.array(X_train).reshape(-1, 1)\n",
        "  X_train, y_train = apply_oversampling(X_train, y_train)\n",
        "  X_train = [x[0] for x in X_train.tolist()]\n",
        "  return X_train,y_train"
      ],
      "metadata": {
        "id": "7tCiiAeuIxVi",
        "execution": {
          "iopub.status.busy": "2023-06-12T05:18:51.445242Z",
          "iopub.execute_input": "2023-06-12T05:18:51.445907Z",
          "iopub.status.idle": "2023-06-12T05:18:51.451797Z",
          "shell.execute_reply.started": "2023-06-12T05:18:51.445876Z",
          "shell.execute_reply": "2023-06-12T05:18:51.450778Z"
        },
        "trusted": true
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Preprocess Data**"
      ],
      "metadata": {
        "id": "Xw-aKg9RIxVi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(training_seed)"
      ],
      "metadata": {
        "id": "T_2iifBVIxVi",
        "execution": {
          "iopub.status.busy": "2023-06-12T05:18:51.453261Z",
          "iopub.execute_input": "2023-06-12T05:18:51.453626Z",
          "iopub.status.idle": "2023-06-12T05:18:51.465558Z",
          "shell.execute_reply.started": "2023-06-12T05:18:51.453595Z",
          "shell.execute_reply": "2023-06-12T05:18:51.464640Z"
        },
        "trusted": true
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, y_train = X_train.values.tolist(), y_train.values.tolist()\n",
        "X_validation, y_validation = X_validation.values.tolist(), y_validation.values.tolist()\n",
        "X_test, y_test = X_test.values.tolist(), y_test.values.tolist()"
      ],
      "metadata": {
        "id": "SxzzTXwZIxVj",
        "execution": {
          "iopub.status.busy": "2023-06-12T05:18:51.468494Z",
          "iopub.execute_input": "2023-06-12T05:18:51.468760Z",
          "iopub.status.idle": "2023-06-12T05:18:51.483094Z",
          "shell.execute_reply.started": "2023-06-12T05:18:51.468714Z",
          "shell.execute_reply": "2023-06-12T05:18:51.482186Z"
        },
        "trusted": true
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_arr=[]\n",
        "y_train_arr=[]\n",
        "\n",
        "for i in range(len(X_train)):\n",
        "    X_train_arr.append(X_train[i][0])\n",
        "    y_train_arr.append(y_train[i][0])\n",
        "\n",
        "\n",
        "X_validation_arr=[]\n",
        "y_validation_arr=[]\n",
        "for i in range(len(X_validation)):\n",
        "    X_validation_arr.append(X_validation[i][0])\n",
        "    y_validation_arr.append(y_validation[i][0])\n",
        "\n",
        "\n",
        "X_test_arr=[]\n",
        "y_test_arr=[]\n",
        "X_test_latin=[]\n",
        "y_test_latin=[]\n",
        "\n",
        "X_test_Sinhala=[]\n",
        "y_test_Sinhala=[]\n",
        "\n",
        "X_test_Mixed=[]\n",
        "y_test_Mixed=[]\n",
        "for i in range(len(X_test)):\n",
        "    X_test_arr.append(X_test[i][0])\n",
        "    y_test_arr.append(y_test[i][0])\n",
        "\n",
        "    if X_test[i][1]==\"Latin\":\n",
        "        X_test_latin.append(X_test[i][0])\n",
        "        y_test_latin.append(y_test[i][0])\n",
        "\n",
        "    elif X_test[i][1]==\"Sinhala\":\n",
        "        X_test_Sinhala.append(X_test[i][0])\n",
        "        y_test_Sinhala.append(y_test[i][0])\n",
        "\n",
        "    elif X_test[i][1]==\"Mixed\":\n",
        "        X_test_Mixed.append(X_test[i][0])\n",
        "        y_test_Mixed.append(y_test[i][0])"
      ],
      "metadata": {
        "id": "oQbG0JmQIxVj",
        "execution": {
          "iopub.status.busy": "2023-06-12T05:18:51.485567Z",
          "iopub.execute_input": "2023-06-12T05:18:51.486413Z",
          "iopub.status.idle": "2023-06-12T05:18:51.506201Z",
          "shell.execute_reply.started": "2023-06-12T05:18:51.486389Z",
          "shell.execute_reply": "2023-06-12T05:18:51.505267Z"
        },
        "trusted": true
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_arr,y_train_arr=oversampling(X_train_arr,y_train_arr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x_4k3WAxZdiJ",
        "outputId": "f6cc760e-cb08-420f-8f14-9a8e4afd389e"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Distribution Without Oversampling [9810  278  726]\n",
            "Class Distribution After Oversampling [9810 2452 2452]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = AutoTokenizer.from_pretrained(\"xlm-roberta-base\", do_lower_case=True)"
      ],
      "metadata": {
        "id": "lCUWfe8-n0i8",
        "execution": {
          "iopub.status.busy": "2023-06-12T05:18:51.507889Z",
          "iopub.execute_input": "2023-06-12T05:18:51.508176Z",
          "iopub.status.idle": "2023-06-12T05:18:55.335122Z",
          "shell.execute_reply.started": "2023-06-12T05:18:51.508152Z",
          "shell.execute_reply": "2023-06-12T05:18:55.334108Z"
        },
        "trusted": true
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_X_train = tokenizer(X_train_arr, truncation=True, padding=True, max_length=MAX_LEN)\n",
        "encoded_X_validation = tokenizer(X_validation_arr, truncation=True, padding=True, max_length=MAX_LEN)\n",
        "encoded_X_test = tokenizer(X_test_arr, truncation=True, padding=True, max_length=MAX_LEN)\n",
        "encoded_X_test_latin = tokenizer(X_test_latin, truncation=True, padding=True, max_length=MAX_LEN)\n",
        "encoded_X_test_Sinhala = tokenizer(X_test_Sinhala, truncation=True, padding=True, max_length=MAX_LEN)\n",
        "encoded_X_test_Mixed = tokenizer(X_test_Mixed, truncation=True, padding=True, max_length=MAX_LEN)\n",
        "\n"
      ],
      "metadata": {
        "id": "TqXJtJe8oObQ",
        "execution": {
          "iopub.status.busy": "2023-06-12T05:18:55.336709Z",
          "iopub.execute_input": "2023-06-12T05:18:55.337332Z",
          "iopub.status.idle": "2023-06-12T05:18:56.345656Z",
          "shell.execute_reply.started": "2023-06-12T05:18:55.337296Z",
          "shell.execute_reply": "2023-06-12T05:18:56.344773Z"
        },
        "trusted": true
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DatasetObject(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = DatasetObject(encoded_X_train, y_train_arr)\n",
        "validation_dataset = DatasetObject(encoded_X_validation, y_validation_arr)\n",
        "test_dataset = DatasetObject(encoded_X_test, y_test_arr)\n",
        "test_dataset_latin = DatasetObject(encoded_X_test_latin, y_test_latin)\n",
        "test_dataset_Sinhala = DatasetObject(encoded_X_test_Sinhala, y_test_Sinhala)\n",
        "test_dataset_Mixed = DatasetObject(encoded_X_test_Mixed, y_test_Mixed)\n"
      ],
      "metadata": {
        "id": "6581Al-K_Nyf",
        "execution": {
          "iopub.status.busy": "2023-06-12T05:18:56.347302Z",
          "iopub.execute_input": "2023-06-12T05:18:56.347660Z",
          "iopub.status.idle": "2023-06-12T05:18:56.357584Z",
          "shell.execute_reply.started": "2023-06-12T05:18:56.347627Z",
          "shell.execute_reply": "2023-06-12T05:18:56.356762Z"
        },
        "trusted": true
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sampler = RandomSampler(train_dataset)\n",
        "# train_sampler = SequentialSampler(train_dataset)\n",
        "validation_sampler = SequentialSampler(validation_dataset)\n",
        "test_sampler = SequentialSampler(test_dataset)\n",
        "validation_sampler_latin = SequentialSampler(test_dataset_latin)\n",
        "validation_sampler_sinhala= SequentialSampler(test_dataset_Sinhala)\n",
        "validation_sampler_mixed = SequentialSampler(test_dataset_Mixed)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, sampler=train_sampler , batch_size=BATCH_SIZE)\n",
        "validation_loader = DataLoader(validation_dataset, sampler=validation_sampler , batch_size=BATCH_SIZE)\n",
        "test_loader = DataLoader(test_dataset, sampler=test_sampler , batch_size=BATCH_SIZE)\n",
        "test_loader_latin = DataLoader(test_dataset_latin, sampler=validation_sampler_latin , batch_size=BATCH_SIZE)\n",
        "test_loader_Sinhala = DataLoader(test_dataset_Sinhala, sampler=validation_sampler_sinhala , batch_size=BATCH_SIZE)\n",
        "test_loader_Mixed = DataLoader(test_dataset_Mixed, sampler=validation_sampler_mixed , batch_size=BATCH_SIZE)"
      ],
      "metadata": {
        "id": "Mol-S8fDIxVk",
        "execution": {
          "iopub.status.busy": "2023-06-12T05:18:56.359968Z",
          "iopub.execute_input": "2023-06-12T05:18:56.360673Z",
          "iopub.status.idle": "2023-06-12T05:18:56.371374Z",
          "shell.execute_reply.started": "2023-06-12T05:18:56.360636Z",
          "shell.execute_reply": "2023-06-12T05:18:56.370404Z"
        },
        "trusted": true
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "cCwk6iQE_XZb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "config = AutoConfig.from_pretrained(\"xlm-roberta-base\", num_labels=NO_OUTPUT_LAYERS)\n",
        "model = AutoModelWithHeads.from_pretrained(\"xlm-roberta-base\", config=config)"
      ],
      "metadata": {
        "id": "KNyi1nFH_TOS",
        "outputId": "4493bbdb-fa45-4563-9d13-ac75b4ef98ff",
        "execution": {
          "iopub.status.busy": "2023-06-12T05:18:56.372928Z",
          "iopub.execute_input": "2023-06-12T05:18:56.373282Z",
          "iopub.status.idle": "2023-06-12T05:19:19.007030Z",
          "shell.execute_reply.started": "2023-06-12T05:18:56.373214Z",
          "shell.execute_reply": "2023-06-12T05:19:19.006114Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/adapters/models/roberta/adapter_model.py:255: FutureWarning: This class has been renamed to `RobertaModelWithHeads` in v3. Please use the new class instead as this class might be removed in a future version.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/adapters/models/roberta/adapter_model.py:233: FutureWarning: This class has been renamed to `RobertaModelWithHeads` in v3. Please use the new class instead as this class might be removed in a future version.\n",
            "  warnings.warn(\n",
            "Some weights of the model checkpoint at xlm-roberta-base were not used when initializing XLMRobertaModelWithHeads: ['lm_head.layer_norm.weight', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.decoder.weight', 'lm_head.dense.weight', 'lm_head.layer_norm.bias']\n",
            "- This IS expected if you are initializing XLMRobertaModelWithHeads from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing XLMRobertaModelWithHeads from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of XLMRobertaModelWithHeads were not initialized from the model checkpoint at xlm-roberta-base and are newly initialized: ['roberta.embeddings.position_ids']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load an adapter\n",
        "if load_adapter:\n",
        "  print(\"loading adapter from\", pretrained_adapter_path)\n",
        "  model.load_adapter(pretrained_adapter_path, with_head=False)\n",
        "\n",
        "# Add a new adapter\n",
        "else:\n",
        "  print(\"adding new adapter\", adapter_config)\n",
        "  if adapter_config == \"pfeiffer\":\n",
        "    config = AdapterConfig.load(\"pfeiffer\", reduction_factor=12)\n",
        "  else:\n",
        "    config = AdapterConfig.load(\"houlsby\")\n",
        "  model.add_adapter(\"task_\"+technique, config=config)"
      ],
      "metadata": {
        "id": "7RPhSipb_diC",
        "outputId": "d0c42e2c-8d16-4ef5-d2a8-09729baf94f8",
        "execution": {
          "iopub.status.busy": "2023-06-12T05:19:19.008362Z",
          "iopub.execute_input": "2023-06-12T05:19:19.008957Z",
          "iopub.status.idle": "2023-06-12T05:19:19.108838Z",
          "shell.execute_reply.started": "2023-06-12T05:19:19.008921Z",
          "shell.execute_reply": "2023-06-12T05:19:19.107856Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "adding new adapter houlsby\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Add a classification head\n",
        "model.add_classification_head(\n",
        "  \"task_\"+technique,\n",
        "  num_labels=NO_OUTPUT_LAYERS,\n",
        "  id2label=id2label\n",
        ")\n",
        "\n",
        "# Without Language Adapters\n",
        "if lang_adapter_setting == \"none\":\n",
        "  model.set_active_adapters(\"task_\"+technique)\n",
        "\n",
        "else:\n",
        "  # Load language adapters\n",
        "  lang_adapter_config = AdapterConfig.load(\"pfeiffer+inv\")\n",
        "  model.load_adapter(\"/kaggle/input/language-adapters/mlm\", config=lang_adapter_config, load_as=\"si-en\", with_head=False)\n",
        "  # model.load_adapter(\"/content/drive/Shareddrives/FYP/TrainedAdapters/si_mlm\", config=lang_adapter_config, load_as=\"si\", with_head=False)\n",
        "  model.load_adapter(\"/kaggle/input/language-adapters/si_mlm\", config=lang_adapter_config, load_as=\"si\", with_head=False)\n",
        "  config = AdapterConfig.load(\"pfeiffer\", non_linearity=\"relu\", reduction_factor=2)\n",
        "  model.load_adapter(\"en/wiki@ukp\", config=config)\n",
        "\n",
        "  # Stack Language Adapters\n",
        "  if lang_adapter_setting == \"stack\":\n",
        "    print(\"stacking language adapters\")\n",
        "    model.set_active_adapters(Stack(\"en\", \"si\", \"si-en\", \"task_\"+technique))\n",
        "\n",
        "  # Parallel Language Adapters\n",
        "  else:\n",
        "    print(\"stacking parallel language adapters set\")\n",
        "    model.set_active_adapters(Stack(Parallel(\"en\", \"si\", \"si-en\"), \"task_\"+technique))\n",
        "\n",
        "# Train Adapter\n",
        "model.train_adapter(\"task_\"+technique)"
      ],
      "metadata": {
        "id": "Zq1dG4sVcDX5",
        "execution": {
          "iopub.status.busy": "2023-06-12T05:19:19.110195Z",
          "iopub.execute_input": "2023-06-12T05:19:19.110621Z",
          "iopub.status.idle": "2023-06-12T05:19:24.752611Z",
          "shell.execute_reply.started": "2023-06-12T05:19:19.110587Z",
          "shell.execute_reply": "2023-06-12T05:19:24.751474Z"
        },
        "trusted": true
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Unfreeze the model to train both the model and adapter\n",
        "if unfreeze_model:\n",
        "  model.freeze_model(False)"
      ],
      "metadata": {
        "id": "iVTWkQaiiuhZ",
        "execution": {
          "iopub.status.busy": "2023-06-12T05:19:24.757838Z",
          "iopub.execute_input": "2023-06-12T05:19:24.761084Z",
          "iopub.status.idle": "2023-06-12T05:19:24.770550Z",
          "shell.execute_reply.started": "2023-06-12T05:19:24.761040Z",
          "shell.execute_reply": "2023-06-12T05:19:24.767543Z"
        },
        "trusted": true
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# for n, p in model.named_parameters():\n",
        "#     print(n, p.requires_grad)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2023-06-12T05:24:31.394251Z",
          "iopub.execute_input": "2023-06-12T05:24:31.394604Z",
          "iopub.status.idle": "2023-06-12T05:24:31.408818Z",
          "shell.execute_reply.started": "2023-06-12T05:24:31.394576Z",
          "shell.execute_reply": "2023-06-12T05:24:31.407915Z"
        },
        "trusted": true,
        "id": "X_M81DDclDDE"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.cuda()\n",
        "print(\"Done\")"
      ],
      "metadata": {
        "id": "SBMtmX77IMlZ",
        "outputId": "4f1758ed-f90b-433a-adb1-20448189a2b6",
        "execution": {
          "iopub.status.busy": "2023-06-12T05:19:24.777193Z",
          "iopub.execute_input": "2023-06-12T05:19:24.778982Z",
          "iopub.status.idle": "2023-06-12T05:19:30.426981Z",
          "shell.execute_reply.started": "2023-06-12T05:19:24.778942Z",
          "shell.execute_reply": "2023-06-12T05:19:30.425887Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()\n",
        "torch.cuda.get_device_name(0)"
      ],
      "metadata": {
        "id": "bny18Y2qHvf0",
        "outputId": "8b933b86-5cec-4149-e630-f95bb5cbfd04",
        "execution": {
          "iopub.status.busy": "2023-06-12T05:19:30.428321Z",
          "iopub.execute_input": "2023-06-12T05:19:30.428779Z",
          "iopub.status.idle": "2023-06-12T05:19:30.439256Z",
          "shell.execute_reply.started": "2023-06-12T05:19:30.428744Z",
          "shell.execute_reply": "2023-06-12T05:19:30.438332Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Tesla T4'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "set_seed(training_seed)"
      ],
      "metadata": {
        "id": "Iu1hV1g3jAvS",
        "execution": {
          "iopub.status.busy": "2023-06-12T05:19:30.445588Z",
          "iopub.execute_input": "2023-06-12T05:19:30.445879Z",
          "iopub.status.idle": "2023-06-12T05:19:30.886819Z",
          "shell.execute_reply.started": "2023-06-12T05:19:30.445855Z",
          "shell.execute_reply": "2023-06-12T05:19:30.885752Z"
        },
        "trusted": true
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_metrics(allpreds,alllabels):\n",
        "    metric1 = load_metric(\"precision\")\n",
        "    metric2 = load_metric(\"recall\")\n",
        "    metric3 = load_metric(\"f1\")\n",
        "    metric4 = load_metric(\"accuracy\")\n",
        "\n",
        "    predictions, labels = allpreds,alllabels\n",
        "    precision = metric1.compute(predictions=predictions, references=labels, average=\"weighted\")[\"precision\"]\n",
        "    recall = metric2.compute(predictions=predictions, references=labels, average=\"weighted\")[\"recall\"]\n",
        "    f1 = metric3.compute(predictions=predictions, references=labels, average=\"weighted\")[\"f1\"]\n",
        "    accuracy = metric4.compute(predictions=predictions, references=labels)[\"accuracy\"]\n",
        "    macro_precision = metric1.compute(predictions=predictions, references=labels, average=\"macro\")[\"precision\"]\n",
        "    macro_recall = metric2.compute(predictions=predictions, references=labels, average=\"macro\")[\"recall\"]\n",
        "    macro_f1 = metric3.compute(predictions=predictions, references=labels, average=\"macro\")[\"f1\"]\n",
        "    return {\"accuracy\":accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1, \"macro_precision\": macro_precision, \"macro_recall\": macro_recall, \"macro_f1\": macro_f1}\n"
      ],
      "metadata": {
        "id": "ZDiEfZumNwYA",
        "execution": {
          "iopub.status.busy": "2023-06-12T05:19:30.888648Z",
          "iopub.execute_input": "2023-06-12T05:19:30.889485Z",
          "iopub.status.idle": "2023-06-12T05:19:30.900689Z",
          "shell.execute_reply.started": "2023-06-12T05:19:30.889451Z",
          "shell.execute_reply": "2023-06-12T05:19:30.899797Z"
        },
        "trusted": true
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, dataloader):\n",
        "    model.eval()\n",
        "    allpreds = []\n",
        "    alllabels = []\n",
        "\n",
        "    for step, batch in enumerate(dataloader):\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**batch)\n",
        "        logits = outputs.logits\n",
        "        allpreds.extend(torch.argmax(logits, dim=-1))\n",
        "        alllabels.extend(batch[\"labels\"])\n",
        "    return compute_metrics(allpreds,alllabels)"
      ],
      "metadata": {
        "id": "ErqMNvyEGL07",
        "execution": {
          "iopub.status.busy": "2023-06-12T05:19:30.902227Z",
          "iopub.execute_input": "2023-06-12T05:19:30.902832Z",
          "iopub.status.idle": "2023-06-12T05:19:30.921300Z",
          "shell.execute_reply.started": "2023-06-12T05:19:30.902798Z",
          "shell.execute_reply": "2023-06-12T05:19:30.920364Z"
        },
        "trusted": true
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def calculate_loss_and_f1(model, dataloader):\n",
        "    model.eval()\n",
        "    allpreds = []\n",
        "    alllabels = []\n",
        "    total_loss = 0\n",
        "\n",
        "    for step, batch in enumerate(dataloader):\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        with torch.no_grad():\n",
        "            outputs = model(**batch)\n",
        "        logits = outputs.logits\n",
        "        loss = outputs.loss\n",
        "        total_loss += loss.item()\n",
        "        allpreds.extend(torch.argmax(logits, dim=-1))\n",
        "        alllabels.extend(batch[\"labels\"])\n",
        "\n",
        "    macro_f1 = load_metric(\"f1\").compute(predictions=allpreds, references=alllabels, average=\"macro\")[\"f1\"]\n",
        "    return macro_f1, (total_loss/len(dataloader))"
      ],
      "metadata": {
        "id": "_oEcPkiDGOjQ",
        "execution": {
          "iopub.status.busy": "2023-06-12T05:19:30.922766Z",
          "iopub.execute_input": "2023-06-12T05:19:30.923213Z",
          "iopub.status.idle": "2023-06-12T05:19:30.936779Z",
          "shell.execute_reply.started": "2023-06-12T05:19:30.923181Z",
          "shell.execute_reply": "2023-06-12T05:19:30.935943Z"
        },
        "trusted": true
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_decay = ['bias', 'LayerNorm.weight']\n",
        "num_training_steps = EPOCHS * len(train_loader)\n",
        "betas = (0.9, 0.999)\n",
        "eps = 1e-08\n",
        "num_warmup_steps = 0\n",
        "param_optimizer = list(model.named_parameters())\n",
        "\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "     'weight_decay_rate': 0.0}\n",
        "]\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=LEARNING_RATE,betas=betas,eps=eps)\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)"
      ],
      "metadata": {
        "id": "oesjvk80GQZW",
        "outputId": "91f569cb-8504-43bd-97dc-d9178c9ffa7e",
        "execution": {
          "iopub.status.busy": "2023-06-12T05:19:30.938187Z",
          "iopub.execute_input": "2023-06-12T05:19:30.939110Z",
          "iopub.status.idle": "2023-06-12T05:19:30.961933Z",
          "shell.execute_reply.started": "2023-06-12T05:19:30.939078Z",
          "shell.execute_reply": "2023-06-12T05:19:30.961024Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tot_loss = 0\n",
        "log_loss = 0\n",
        "best_val_acc = 0\n",
        "\n",
        "tot_train_time = 0\n",
        "pbar_update_freq = 10\n",
        "\n",
        "glb_step = 0\n",
        "actual_step = 0\n",
        "max_grad_norm = 1.0\n",
        "eval_every_steps = 100\n",
        "gradient_accumulation_steps = 1\n",
        "\n",
        "leave_training = False\n",
        "val_metric = \"macro_f1\"\n",
        "\n",
        "best_epoch = -1\n",
        "early_stop_epoch_thresh = 5\n",
        "\n",
        "epoch_traces = []\n",
        "acc_traces = []\n",
        "validation_loss_traces = []"
      ],
      "metadata": {
        "id": "5l6csY77GS8F",
        "execution": {
          "iopub.status.busy": "2023-06-12T05:19:30.963142Z",
          "iopub.execute_input": "2023-06-12T05:19:30.963858Z",
          "iopub.status.idle": "2023-06-12T05:19:30.973548Z",
          "shell.execute_reply.started": "2023-06-12T05:19:30.963817Z",
          "shell.execute_reply": "2023-06-12T05:19:30.972538Z"
        },
        "trusted": true
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pbar = tqdm(total=num_training_steps, desc=\"Train\")\n",
        "for epoch in range(EPOCHS):\n",
        "    print(f\"Begin Epoch {epoch}\")\n",
        "    epoch_start_time = time.time()\n",
        "    for step, batch in enumerate(train_loader):\n",
        "        batch = {k: v.to(device) for k, v in batch.items()}\n",
        "        outputs = model(**batch)\n",
        "        loss = outputs.loss\n",
        "        loss = loss / gradient_accumulation_steps\n",
        "        loss.backward()\n",
        "        tot_loss += loss.item()\n",
        "        actual_step += 1\n",
        "\n",
        "        if actual_step % gradient_accumulation_steps == 0:\n",
        "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n",
        "            glb_step += 1\n",
        "\n",
        "            if glb_step % pbar_update_freq == 0:\n",
        "                aveloss = (tot_loss - log_loss)/pbar_update_freq\n",
        "                pbar.update(pbar_update_freq)\n",
        "                pbar.set_postfix({'Average Loss': aveloss, \"Epoch\": epoch})\n",
        "                log_loss = tot_loss\n",
        "\n",
        "            if optimizer is not None:\n",
        "                optimizer.step()\n",
        "                optimizer.zero_grad()\n",
        "            if scheduler is not None:\n",
        "                scheduler.step()\n",
        "\n",
        "        if glb_step > num_training_steps:\n",
        "            leave_training = True\n",
        "            break\n",
        "\n",
        "    val_acc, val_loss = calculate_loss_and_f1(model, validation_loader)\n",
        "    epoch_traces.append(epoch)\n",
        "    acc_traces.append(val_acc)\n",
        "    validation_loss_traces.append(val_loss)\n",
        "    print(\"Validation: [Epoch: {}, Macro F1: {}, Validation Loss: {}, Time per Epoch: {}]\".format(epoch, val_acc, val_loss, time.time()-epoch_start_time), flush=True)\n",
        "\n",
        "    if val_acc > best_val_acc:\n",
        "        torch.save(model.state_dict(),f\"best_model.ckpt\")\n",
        "        best_val_acc = val_acc\n",
        "        best_epoch = epoch\n",
        "\n",
        "    elif (epoch - best_epoch) >= early_stop_epoch_thresh:\n",
        "        print(\"Training stopped early at Epoch: %d\" % epoch)\n",
        "        break  # Terminate the training loop\n",
        "\n",
        "    if leave_training:\n",
        "        break"
      ],
      "metadata": {
        "id": "dkv8HsFgGVGY",
        "outputId": "8817b886-d2c1-4a6b-cc9e-dd3e60f723ef",
        "execution": {
          "iopub.status.busy": "2023-06-12T05:19:30.975003Z",
          "iopub.execute_input": "2023-06-12T05:19:30.975544Z",
          "iopub.status.idle": "2023-06-12T05:19:39.534607Z",
          "shell.execute_reply.started": "2023-06-12T05:19:30.975512Z",
          "shell.execute_reply": "2023-06-12T05:19:39.533123Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Train:  40%|████      | 3680/9200 [40:27<1:00:40,  1.52it/s, Average Loss=0.000124, Epoch=7]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Begin Epoch 0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Train:   0%|          | 10/9200 [00:04<1:06:59,  2.29it/s]\u001b[A\n",
            "Train:   0%|          | 10/9200 [00:04<1:06:59,  2.29it/s, Average Loss=1.06, Epoch=0]\u001b[A\n",
            "Train:   0%|          | 20/9200 [00:08<1:08:17,  2.24it/s, Average Loss=1.06, Epoch=0]\u001b[A\n",
            "Train:   0%|          | 20/9200 [00:08<1:08:17,  2.24it/s, Average Loss=0.869, Epoch=0]\u001b[A\n",
            "Train:   0%|          | 30/9200 [00:13<1:08:37,  2.23it/s, Average Loss=0.869, Epoch=0]\u001b[A\n",
            "Train:   0%|          | 30/9200 [00:13<1:08:37,  2.23it/s, Average Loss=0.866, Epoch=0]\u001b[A\n",
            "Train:   0%|          | 40/9200 [00:17<1:08:24,  2.23it/s, Average Loss=0.866, Epoch=0]\u001b[A\n",
            "Train:   0%|          | 40/9200 [00:17<1:08:24,  2.23it/s, Average Loss=0.86, Epoch=0] \u001b[A\n",
            "Train:   1%|          | 50/9200 [00:22<1:08:19,  2.23it/s, Average Loss=0.86, Epoch=0]\u001b[A\n",
            "Train:   1%|          | 50/9200 [00:22<1:08:19,  2.23it/s, Average Loss=0.811, Epoch=0]\u001b[A\n",
            "Train:   1%|          | 60/9200 [00:27<1:09:06,  2.20it/s, Average Loss=0.811, Epoch=0]\u001b[A\n",
            "Train:   1%|          | 60/9200 [00:27<1:09:06,  2.20it/s, Average Loss=0.84, Epoch=0] \u001b[A\n",
            "Train:   1%|          | 70/9200 [00:31<1:08:52,  2.21it/s, Average Loss=0.84, Epoch=0]\u001b[A\n",
            "Train:   1%|          | 70/9200 [00:31<1:08:52,  2.21it/s, Average Loss=0.745, Epoch=0]\u001b[A\n",
            "Train:   1%|          | 80/9200 [00:35<1:07:42,  2.24it/s, Average Loss=0.745, Epoch=0]\u001b[A\n",
            "Train:   1%|          | 80/9200 [00:35<1:07:42,  2.24it/s, Average Loss=0.797, Epoch=0]\u001b[A\n",
            "Train:   1%|          | 90/9200 [00:40<1:07:03,  2.26it/s, Average Loss=0.797, Epoch=0]\u001b[A\n",
            "Train:   1%|          | 90/9200 [00:40<1:07:03,  2.26it/s, Average Loss=0.838, Epoch=0]\u001b[A\n",
            "Train:   1%|          | 100/9200 [00:44<1:06:43,  2.27it/s, Average Loss=0.838, Epoch=0]\u001b[A\n",
            "Train:   1%|          | 100/9200 [00:44<1:06:43,  2.27it/s, Average Loss=0.808, Epoch=0]\u001b[A\n",
            "Train:   1%|          | 110/9200 [00:48<1:06:22,  2.28it/s, Average Loss=0.808, Epoch=0]\u001b[A\n",
            "Train:   1%|          | 110/9200 [00:48<1:06:22,  2.28it/s, Average Loss=0.763, Epoch=0]\u001b[A\n",
            "Train:   1%|▏         | 120/9200 [00:53<1:06:15,  2.28it/s, Average Loss=0.763, Epoch=0]\u001b[A\n",
            "Train:   1%|▏         | 120/9200 [00:53<1:06:15,  2.28it/s, Average Loss=0.747, Epoch=0]\u001b[A\n",
            "Train:   1%|▏         | 130/9200 [00:57<1:06:24,  2.28it/s, Average Loss=0.747, Epoch=0]\u001b[A\n",
            "Train:   1%|▏         | 130/9200 [00:57<1:06:24,  2.28it/s, Average Loss=0.76, Epoch=0] \u001b[A\n",
            "Train:   2%|▏         | 140/9200 [01:02<1:06:22,  2.27it/s, Average Loss=0.76, Epoch=0]\u001b[A\n",
            "Train:   2%|▏         | 140/9200 [01:02<1:06:22,  2.27it/s, Average Loss=0.731, Epoch=0]\u001b[A\n",
            "Train:   2%|▏         | 150/9200 [01:06<1:06:26,  2.27it/s, Average Loss=0.731, Epoch=0]\u001b[A\n",
            "Train:   2%|▏         | 150/9200 [01:06<1:06:26,  2.27it/s, Average Loss=0.584, Epoch=0]\u001b[A\n",
            "Train:   2%|▏         | 160/9200 [01:10<1:06:44,  2.26it/s, Average Loss=0.584, Epoch=0]\u001b[A\n",
            "Train:   2%|▏         | 160/9200 [01:10<1:06:44,  2.26it/s, Average Loss=0.701, Epoch=0]\u001b[A\n",
            "Train:   2%|▏         | 170/9200 [01:15<1:06:56,  2.25it/s, Average Loss=0.701, Epoch=0]\u001b[A\n",
            "Train:   2%|▏         | 170/9200 [01:15<1:06:56,  2.25it/s, Average Loss=0.617, Epoch=0]\u001b[A\n",
            "Train:   2%|▏         | 180/9200 [01:19<1:07:02,  2.24it/s, Average Loss=0.617, Epoch=0]\u001b[A\n",
            "Train:   2%|▏         | 180/9200 [01:19<1:07:02,  2.24it/s, Average Loss=0.708, Epoch=0]\u001b[A\n",
            "Train:   2%|▏         | 190/9200 [01:24<1:07:18,  2.23it/s, Average Loss=0.708, Epoch=0]\u001b[A\n",
            "Train:   2%|▏         | 190/9200 [01:24<1:07:18,  2.23it/s, Average Loss=0.681, Epoch=0]\u001b[A\n",
            "Train:   2%|▏         | 200/9200 [01:29<1:07:41,  2.22it/s, Average Loss=0.681, Epoch=0]\u001b[A\n",
            "Train:   2%|▏         | 200/9200 [01:29<1:07:41,  2.22it/s, Average Loss=0.605, Epoch=0]\u001b[A\n",
            "Train:   2%|▏         | 210/9200 [01:33<1:07:45,  2.21it/s, Average Loss=0.605, Epoch=0]\u001b[A\n",
            "Train:   2%|▏         | 210/9200 [01:33<1:07:45,  2.21it/s, Average Loss=0.645, Epoch=0]\u001b[A\n",
            "Train:   2%|▏         | 220/9200 [01:38<1:08:55,  2.17it/s, Average Loss=0.645, Epoch=0]\u001b[A\n",
            "Train:   2%|▏         | 220/9200 [01:38<1:08:55,  2.17it/s, Average Loss=0.67, Epoch=0] \u001b[A\n",
            "Train:   2%|▎         | 230/9200 [01:43<1:09:42,  2.14it/s, Average Loss=0.67, Epoch=0]\u001b[A\n",
            "Train:   2%|▎         | 230/9200 [01:43<1:09:42,  2.14it/s, Average Loss=0.661, Epoch=0]\u001b[A\n",
            "Train:   3%|▎         | 240/9200 [01:47<1:08:51,  2.17it/s, Average Loss=0.661, Epoch=0]\u001b[A\n",
            "Train:   3%|▎         | 240/9200 [01:47<1:08:51,  2.17it/s, Average Loss=0.56, Epoch=0] \u001b[A\n",
            "Train:   3%|▎         | 250/9200 [01:52<1:08:10,  2.19it/s, Average Loss=0.56, Epoch=0]\u001b[A\n",
            "Train:   3%|▎         | 250/9200 [01:52<1:08:10,  2.19it/s, Average Loss=0.6, Epoch=0] \u001b[A\n",
            "Train:   3%|▎         | 260/9200 [01:56<1:07:51,  2.20it/s, Average Loss=0.6, Epoch=0]\u001b[A\n",
            "Train:   3%|▎         | 260/9200 [01:56<1:07:51,  2.20it/s, Average Loss=0.708, Epoch=0]\u001b[A\n",
            "Train:   3%|▎         | 270/9200 [02:01<1:07:26,  2.21it/s, Average Loss=0.708, Epoch=0]\u001b[A\n",
            "Train:   3%|▎         | 270/9200 [02:01<1:07:26,  2.21it/s, Average Loss=0.676, Epoch=0]\u001b[A\n",
            "Train:   3%|▎         | 280/9200 [02:05<1:06:58,  2.22it/s, Average Loss=0.676, Epoch=0]\u001b[A\n",
            "Train:   3%|▎         | 280/9200 [02:05<1:06:58,  2.22it/s, Average Loss=0.682, Epoch=0]\u001b[A\n",
            "Train:   3%|▎         | 290/9200 [02:10<1:06:45,  2.22it/s, Average Loss=0.682, Epoch=0]\u001b[A\n",
            "Train:   3%|▎         | 290/9200 [02:10<1:06:45,  2.22it/s, Average Loss=0.569, Epoch=0]\u001b[A\n",
            "Train:   3%|▎         | 300/9200 [02:14<1:06:38,  2.23it/s, Average Loss=0.569, Epoch=0]\u001b[A\n",
            "Train:   3%|▎         | 300/9200 [02:14<1:06:38,  2.23it/s, Average Loss=0.618, Epoch=0]\u001b[A\n",
            "Train:   3%|▎         | 310/9200 [02:19<1:06:27,  2.23it/s, Average Loss=0.618, Epoch=0]\u001b[A\n",
            "Train:   3%|▎         | 310/9200 [02:19<1:06:27,  2.23it/s, Average Loss=0.657, Epoch=0]\u001b[A\n",
            "Train:   3%|▎         | 320/9200 [02:23<1:06:17,  2.23it/s, Average Loss=0.657, Epoch=0]\u001b[A\n",
            "Train:   3%|▎         | 320/9200 [02:23<1:06:17,  2.23it/s, Average Loss=0.537, Epoch=0]\u001b[A\n",
            "Train:   4%|▎         | 330/9200 [02:28<1:06:26,  2.23it/s, Average Loss=0.537, Epoch=0]\u001b[A\n",
            "Train:   4%|▎         | 330/9200 [02:28<1:06:26,  2.23it/s, Average Loss=0.595, Epoch=0]\u001b[A\n",
            "Train:   4%|▎         | 340/9200 [02:32<1:06:19,  2.23it/s, Average Loss=0.595, Epoch=0]\u001b[A\n",
            "Train:   4%|▎         | 340/9200 [02:32<1:06:19,  2.23it/s, Average Loss=0.611, Epoch=0]\u001b[A\n",
            "Train:   4%|▍         | 350/9200 [02:37<1:06:12,  2.23it/s, Average Loss=0.611, Epoch=0]\u001b[A\n",
            "Train:   4%|▍         | 350/9200 [02:37<1:06:12,  2.23it/s, Average Loss=0.53, Epoch=0] \u001b[A\n",
            "Train:   4%|▍         | 360/9200 [02:41<1:06:15,  2.22it/s, Average Loss=0.53, Epoch=0]\u001b[A\n",
            "Train:   4%|▍         | 360/9200 [02:41<1:06:15,  2.22it/s, Average Loss=0.627, Epoch=0]\u001b[A\n",
            "Train:   4%|▍         | 370/9200 [02:46<1:06:14,  2.22it/s, Average Loss=0.627, Epoch=0]\u001b[A\n",
            "Train:   4%|▍         | 370/9200 [02:46<1:06:14,  2.22it/s, Average Loss=0.574, Epoch=0]\u001b[A\n",
            "Train:   4%|▍         | 380/9200 [02:50<1:06:05,  2.22it/s, Average Loss=0.574, Epoch=0]\u001b[A\n",
            "Train:   4%|▍         | 380/9200 [02:50<1:06:05,  2.22it/s, Average Loss=0.554, Epoch=0]\u001b[A\n",
            "Train:   4%|▍         | 390/9200 [02:55<1:06:07,  2.22it/s, Average Loss=0.554, Epoch=0]\u001b[A\n",
            "Train:   4%|▍         | 390/9200 [02:55<1:06:07,  2.22it/s, Average Loss=0.549, Epoch=0]\u001b[A\n",
            "Train:   4%|▍         | 400/9200 [02:59<1:06:11,  2.22it/s, Average Loss=0.549, Epoch=0]\u001b[A\n",
            "Train:   4%|▍         | 400/9200 [02:59<1:06:11,  2.22it/s, Average Loss=0.555, Epoch=0]\u001b[A\n",
            "Train:   4%|▍         | 410/9200 [03:04<1:05:59,  2.22it/s, Average Loss=0.555, Epoch=0]\u001b[A\n",
            "Train:   4%|▍         | 410/9200 [03:04<1:05:59,  2.22it/s, Average Loss=0.51, Epoch=0] \u001b[A\n",
            "Train:   5%|▍         | 420/9200 [03:08<1:05:49,  2.22it/s, Average Loss=0.51, Epoch=0]\u001b[A\n",
            "Train:   5%|▍         | 420/9200 [03:08<1:05:49,  2.22it/s, Average Loss=0.526, Epoch=0]\u001b[A\n",
            "Train:   5%|▍         | 430/9200 [03:13<1:05:55,  2.22it/s, Average Loss=0.526, Epoch=0]\u001b[A\n",
            "Train:   5%|▍         | 430/9200 [03:13<1:05:55,  2.22it/s, Average Loss=0.476, Epoch=0]\u001b[A\n",
            "Train:   5%|▍         | 440/9200 [03:17<1:06:14,  2.20it/s, Average Loss=0.476, Epoch=0]\u001b[A\n",
            "Train:   5%|▍         | 440/9200 [03:17<1:06:14,  2.20it/s, Average Loss=0.482, Epoch=0]\u001b[A\n",
            "Train:   5%|▍         | 450/9200 [03:22<1:06:47,  2.18it/s, Average Loss=0.482, Epoch=0]\u001b[A\n",
            "Train:   5%|▍         | 450/9200 [03:22<1:06:47,  2.18it/s, Average Loss=0.547, Epoch=0]\u001b[A\n",
            "Train:   5%|▌         | 460/9200 [03:27<1:07:49,  2.15it/s, Average Loss=0.547, Epoch=0]\u001b[A\n",
            "Train:   5%|▌         | 460/9200 [03:27<1:07:49,  2.15it/s, Average Loss=0.553, Epoch=0]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: [Epoch: 0, Macro F1: 0.5471248628227218, Validation Loss: 0.42144988269306893, Time per Epoch: 216.8807897567749]\n",
            "Begin Epoch 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Train:   5%|▌         | 470/9200 [03:45<2:09:08,  1.13it/s, Average Loss=0.553, Epoch=0]\u001b[A\n",
            "Train:   5%|▌         | 470/9200 [03:45<2:09:08,  1.13it/s, Average Loss=0.43, Epoch=1] \u001b[A\n",
            "Train:   5%|▌         | 480/9200 [03:50<1:48:26,  1.34it/s, Average Loss=0.43, Epoch=1]\u001b[A\n",
            "Train:   5%|▌         | 480/9200 [03:50<1:48:26,  1.34it/s, Average Loss=0.387, Epoch=1]\u001b[A\n",
            "Train:   5%|▌         | 490/9200 [03:54<1:33:59,  1.54it/s, Average Loss=0.387, Epoch=1]\u001b[A\n",
            "Train:   5%|▌         | 490/9200 [03:54<1:33:59,  1.54it/s, Average Loss=0.348, Epoch=1]\u001b[A\n",
            "Train:   5%|▌         | 500/9200 [03:58<1:24:12,  1.72it/s, Average Loss=0.348, Epoch=1]\u001b[A\n",
            "Train:   5%|▌         | 500/9200 [03:58<1:24:12,  1.72it/s, Average Loss=0.402, Epoch=1]\u001b[A\n",
            "Train:   6%|▌         | 510/9200 [04:02<1:17:17,  1.87it/s, Average Loss=0.402, Epoch=1]\u001b[A\n",
            "Train:   6%|▌         | 510/9200 [04:02<1:17:17,  1.87it/s, Average Loss=0.345, Epoch=1]\u001b[A\n",
            "Train:   6%|▌         | 520/9200 [04:06<1:12:26,  2.00it/s, Average Loss=0.345, Epoch=1]\u001b[A\n",
            "Train:   6%|▌         | 520/9200 [04:06<1:12:26,  2.00it/s, Average Loss=0.364, Epoch=1]\u001b[A\n",
            "Train:   6%|▌         | 530/9200 [04:11<1:09:13,  2.09it/s, Average Loss=0.364, Epoch=1]\u001b[A\n",
            "Train:   6%|▌         | 530/9200 [04:11<1:09:13,  2.09it/s, Average Loss=0.384, Epoch=1]\u001b[A\n",
            "Train:   6%|▌         | 540/9200 [04:15<1:06:58,  2.16it/s, Average Loss=0.384, Epoch=1]\u001b[A\n",
            "Train:   6%|▌         | 540/9200 [04:15<1:06:58,  2.16it/s, Average Loss=0.265, Epoch=1]\u001b[A\n",
            "Train:   6%|▌         | 550/9200 [04:19<1:05:06,  2.21it/s, Average Loss=0.265, Epoch=1]\u001b[A\n",
            "Train:   6%|▌         | 550/9200 [04:19<1:05:06,  2.21it/s, Average Loss=0.393, Epoch=1]\u001b[A\n",
            "Train:   6%|▌         | 560/9200 [04:23<1:03:40,  2.26it/s, Average Loss=0.393, Epoch=1]\u001b[A\n",
            "Train:   6%|▌         | 560/9200 [04:23<1:03:40,  2.26it/s, Average Loss=0.288, Epoch=1]\u001b[A\n",
            "Train:   6%|▌         | 570/9200 [04:28<1:02:52,  2.29it/s, Average Loss=0.288, Epoch=1]\u001b[A\n",
            "Train:   6%|▌         | 570/9200 [04:28<1:02:52,  2.29it/s, Average Loss=0.338, Epoch=1]\u001b[A\n",
            "Train:   6%|▋         | 580/9200 [04:32<1:02:02,  2.32it/s, Average Loss=0.338, Epoch=1]\u001b[A\n",
            "Train:   6%|▋         | 580/9200 [04:32<1:02:02,  2.32it/s, Average Loss=0.31, Epoch=1] \u001b[A\n",
            "Train:   6%|▋         | 590/9200 [04:36<1:01:23,  2.34it/s, Average Loss=0.31, Epoch=1]\u001b[A\n",
            "Train:   6%|▋         | 590/9200 [04:36<1:01:23,  2.34it/s, Average Loss=0.33, Epoch=1]\u001b[A\n",
            "Train:   7%|▋         | 600/9200 [04:40<1:00:57,  2.35it/s, Average Loss=0.33, Epoch=1]\u001b[A\n",
            "Train:   7%|▋         | 600/9200 [04:40<1:00:57,  2.35it/s, Average Loss=0.298, Epoch=1]\u001b[A\n",
            "Train:   7%|▋         | 610/9200 [04:45<1:00:47,  2.36it/s, Average Loss=0.298, Epoch=1]\u001b[A\n",
            "Train:   7%|▋         | 610/9200 [04:45<1:00:47,  2.36it/s, Average Loss=0.272, Epoch=1]\u001b[A\n",
            "Train:   7%|▋         | 620/9200 [04:49<1:00:22,  2.37it/s, Average Loss=0.272, Epoch=1]\u001b[A\n",
            "Train:   7%|▋         | 620/9200 [04:49<1:00:22,  2.37it/s, Average Loss=0.294, Epoch=1]\u001b[A\n",
            "Train:   7%|▋         | 630/9200 [04:53<1:00:04,  2.38it/s, Average Loss=0.294, Epoch=1]\u001b[A\n",
            "Train:   7%|▋         | 630/9200 [04:53<1:00:04,  2.38it/s, Average Loss=0.28, Epoch=1] \u001b[A\n",
            "Train:   7%|▋         | 640/9200 [04:57<1:00:00,  2.38it/s, Average Loss=0.28, Epoch=1]\u001b[A\n",
            "Train:   7%|▋         | 640/9200 [04:57<1:00:00,  2.38it/s, Average Loss=0.295, Epoch=1]\u001b[A\n",
            "Train:   7%|▋         | 650/9200 [05:01<1:00:07,  2.37it/s, Average Loss=0.295, Epoch=1]\u001b[A\n",
            "Train:   7%|▋         | 650/9200 [05:01<1:00:07,  2.37it/s, Average Loss=0.254, Epoch=1]\u001b[A\n",
            "Train:   7%|▋         | 660/9200 [05:05<59:52,  2.38it/s, Average Loss=0.254, Epoch=1]  \u001b[A\n",
            "Train:   7%|▋         | 660/9200 [05:06<59:52,  2.38it/s, Average Loss=0.253, Epoch=1]\u001b[A\n",
            "Train:   7%|▋         | 670/9200 [05:10<59:43,  2.38it/s, Average Loss=0.253, Epoch=1]\u001b[A\n",
            "Train:   7%|▋         | 670/9200 [05:10<59:43,  2.38it/s, Average Loss=0.298, Epoch=1]\u001b[A\n",
            "Train:   7%|▋         | 680/9200 [05:14<59:52,  2.37it/s, Average Loss=0.298, Epoch=1]\u001b[A\n",
            "Train:   7%|▋         | 680/9200 [05:14<59:52,  2.37it/s, Average Loss=0.278, Epoch=1]\u001b[A\n",
            "Train:   8%|▊         | 690/9200 [05:18<59:42,  2.38it/s, Average Loss=0.278, Epoch=1]\u001b[A\n",
            "Train:   8%|▊         | 690/9200 [05:18<59:42,  2.38it/s, Average Loss=0.218, Epoch=1]\u001b[A\n",
            "Train:   8%|▊         | 700/9200 [05:22<59:32,  2.38it/s, Average Loss=0.218, Epoch=1]\u001b[A\n",
            "Train:   8%|▊         | 700/9200 [05:22<59:32,  2.38it/s, Average Loss=0.262, Epoch=1]\u001b[A\n",
            "Train:   8%|▊         | 710/9200 [05:27<59:35,  2.37it/s, Average Loss=0.262, Epoch=1]\u001b[A\n",
            "Train:   8%|▊         | 710/9200 [05:27<59:35,  2.37it/s, Average Loss=0.218, Epoch=1]\u001b[A\n",
            "Train:   8%|▊         | 720/9200 [05:31<59:37,  2.37it/s, Average Loss=0.218, Epoch=1]\u001b[A\n",
            "Train:   8%|▊         | 720/9200 [05:31<59:37,  2.37it/s, Average Loss=0.17, Epoch=1] \u001b[A\n",
            "Train:   8%|▊         | 730/9200 [05:35<59:28,  2.37it/s, Average Loss=0.17, Epoch=1]\u001b[A\n",
            "Train:   8%|▊         | 730/9200 [05:35<59:28,  2.37it/s, Average Loss=0.249, Epoch=1]\u001b[A\n",
            "Train:   8%|▊         | 740/9200 [05:39<59:23,  2.37it/s, Average Loss=0.249, Epoch=1]\u001b[A\n",
            "Train:   8%|▊         | 740/9200 [05:39<59:23,  2.37it/s, Average Loss=0.223, Epoch=1]\u001b[A\n",
            "Train:   8%|▊         | 750/9200 [05:43<59:30,  2.37it/s, Average Loss=0.223, Epoch=1]\u001b[A\n",
            "Train:   8%|▊         | 750/9200 [05:43<59:30,  2.37it/s, Average Loss=0.25, Epoch=1] \u001b[A\n",
            "Train:   8%|▊         | 760/9200 [05:48<59:18,  2.37it/s, Average Loss=0.25, Epoch=1]\u001b[A\n",
            "Train:   8%|▊         | 760/9200 [05:48<59:18,  2.37it/s, Average Loss=0.214, Epoch=1]\u001b[A\n",
            "Train:   8%|▊         | 770/9200 [05:52<59:08,  2.38it/s, Average Loss=0.214, Epoch=1]\u001b[A\n",
            "Train:   8%|▊         | 770/9200 [05:52<59:08,  2.38it/s, Average Loss=0.166, Epoch=1]\u001b[A\n",
            "Train:   8%|▊         | 780/9200 [05:56<59:12,  2.37it/s, Average Loss=0.166, Epoch=1]\u001b[A\n",
            "Train:   8%|▊         | 780/9200 [05:56<59:12,  2.37it/s, Average Loss=0.149, Epoch=1]\u001b[A\n",
            "Train:   9%|▊         | 790/9200 [06:00<59:13,  2.37it/s, Average Loss=0.149, Epoch=1]\u001b[A\n",
            "Train:   9%|▊         | 790/9200 [06:00<59:13,  2.37it/s, Average Loss=0.188, Epoch=1]\u001b[A\n",
            "Train:   9%|▊         | 800/9200 [06:05<59:01,  2.37it/s, Average Loss=0.188, Epoch=1]\u001b[A\n",
            "Train:   9%|▊         | 800/9200 [06:05<59:01,  2.37it/s, Average Loss=0.231, Epoch=1]\u001b[A\n",
            "Train:   9%|▉         | 810/9200 [06:09<58:52,  2.38it/s, Average Loss=0.231, Epoch=1]\u001b[A\n",
            "Train:   9%|▉         | 810/9200 [06:09<58:52,  2.38it/s, Average Loss=0.218, Epoch=1]\u001b[A\n",
            "Train:   9%|▉         | 820/9200 [06:13<58:57,  2.37it/s, Average Loss=0.218, Epoch=1]\u001b[A\n",
            "Train:   9%|▉         | 820/9200 [06:13<58:57,  2.37it/s, Average Loss=0.166, Epoch=1]\u001b[A\n",
            "Train:   9%|▉         | 830/9200 [06:17<58:48,  2.37it/s, Average Loss=0.166, Epoch=1]\u001b[A\n",
            "Train:   9%|▉         | 830/9200 [06:17<58:48,  2.37it/s, Average Loss=0.257, Epoch=1]\u001b[A\n",
            "Train:   9%|▉         | 840/9200 [06:21<58:37,  2.38it/s, Average Loss=0.257, Epoch=1]\u001b[A\n",
            "Train:   9%|▉         | 840/9200 [06:21<58:37,  2.38it/s, Average Loss=0.253, Epoch=1]\u001b[A\n",
            "Train:   9%|▉         | 850/9200 [06:26<58:33,  2.38it/s, Average Loss=0.253, Epoch=1]\u001b[A\n",
            "Train:   9%|▉         | 850/9200 [06:26<58:33,  2.38it/s, Average Loss=0.212, Epoch=1]\u001b[A\n",
            "Train:   9%|▉         | 860/9200 [06:30<58:34,  2.37it/s, Average Loss=0.212, Epoch=1]\u001b[A\n",
            "Train:   9%|▉         | 860/9200 [06:30<58:34,  2.37it/s, Average Loss=0.137, Epoch=1]\u001b[A\n",
            "Train:   9%|▉         | 870/9200 [06:34<58:21,  2.38it/s, Average Loss=0.137, Epoch=1]\u001b[A\n",
            "Train:   9%|▉         | 870/9200 [06:34<58:21,  2.38it/s, Average Loss=0.151, Epoch=1]\u001b[A\n",
            "Train:  10%|▉         | 880/9200 [06:38<58:12,  2.38it/s, Average Loss=0.151, Epoch=1]\u001b[A\n",
            "Train:  10%|▉         | 880/9200 [06:38<58:12,  2.38it/s, Average Loss=0.186, Epoch=1]\u001b[A\n",
            "Train:  10%|▉         | 890/9200 [06:42<58:11,  2.38it/s, Average Loss=0.186, Epoch=1]\u001b[A\n",
            "Train:  10%|▉         | 890/9200 [06:42<58:11,  2.38it/s, Average Loss=0.118, Epoch=1]\u001b[A\n",
            "Train:  10%|▉         | 900/9200 [06:47<58:17,  2.37it/s, Average Loss=0.118, Epoch=1]\u001b[A\n",
            "Train:  10%|▉         | 900/9200 [06:47<58:17,  2.37it/s, Average Loss=0.146, Epoch=1]\u001b[A\n",
            "Train:  10%|▉         | 910/9200 [06:51<58:15,  2.37it/s, Average Loss=0.146, Epoch=1]\u001b[A\n",
            "Train:  10%|▉         | 910/9200 [06:51<58:15,  2.37it/s, Average Loss=0.168, Epoch=1]\u001b[A\n",
            "Train:  10%|█         | 920/9200 [06:55<57:49,  2.39it/s, Average Loss=0.168, Epoch=1]\u001b[A\n",
            "Train:  10%|█         | 920/9200 [06:55<57:49,  2.39it/s, Average Loss=0.11, Epoch=1] \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: [Epoch: 1, Macro F1: 0.5892647412382591, Validation Loss: 0.3378231091164919, Time per Epoch: 203.30493450164795]\n",
            "Begin Epoch 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Train:  10%|█         | 930/9200 [07:13<1:56:57,  1.18it/s, Average Loss=0.11, Epoch=1]\u001b[A\n",
            "Train:  10%|█         | 930/9200 [07:13<1:56:57,  1.18it/s, Average Loss=0.136, Epoch=2]\u001b[A\n",
            "Train:  10%|█         | 940/9200 [07:18<1:39:04,  1.39it/s, Average Loss=0.136, Epoch=2]\u001b[A\n",
            "Train:  10%|█         | 940/9200 [07:18<1:39:04,  1.39it/s, Average Loss=0.0499, Epoch=2]\u001b[A\n",
            "Train:  10%|█         | 950/9200 [07:22<1:26:29,  1.59it/s, Average Loss=0.0499, Epoch=2]\u001b[A\n",
            "Train:  10%|█         | 950/9200 [07:22<1:26:29,  1.59it/s, Average Loss=0.0978, Epoch=2]\u001b[A\n",
            "Train:  10%|█         | 960/9200 [07:26<1:17:51,  1.76it/s, Average Loss=0.0978, Epoch=2]\u001b[A\n",
            "Train:  10%|█         | 960/9200 [07:26<1:17:51,  1.76it/s, Average Loss=0.0475, Epoch=2]\u001b[A\n",
            "Train:  11%|█         | 970/9200 [07:30<1:12:00,  1.90it/s, Average Loss=0.0475, Epoch=2]\u001b[A\n",
            "Train:  11%|█         | 970/9200 [07:30<1:12:00,  1.90it/s, Average Loss=0.139, Epoch=2] \u001b[A\n",
            "Train:  11%|█         | 980/9200 [07:35<1:07:48,  2.02it/s, Average Loss=0.139, Epoch=2]\u001b[A\n",
            "Train:  11%|█         | 980/9200 [07:35<1:07:48,  2.02it/s, Average Loss=0.107, Epoch=2]\u001b[A\n",
            "Train:  11%|█         | 990/9200 [07:39<1:04:51,  2.11it/s, Average Loss=0.107, Epoch=2]\u001b[A\n",
            "Train:  11%|█         | 990/9200 [07:39<1:04:51,  2.11it/s, Average Loss=0.122, Epoch=2]\u001b[A\n",
            "Train:  11%|█         | 1000/9200 [07:43<1:02:57,  2.17it/s, Average Loss=0.122, Epoch=2]\u001b[A\n",
            "Train:  11%|█         | 1000/9200 [07:43<1:02:57,  2.17it/s, Average Loss=0.134, Epoch=2]\u001b[A\n",
            "Train:  11%|█         | 1010/9200 [07:47<1:01:22,  2.22it/s, Average Loss=0.134, Epoch=2]\u001b[A\n",
            "Train:  11%|█         | 1010/9200 [07:47<1:01:22,  2.22it/s, Average Loss=0.0767, Epoch=2]\u001b[A\n",
            "Train:  11%|█         | 1020/9200 [07:52<1:00:08,  2.27it/s, Average Loss=0.0767, Epoch=2]\u001b[A\n",
            "Train:  11%|█         | 1020/9200 [07:52<1:00:08,  2.27it/s, Average Loss=0.128, Epoch=2] \u001b[A\n",
            "Train:  11%|█         | 1030/9200 [07:56<59:17,  2.30it/s, Average Loss=0.128, Epoch=2]  \u001b[A\n",
            "Train:  11%|█         | 1030/9200 [07:56<59:17,  2.30it/s, Average Loss=0.122, Epoch=2]\u001b[A\n",
            "Train:  11%|█▏        | 1040/9200 [08:00<58:45,  2.31it/s, Average Loss=0.122, Epoch=2]\u001b[A\n",
            "Train:  11%|█▏        | 1040/9200 [08:00<58:45,  2.31it/s, Average Loss=0.133, Epoch=2]\u001b[A\n",
            "Train:  11%|█▏        | 1050/9200 [08:04<58:07,  2.34it/s, Average Loss=0.133, Epoch=2]\u001b[A\n",
            "Train:  11%|█▏        | 1050/9200 [08:04<58:07,  2.34it/s, Average Loss=0.0596, Epoch=2]\u001b[A\n",
            "Train:  12%|█▏        | 1060/9200 [08:08<57:37,  2.35it/s, Average Loss=0.0596, Epoch=2]\u001b[A\n",
            "Train:  12%|█▏        | 1060/9200 [08:08<57:37,  2.35it/s, Average Loss=0.104, Epoch=2] \u001b[A\n",
            "Train:  12%|█▏        | 1070/9200 [08:13<57:23,  2.36it/s, Average Loss=0.104, Epoch=2]\u001b[A\n",
            "Train:  12%|█▏        | 1070/9200 [08:13<57:23,  2.36it/s, Average Loss=0.136, Epoch=2]\u001b[A\n",
            "Train:  12%|█▏        | 1080/9200 [08:17<57:11,  2.37it/s, Average Loss=0.136, Epoch=2]\u001b[A\n",
            "Train:  12%|█▏        | 1080/9200 [08:17<57:11,  2.37it/s, Average Loss=0.11, Epoch=2] \u001b[A\n",
            "Train:  12%|█▏        | 1090/9200 [08:21<56:54,  2.38it/s, Average Loss=0.11, Epoch=2]\u001b[A\n",
            "Train:  12%|█▏        | 1090/9200 [08:21<56:54,  2.38it/s, Average Loss=0.0973, Epoch=2]\u001b[A\n",
            "Train:  12%|█▏        | 1100/9200 [08:25<56:41,  2.38it/s, Average Loss=0.0973, Epoch=2]\u001b[A\n",
            "Train:  12%|█▏        | 1100/9200 [08:25<56:41,  2.38it/s, Average Loss=0.101, Epoch=2] \u001b[A\n",
            "Train:  12%|█▏        | 1110/9200 [08:29<56:48,  2.37it/s, Average Loss=0.101, Epoch=2]\u001b[A\n",
            "Train:  12%|█▏        | 1110/9200 [08:29<56:48,  2.37it/s, Average Loss=0.0882, Epoch=2]\u001b[A\n",
            "Train:  12%|█▏        | 1120/9200 [08:34<56:37,  2.38it/s, Average Loss=0.0882, Epoch=2]\u001b[A\n",
            "Train:  12%|█▏        | 1120/9200 [08:34<56:37,  2.38it/s, Average Loss=0.0998, Epoch=2]\u001b[A\n",
            "Train:  12%|█▏        | 1130/9200 [08:38<56:27,  2.38it/s, Average Loss=0.0998, Epoch=2]\u001b[A\n",
            "Train:  12%|█▏        | 1130/9200 [08:38<56:27,  2.38it/s, Average Loss=0.0411, Epoch=2]\u001b[A\n",
            "Train:  12%|█▏        | 1140/9200 [08:42<56:30,  2.38it/s, Average Loss=0.0411, Epoch=2]\u001b[A\n",
            "Train:  12%|█▏        | 1140/9200 [08:42<56:30,  2.38it/s, Average Loss=0.102, Epoch=2] \u001b[A\n",
            "Train:  12%|█▎        | 1150/9200 [08:46<56:30,  2.37it/s, Average Loss=0.102, Epoch=2]\u001b[A\n",
            "Train:  12%|█▎        | 1150/9200 [08:46<56:30,  2.37it/s, Average Loss=0.0625, Epoch=2]\u001b[A\n",
            "Train:  13%|█▎        | 1160/9200 [08:50<56:21,  2.38it/s, Average Loss=0.0625, Epoch=2]\u001b[A\n",
            "Train:  13%|█▎        | 1160/9200 [08:50<56:21,  2.38it/s, Average Loss=0.121, Epoch=2] \u001b[A\n",
            "Train:  13%|█▎        | 1170/9200 [08:55<56:14,  2.38it/s, Average Loss=0.121, Epoch=2]\u001b[A\n",
            "Train:  13%|█▎        | 1170/9200 [08:55<56:14,  2.38it/s, Average Loss=0.0552, Epoch=2]\u001b[A\n",
            "Train:  13%|█▎        | 1180/9200 [08:59<56:24,  2.37it/s, Average Loss=0.0552, Epoch=2]\u001b[A\n",
            "Train:  13%|█▎        | 1180/9200 [08:59<56:24,  2.37it/s, Average Loss=0.127, Epoch=2] \u001b[A\n",
            "Train:  13%|█▎        | 1190/9200 [09:03<56:21,  2.37it/s, Average Loss=0.127, Epoch=2]\u001b[A\n",
            "Train:  13%|█▎        | 1190/9200 [09:03<56:21,  2.37it/s, Average Loss=0.0627, Epoch=2]\u001b[A\n",
            "Train:  13%|█▎        | 1200/9200 [09:07<56:12,  2.37it/s, Average Loss=0.0627, Epoch=2]\u001b[A\n",
            "Train:  13%|█▎        | 1200/9200 [09:07<56:12,  2.37it/s, Average Loss=0.0429, Epoch=2]\u001b[A\n",
            "Train:  13%|█▎        | 1210/9200 [09:12<56:09,  2.37it/s, Average Loss=0.0429, Epoch=2]\u001b[A\n",
            "Train:  13%|█▎        | 1210/9200 [09:12<56:09,  2.37it/s, Average Loss=0.0684, Epoch=2]\u001b[A\n",
            "Train:  13%|█▎        | 1220/9200 [09:16<56:12,  2.37it/s, Average Loss=0.0684, Epoch=2]\u001b[A\n",
            "Train:  13%|█▎        | 1220/9200 [09:16<56:12,  2.37it/s, Average Loss=0.146, Epoch=2] \u001b[A\n",
            "Train:  13%|█▎        | 1230/9200 [09:20<56:01,  2.37it/s, Average Loss=0.146, Epoch=2]\u001b[A\n",
            "Train:  13%|█▎        | 1230/9200 [09:20<56:01,  2.37it/s, Average Loss=0.0467, Epoch=2]\u001b[A\n",
            "Train:  13%|█▎        | 1240/9200 [09:24<55:51,  2.38it/s, Average Loss=0.0467, Epoch=2]\u001b[A\n",
            "Train:  13%|█▎        | 1240/9200 [09:24<55:51,  2.38it/s, Average Loss=0.0595, Epoch=2]\u001b[A\n",
            "Train:  14%|█▎        | 1250/9200 [09:28<55:52,  2.37it/s, Average Loss=0.0595, Epoch=2]\u001b[A\n",
            "Train:  14%|█▎        | 1250/9200 [09:28<55:52,  2.37it/s, Average Loss=0.0654, Epoch=2]\u001b[A\n",
            "Train:  14%|█▎        | 1260/9200 [09:33<55:48,  2.37it/s, Average Loss=0.0654, Epoch=2]\u001b[A\n",
            "Train:  14%|█▎        | 1260/9200 [09:33<55:48,  2.37it/s, Average Loss=0.048, Epoch=2] \u001b[A\n",
            "Train:  14%|█▍        | 1270/9200 [09:37<55:36,  2.38it/s, Average Loss=0.048, Epoch=2]\u001b[A\n",
            "Train:  14%|█▍        | 1270/9200 [09:37<55:36,  2.38it/s, Average Loss=0.0776, Epoch=2]\u001b[A\n",
            "Train:  14%|█▍        | 1280/9200 [09:41<55:30,  2.38it/s, Average Loss=0.0776, Epoch=2]\u001b[A\n",
            "Train:  14%|█▍        | 1280/9200 [09:41<55:30,  2.38it/s, Average Loss=0.121, Epoch=2] \u001b[A\n",
            "Train:  14%|█▍        | 1290/9200 [09:45<55:35,  2.37it/s, Average Loss=0.121, Epoch=2]\u001b[A\n",
            "Train:  14%|█▍        | 1290/9200 [09:45<55:35,  2.37it/s, Average Loss=0.0943, Epoch=2]\u001b[A\n",
            "Train:  14%|█▍        | 1300/9200 [09:49<55:23,  2.38it/s, Average Loss=0.0943, Epoch=2]\u001b[A\n",
            "Train:  14%|█▍        | 1300/9200 [09:49<55:23,  2.38it/s, Average Loss=0.104, Epoch=2] \u001b[A\n",
            "Train:  14%|█▍        | 1310/9200 [09:54<55:15,  2.38it/s, Average Loss=0.104, Epoch=2]\u001b[A\n",
            "Train:  14%|█▍        | 1310/9200 [09:54<55:15,  2.38it/s, Average Loss=0.0933, Epoch=2]\u001b[A\n",
            "Train:  14%|█▍        | 1320/9200 [09:58<55:15,  2.38it/s, Average Loss=0.0933, Epoch=2]\u001b[A\n",
            "Train:  14%|█▍        | 1320/9200 [09:58<55:15,  2.38it/s, Average Loss=0.0581, Epoch=2]\u001b[A\n",
            "Train:  14%|█▍        | 1330/9200 [10:02<55:10,  2.38it/s, Average Loss=0.0581, Epoch=2]\u001b[A\n",
            "Train:  14%|█▍        | 1330/9200 [10:02<55:10,  2.38it/s, Average Loss=0.12, Epoch=2]  \u001b[A\n",
            "Train:  15%|█▍        | 1340/9200 [10:06<55:02,  2.38it/s, Average Loss=0.12, Epoch=2]\u001b[A\n",
            "Train:  15%|█▍        | 1340/9200 [10:06<55:02,  2.38it/s, Average Loss=0.103, Epoch=2]\u001b[A\n",
            "Train:  15%|█▍        | 1350/9200 [10:10<54:55,  2.38it/s, Average Loss=0.103, Epoch=2]\u001b[A\n",
            "Train:  15%|█▍        | 1350/9200 [10:10<54:55,  2.38it/s, Average Loss=0.137, Epoch=2]\u001b[A\n",
            "Train:  15%|█▍        | 1360/9200 [10:15<54:58,  2.38it/s, Average Loss=0.137, Epoch=2]\u001b[A\n",
            "Train:  15%|█▍        | 1360/9200 [10:15<54:58,  2.38it/s, Average Loss=0.0518, Epoch=2]\u001b[A\n",
            "Train:  15%|█▍        | 1370/9200 [10:19<54:49,  2.38it/s, Average Loss=0.0518, Epoch=2]\u001b[A\n",
            "Train:  15%|█▍        | 1370/9200 [10:19<54:49,  2.38it/s, Average Loss=0.131, Epoch=2] \u001b[A\n",
            "Train:  15%|█▌        | 1380/9200 [10:23<54:24,  2.40it/s, Average Loss=0.131, Epoch=2]\u001b[A\n",
            "Train:  15%|█▌        | 1380/9200 [10:23<54:24,  2.40it/s, Average Loss=0.0833, Epoch=2]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: [Epoch: 2, Macro F1: 0.5932731056828074, Validation Loss: 0.3784156855802203, Time per Epoch: 203.34395742416382]\n",
            "Begin Epoch 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Train:  15%|█▌        | 1390/9200 [10:42<1:50:39,  1.18it/s, Average Loss=0.0833, Epoch=2]\u001b[A\n",
            "Train:  15%|█▌        | 1390/9200 [10:42<1:50:39,  1.18it/s, Average Loss=0.0689, Epoch=3]\u001b[A\n",
            "Train:  15%|█▌        | 1400/9200 [10:46<1:33:50,  1.39it/s, Average Loss=0.0689, Epoch=3]\u001b[A\n",
            "Train:  15%|█▌        | 1400/9200 [10:46<1:33:50,  1.39it/s, Average Loss=0.0307, Epoch=3]\u001b[A\n",
            "Train:  15%|█▌        | 1410/9200 [10:50<1:21:53,  1.59it/s, Average Loss=0.0307, Epoch=3]\u001b[A\n",
            "Train:  15%|█▌        | 1410/9200 [10:50<1:21:53,  1.59it/s, Average Loss=0.0195, Epoch=3]\u001b[A\n",
            "Train:  15%|█▌        | 1420/9200 [10:54<1:13:37,  1.76it/s, Average Loss=0.0195, Epoch=3]\u001b[A\n",
            "Train:  15%|█▌        | 1420/9200 [10:54<1:13:37,  1.76it/s, Average Loss=0.0238, Epoch=3]\u001b[A\n",
            "Train:  16%|█▌        | 1430/9200 [10:58<1:08:05,  1.90it/s, Average Loss=0.0238, Epoch=3]\u001b[A\n",
            "Train:  16%|█▌        | 1430/9200 [10:58<1:08:05,  1.90it/s, Average Loss=0.0388, Epoch=3]\u001b[A\n",
            "Train:  16%|█▌        | 1440/9200 [11:03<1:04:15,  2.01it/s, Average Loss=0.0388, Epoch=3]\u001b[A\n",
            "Train:  16%|█▌        | 1440/9200 [11:03<1:04:15,  2.01it/s, Average Loss=0.0568, Epoch=3]\u001b[A\n",
            "Train:  16%|█▌        | 1450/9200 [11:07<1:01:24,  2.10it/s, Average Loss=0.0568, Epoch=3]\u001b[A\n",
            "Train:  16%|█▌        | 1450/9200 [11:07<1:01:24,  2.10it/s, Average Loss=0.0435, Epoch=3]\u001b[A\n",
            "Train:  16%|█▌        | 1460/9200 [11:11<59:24,  2.17it/s, Average Loss=0.0435, Epoch=3]  \u001b[A\n",
            "Train:  16%|█▌        | 1460/9200 [11:11<59:24,  2.17it/s, Average Loss=0.0819, Epoch=3]\u001b[A\n",
            "Train:  16%|█▌        | 1470/9200 [11:15<58:01,  2.22it/s, Average Loss=0.0819, Epoch=3]\u001b[A\n",
            "Train:  16%|█▌        | 1470/9200 [11:16<58:01,  2.22it/s, Average Loss=0.0391, Epoch=3]\u001b[A\n",
            "Train:  16%|█▌        | 1480/9200 [11:20<56:43,  2.27it/s, Average Loss=0.0391, Epoch=3]\u001b[A\n",
            "Train:  16%|█▌        | 1480/9200 [11:20<56:43,  2.27it/s, Average Loss=0.0694, Epoch=3]\u001b[A\n",
            "Train:  16%|█▌        | 1490/9200 [11:24<55:47,  2.30it/s, Average Loss=0.0694, Epoch=3]\u001b[A\n",
            "Train:  16%|█▌        | 1490/9200 [11:24<55:47,  2.30it/s, Average Loss=0.0359, Epoch=3]\u001b[A\n",
            "Train:  16%|█▋        | 1500/9200 [11:28<55:17,  2.32it/s, Average Loss=0.0359, Epoch=3]\u001b[A\n",
            "Train:  16%|█▋        | 1500/9200 [11:28<55:17,  2.32it/s, Average Loss=0.0214, Epoch=3]\u001b[A\n",
            "Train:  16%|█▋        | 1510/9200 [11:32<54:50,  2.34it/s, Average Loss=0.0214, Epoch=3]\u001b[A\n",
            "Train:  16%|█▋        | 1510/9200 [11:32<54:50,  2.34it/s, Average Loss=0.0437, Epoch=3]\u001b[A\n",
            "Train:  17%|█▋        | 1520/9200 [11:36<54:22,  2.35it/s, Average Loss=0.0437, Epoch=3]\u001b[A\n",
            "Train:  17%|█▋        | 1520/9200 [11:36<54:22,  2.35it/s, Average Loss=0.0407, Epoch=3]\u001b[A\n",
            "Train:  17%|█▋        | 1530/9200 [11:41<54:00,  2.37it/s, Average Loss=0.0407, Epoch=3]\u001b[A\n",
            "Train:  17%|█▋        | 1530/9200 [11:41<54:00,  2.37it/s, Average Loss=0.0404, Epoch=3]\u001b[A\n",
            "Train:  17%|█▋        | 1540/9200 [11:45<53:58,  2.36it/s, Average Loss=0.0404, Epoch=3]\u001b[A\n",
            "Train:  17%|█▋        | 1540/9200 [11:45<53:58,  2.36it/s, Average Loss=0.0781, Epoch=3]\u001b[A\n",
            "Train:  17%|█▋        | 1550/9200 [11:49<53:41,  2.37it/s, Average Loss=0.0781, Epoch=3]\u001b[A\n",
            "Train:  17%|█▋        | 1550/9200 [11:49<53:41,  2.37it/s, Average Loss=0.04, Epoch=3]  \u001b[A\n",
            "Train:  17%|█▋        | 1560/9200 [11:53<53:31,  2.38it/s, Average Loss=0.04, Epoch=3]\u001b[A\n",
            "Train:  17%|█▋        | 1560/9200 [11:53<53:31,  2.38it/s, Average Loss=0.068, Epoch=3]\u001b[A\n",
            "Train:  17%|█▋        | 1570/9200 [11:57<53:31,  2.38it/s, Average Loss=0.068, Epoch=3]\u001b[A\n",
            "Train:  17%|█▋        | 1570/9200 [11:57<53:31,  2.38it/s, Average Loss=0.0434, Epoch=3]\u001b[A\n",
            "Train:  17%|█▋        | 1580/9200 [12:02<53:34,  2.37it/s, Average Loss=0.0434, Epoch=3]\u001b[A\n",
            "Train:  17%|█▋        | 1580/9200 [12:02<53:34,  2.37it/s, Average Loss=0.0367, Epoch=3]\u001b[A\n",
            "Train:  17%|█▋        | 1590/9200 [12:06<53:27,  2.37it/s, Average Loss=0.0367, Epoch=3]\u001b[A\n",
            "Train:  17%|█▋        | 1590/9200 [12:06<53:27,  2.37it/s, Average Loss=0.0286, Epoch=3]\u001b[A\n",
            "Train:  17%|█▋        | 1600/9200 [12:10<53:19,  2.38it/s, Average Loss=0.0286, Epoch=3]\u001b[A\n",
            "Train:  17%|█▋        | 1600/9200 [12:10<53:19,  2.38it/s, Average Loss=0.0208, Epoch=3]\u001b[A\n",
            "Train:  18%|█▊        | 1610/9200 [12:14<53:23,  2.37it/s, Average Loss=0.0208, Epoch=3]\u001b[A\n",
            "Train:  18%|█▊        | 1610/9200 [12:14<53:23,  2.37it/s, Average Loss=0.0108, Epoch=3]\u001b[A\n",
            "Train:  18%|█▊        | 1620/9200 [12:19<53:16,  2.37it/s, Average Loss=0.0108, Epoch=3]\u001b[A\n",
            "Train:  18%|█▊        | 1620/9200 [12:19<53:16,  2.37it/s, Average Loss=0.0273, Epoch=3]\u001b[A\n",
            "Train:  18%|█▊        | 1630/9200 [12:23<53:07,  2.38it/s, Average Loss=0.0273, Epoch=3]\u001b[A\n",
            "Train:  18%|█▊        | 1630/9200 [12:23<53:07,  2.38it/s, Average Loss=0.0507, Epoch=3]\u001b[A\n",
            "Train:  18%|█▊        | 1640/9200 [12:27<53:06,  2.37it/s, Average Loss=0.0507, Epoch=3]\u001b[A\n",
            "Train:  18%|█▊        | 1640/9200 [12:27<53:06,  2.37it/s, Average Loss=0.116, Epoch=3] \u001b[A\n",
            "Train:  18%|█▊        | 1650/9200 [12:31<53:08,  2.37it/s, Average Loss=0.116, Epoch=3]\u001b[A\n",
            "Train:  18%|█▊        | 1650/9200 [12:31<53:08,  2.37it/s, Average Loss=0.0189, Epoch=3]\u001b[A\n",
            "Train:  18%|█▊        | 1660/9200 [12:35<52:56,  2.37it/s, Average Loss=0.0189, Epoch=3]\u001b[A\n",
            "Train:  18%|█▊        | 1660/9200 [12:35<52:56,  2.37it/s, Average Loss=0.0466, Epoch=3]\u001b[A\n",
            "Train:  18%|█▊        | 1670/9200 [12:40<52:46,  2.38it/s, Average Loss=0.0466, Epoch=3]\u001b[A\n",
            "Train:  18%|█▊        | 1670/9200 [12:40<52:46,  2.38it/s, Average Loss=0.0599, Epoch=3]\u001b[A\n",
            "Train:  18%|█▊        | 1680/9200 [12:44<52:48,  2.37it/s, Average Loss=0.0599, Epoch=3]\u001b[A\n",
            "Train:  18%|█▊        | 1680/9200 [12:44<52:48,  2.37it/s, Average Loss=0.0427, Epoch=3]\u001b[A\n",
            "Train:  18%|█▊        | 1690/9200 [12:48<52:46,  2.37it/s, Average Loss=0.0427, Epoch=3]\u001b[A\n",
            "Train:  18%|█▊        | 1690/9200 [12:48<52:46,  2.37it/s, Average Loss=0.0117, Epoch=3]\u001b[A\n",
            "Train:  18%|█▊        | 1700/9200 [12:52<52:34,  2.38it/s, Average Loss=0.0117, Epoch=3]\u001b[A\n",
            "Train:  18%|█▊        | 1700/9200 [12:52<52:34,  2.38it/s, Average Loss=0.096, Epoch=3] \u001b[A\n",
            "Train:  19%|█▊        | 1710/9200 [12:56<52:28,  2.38it/s, Average Loss=0.096, Epoch=3]\u001b[A\n",
            "Train:  19%|█▊        | 1710/9200 [12:56<52:28,  2.38it/s, Average Loss=0.111, Epoch=3]\u001b[A\n",
            "Train:  19%|█▊        | 1720/9200 [13:01<52:31,  2.37it/s, Average Loss=0.111, Epoch=3]\u001b[A\n",
            "Train:  19%|█▊        | 1720/9200 [13:01<52:31,  2.37it/s, Average Loss=0.00762, Epoch=3]\u001b[A\n",
            "Train:  19%|█▉        | 1730/9200 [13:05<52:19,  2.38it/s, Average Loss=0.00762, Epoch=3]\u001b[A\n",
            "Train:  19%|█▉        | 1730/9200 [13:05<52:19,  2.38it/s, Average Loss=0.0384, Epoch=3] \u001b[A\n",
            "Train:  19%|█▉        | 1740/9200 [13:09<52:11,  2.38it/s, Average Loss=0.0384, Epoch=3]\u001b[A\n",
            "Train:  19%|█▉        | 1740/9200 [13:09<52:11,  2.38it/s, Average Loss=0.00189, Epoch=3]\u001b[A\n",
            "Train:  19%|█▉        | 1750/9200 [13:13<52:09,  2.38it/s, Average Loss=0.00189, Epoch=3]\u001b[A\n",
            "Train:  19%|█▉        | 1750/9200 [13:13<52:09,  2.38it/s, Average Loss=0.0214, Epoch=3] \u001b[A\n",
            "Train:  19%|█▉        | 1760/9200 [13:17<52:07,  2.38it/s, Average Loss=0.0214, Epoch=3]\u001b[A\n",
            "Train:  19%|█▉        | 1760/9200 [13:17<52:07,  2.38it/s, Average Loss=0.0245, Epoch=3]\u001b[A\n",
            "Train:  19%|█▉        | 1770/9200 [13:22<51:58,  2.38it/s, Average Loss=0.0245, Epoch=3]\u001b[A\n",
            "Train:  19%|█▉        | 1770/9200 [13:22<51:58,  2.38it/s, Average Loss=0.0388, Epoch=3]\u001b[A\n",
            "Train:  19%|█▉        | 1780/9200 [13:26<51:52,  2.38it/s, Average Loss=0.0388, Epoch=3]\u001b[A\n",
            "Train:  19%|█▉        | 1780/9200 [13:26<51:52,  2.38it/s, Average Loss=0.0682, Epoch=3]\u001b[A\n",
            "Train:  19%|█▉        | 1790/9200 [13:30<52:00,  2.37it/s, Average Loss=0.0682, Epoch=3]\u001b[A\n",
            "Train:  19%|█▉        | 1790/9200 [13:30<52:00,  2.37it/s, Average Loss=0.0379, Epoch=3]\u001b[A\n",
            "Train:  20%|█▉        | 1800/9200 [13:34<51:50,  2.38it/s, Average Loss=0.0379, Epoch=3]\u001b[A\n",
            "Train:  20%|█▉        | 1800/9200 [13:34<51:50,  2.38it/s, Average Loss=0.00556, Epoch=3]\u001b[A\n",
            "Train:  20%|█▉        | 1810/9200 [13:38<51:41,  2.38it/s, Average Loss=0.00556, Epoch=3]\u001b[A\n",
            "Train:  20%|█▉        | 1810/9200 [13:38<51:41,  2.38it/s, Average Loss=0.026, Epoch=3]  \u001b[A\n",
            "Train:  20%|█▉        | 1820/9200 [13:43<51:42,  2.38it/s, Average Loss=0.026, Epoch=3]\u001b[A\n",
            "Train:  20%|█▉        | 1820/9200 [13:43<51:42,  2.38it/s, Average Loss=0.0175, Epoch=3]\u001b[A\n",
            "Train:  20%|█▉        | 1830/9200 [13:47<51:44,  2.37it/s, Average Loss=0.0175, Epoch=3]\u001b[A\n",
            "Train:  20%|█▉        | 1830/9200 [13:47<51:44,  2.37it/s, Average Loss=0.0287, Epoch=3]\u001b[A\n",
            "Train:  20%|██        | 1840/9200 [13:51<51:17,  2.39it/s, Average Loss=0.0287, Epoch=3]\u001b[A\n",
            "Train:  20%|██        | 1840/9200 [13:51<51:17,  2.39it/s, Average Loss=0.028, Epoch=3] \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: [Epoch: 3, Macro F1: 0.6268846321613085, Validation Loss: 0.47058769135985, Time per Epoch: 203.23832440376282]\n",
            "Begin Epoch 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Train:  20%|██        | 1850/9200 [14:09<1:43:42,  1.18it/s, Average Loss=0.028, Epoch=3]\u001b[A\n",
            "Train:  20%|██        | 1850/9200 [14:09<1:43:42,  1.18it/s, Average Loss=0.0128, Epoch=4]\u001b[A\n",
            "Train:  20%|██        | 1860/9200 [14:14<1:27:57,  1.39it/s, Average Loss=0.0128, Epoch=4]\u001b[A\n",
            "Train:  20%|██        | 1860/9200 [14:14<1:27:57,  1.39it/s, Average Loss=0.0487, Epoch=4]\u001b[A\n",
            "Train:  20%|██        | 1870/9200 [14:18<1:16:56,  1.59it/s, Average Loss=0.0487, Epoch=4]\u001b[A\n",
            "Train:  20%|██        | 1870/9200 [14:18<1:16:56,  1.59it/s, Average Loss=0.0272, Epoch=4]\u001b[A\n",
            "Train:  20%|██        | 1880/9200 [14:22<1:09:12,  1.76it/s, Average Loss=0.0272, Epoch=4]\u001b[A\n",
            "Train:  20%|██        | 1880/9200 [14:22<1:09:12,  1.76it/s, Average Loss=0.0203, Epoch=4]\u001b[A\n",
            "Train:  21%|██        | 1890/9200 [14:26<1:03:54,  1.91it/s, Average Loss=0.0203, Epoch=4]\u001b[A\n",
            "Train:  21%|██        | 1890/9200 [14:26<1:03:54,  1.91it/s, Average Loss=0.0421, Epoch=4]\u001b[A\n",
            "Train:  21%|██        | 1900/9200 [14:31<1:00:23,  2.01it/s, Average Loss=0.0421, Epoch=4]\u001b[A\n",
            "Train:  21%|██        | 1900/9200 [14:31<1:00:23,  2.01it/s, Average Loss=0.0554, Epoch=4]\u001b[A\n",
            "Train:  21%|██        | 1910/9200 [14:35<57:45,  2.10it/s, Average Loss=0.0554, Epoch=4]  \u001b[A\n",
            "Train:  21%|██        | 1910/9200 [14:35<57:45,  2.10it/s, Average Loss=0.00167, Epoch=4]\u001b[A\n",
            "Train:  21%|██        | 1920/9200 [14:39<55:44,  2.18it/s, Average Loss=0.00167, Epoch=4]\u001b[A\n",
            "Train:  21%|██        | 1920/9200 [14:39<55:44,  2.18it/s, Average Loss=0.0277, Epoch=4] \u001b[A\n",
            "Train:  21%|██        | 1930/9200 [14:43<54:22,  2.23it/s, Average Loss=0.0277, Epoch=4]\u001b[A\n",
            "Train:  21%|██        | 1930/9200 [14:43<54:22,  2.23it/s, Average Loss=0.0134, Epoch=4]\u001b[A\n",
            "Train:  21%|██        | 1940/9200 [14:48<53:19,  2.27it/s, Average Loss=0.0134, Epoch=4]\u001b[A\n",
            "Train:  21%|██        | 1940/9200 [14:48<53:19,  2.27it/s, Average Loss=0.0155, Epoch=4]\u001b[A\n",
            "Train:  21%|██        | 1950/9200 [14:52<52:26,  2.30it/s, Average Loss=0.0155, Epoch=4]\u001b[A\n",
            "Train:  21%|██        | 1950/9200 [14:52<52:26,  2.30it/s, Average Loss=0.00412, Epoch=4]\u001b[A\n",
            "Train:  21%|██▏       | 1960/9200 [14:56<51:52,  2.33it/s, Average Loss=0.00412, Epoch=4]\u001b[A\n",
            "Train:  21%|██▏       | 1960/9200 [14:56<51:52,  2.33it/s, Average Loss=0.00805, Epoch=4]\u001b[A\n",
            "Train:  21%|██▏       | 1970/9200 [15:00<51:34,  2.34it/s, Average Loss=0.00805, Epoch=4]\u001b[A\n",
            "Train:  21%|██▏       | 1970/9200 [15:00<51:34,  2.34it/s, Average Loss=0.0183, Epoch=4] \u001b[A\n",
            "Train:  22%|██▏       | 1980/9200 [15:04<51:08,  2.35it/s, Average Loss=0.0183, Epoch=4]\u001b[A\n",
            "Train:  22%|██▏       | 1980/9200 [15:04<51:08,  2.35it/s, Average Loss=0.00911, Epoch=4]\u001b[A\n",
            "Train:  22%|██▏       | 1990/9200 [15:09<50:44,  2.37it/s, Average Loss=0.00911, Epoch=4]\u001b[A\n",
            "Train:  22%|██▏       | 1990/9200 [15:09<50:44,  2.37it/s, Average Loss=0.0165, Epoch=4] \u001b[A\n",
            "Train:  22%|██▏       | 2000/9200 [15:13<50:37,  2.37it/s, Average Loss=0.0165, Epoch=4]\u001b[A\n",
            "Train:  22%|██▏       | 2000/9200 [15:13<50:37,  2.37it/s, Average Loss=0.0188, Epoch=4]\u001b[A\n",
            "Train:  22%|██▏       | 2010/9200 [15:17<50:29,  2.37it/s, Average Loss=0.0188, Epoch=4]\u001b[A\n",
            "Train:  22%|██▏       | 2010/9200 [15:17<50:29,  2.37it/s, Average Loss=0.0154, Epoch=4]\u001b[A\n",
            "Train:  22%|██▏       | 2020/9200 [15:21<50:17,  2.38it/s, Average Loss=0.0154, Epoch=4]\u001b[A\n",
            "Train:  22%|██▏       | 2020/9200 [15:21<50:17,  2.38it/s, Average Loss=0.0126, Epoch=4]\u001b[A\n",
            "Train:  22%|██▏       | 2030/9200 [15:25<50:12,  2.38it/s, Average Loss=0.0126, Epoch=4]\u001b[A\n",
            "Train:  22%|██▏       | 2030/9200 [15:25<50:12,  2.38it/s, Average Loss=0.0156, Epoch=4]\u001b[A\n",
            "Train:  22%|██▏       | 2040/9200 [15:30<50:17,  2.37it/s, Average Loss=0.0156, Epoch=4]\u001b[A\n",
            "Train:  22%|██▏       | 2040/9200 [15:30<50:17,  2.37it/s, Average Loss=0.0152, Epoch=4]\u001b[A\n",
            "Train:  22%|██▏       | 2050/9200 [15:34<50:11,  2.37it/s, Average Loss=0.0152, Epoch=4]\u001b[A\n",
            "Train:  22%|██▏       | 2050/9200 [15:34<50:11,  2.37it/s, Average Loss=0.0248, Epoch=4]\u001b[A\n",
            "Train:  22%|██▏       | 2060/9200 [15:38<50:02,  2.38it/s, Average Loss=0.0248, Epoch=4]\u001b[A\n",
            "Train:  22%|██▏       | 2060/9200 [15:38<50:02,  2.38it/s, Average Loss=0.00023, Epoch=4]\u001b[A\n",
            "Train:  22%|██▎       | 2070/9200 [15:42<50:05,  2.37it/s, Average Loss=0.00023, Epoch=4]\u001b[A\n",
            "Train:  22%|██▎       | 2070/9200 [15:42<50:05,  2.37it/s, Average Loss=0.03, Epoch=4]   \u001b[A\n",
            "Train:  23%|██▎       | 2080/9200 [15:46<50:08,  2.37it/s, Average Loss=0.03, Epoch=4]\u001b[A\n",
            "Train:  23%|██▎       | 2080/9200 [15:46<50:08,  2.37it/s, Average Loss=0.0152, Epoch=4]\u001b[A\n",
            "Train:  23%|██▎       | 2090/9200 [15:51<50:00,  2.37it/s, Average Loss=0.0152, Epoch=4]\u001b[A\n",
            "Train:  23%|██▎       | 2090/9200 [15:51<50:00,  2.37it/s, Average Loss=0.0473, Epoch=4]\u001b[A\n",
            "Train:  23%|██▎       | 2100/9200 [15:55<49:54,  2.37it/s, Average Loss=0.0473, Epoch=4]\u001b[A\n",
            "Train:  23%|██▎       | 2100/9200 [15:55<49:54,  2.37it/s, Average Loss=0.0117, Epoch=4]\u001b[A\n",
            "Train:  23%|██▎       | 2110/9200 [15:59<49:57,  2.37it/s, Average Loss=0.0117, Epoch=4]\u001b[A\n",
            "Train:  23%|██▎       | 2110/9200 [15:59<49:57,  2.37it/s, Average Loss=0.0153, Epoch=4]\u001b[A\n",
            "Train:  23%|██▎       | 2120/9200 [16:03<49:53,  2.37it/s, Average Loss=0.0153, Epoch=4]\u001b[A\n",
            "Train:  23%|██▎       | 2120/9200 [16:03<49:53,  2.37it/s, Average Loss=0.0347, Epoch=4]\u001b[A\n",
            "Train:  23%|██▎       | 2130/9200 [16:08<49:41,  2.37it/s, Average Loss=0.0347, Epoch=4]\u001b[A\n",
            "Train:  23%|██▎       | 2130/9200 [16:08<49:41,  2.37it/s, Average Loss=0.0327, Epoch=4]\u001b[A\n",
            "Train:  23%|██▎       | 2140/9200 [16:12<49:36,  2.37it/s, Average Loss=0.0327, Epoch=4]\u001b[A\n",
            "Train:  23%|██▎       | 2140/9200 [16:12<49:36,  2.37it/s, Average Loss=0.0371, Epoch=4]\u001b[A\n",
            "Train:  23%|██▎       | 2150/9200 [16:16<49:36,  2.37it/s, Average Loss=0.0371, Epoch=4]\u001b[A\n",
            "Train:  23%|██▎       | 2150/9200 [16:16<49:36,  2.37it/s, Average Loss=0.00674, Epoch=4]\u001b[A\n",
            "Train:  23%|██▎       | 2160/9200 [16:20<49:26,  2.37it/s, Average Loss=0.00674, Epoch=4]\u001b[A\n",
            "Train:  23%|██▎       | 2160/9200 [16:20<49:26,  2.37it/s, Average Loss=0.0121, Epoch=4] \u001b[A\n",
            "Train:  24%|██▎       | 2170/9200 [16:24<49:16,  2.38it/s, Average Loss=0.0121, Epoch=4]\u001b[A\n",
            "Train:  24%|██▎       | 2170/9200 [16:24<49:16,  2.38it/s, Average Loss=0.019, Epoch=4] \u001b[A\n",
            "Train:  24%|██▎       | 2180/9200 [16:29<49:20,  2.37it/s, Average Loss=0.019, Epoch=4]\u001b[A\n",
            "Train:  24%|██▎       | 2180/9200 [16:29<49:20,  2.37it/s, Average Loss=0.0228, Epoch=4]\u001b[A\n",
            "Train:  24%|██▍       | 2190/9200 [16:33<49:13,  2.37it/s, Average Loss=0.0228, Epoch=4]\u001b[A\n",
            "Train:  24%|██▍       | 2190/9200 [16:33<49:13,  2.37it/s, Average Loss=0.00464, Epoch=4]\u001b[A\n",
            "Train:  24%|██▍       | 2200/9200 [16:37<49:07,  2.38it/s, Average Loss=0.00464, Epoch=4]\u001b[A\n",
            "Train:  24%|██▍       | 2200/9200 [16:37<49:07,  2.38it/s, Average Loss=0.00741, Epoch=4]\u001b[A\n",
            "Train:  24%|██▍       | 2210/9200 [16:41<49:00,  2.38it/s, Average Loss=0.00741, Epoch=4]\u001b[A\n",
            "Train:  24%|██▍       | 2210/9200 [16:41<49:00,  2.38it/s, Average Loss=0.0221, Epoch=4] \u001b[A\n",
            "Train:  24%|██▍       | 2220/9200 [16:45<49:00,  2.37it/s, Average Loss=0.0221, Epoch=4]\u001b[A\n",
            "Train:  24%|██▍       | 2220/9200 [16:46<49:00,  2.37it/s, Average Loss=0.0425, Epoch=4]\u001b[A\n",
            "Train:  24%|██▍       | 2230/9200 [16:50<48:48,  2.38it/s, Average Loss=0.0425, Epoch=4]\u001b[A\n",
            "Train:  24%|██▍       | 2230/9200 [16:50<48:48,  2.38it/s, Average Loss=0.0403, Epoch=4]\u001b[A\n",
            "Train:  24%|██▍       | 2240/9200 [16:54<48:40,  2.38it/s, Average Loss=0.0403, Epoch=4]\u001b[A\n",
            "Train:  24%|██▍       | 2240/9200 [16:54<48:40,  2.38it/s, Average Loss=0.0218, Epoch=4]\u001b[A\n",
            "Train:  24%|██▍       | 2250/9200 [16:58<48:42,  2.38it/s, Average Loss=0.0218, Epoch=4]\u001b[A\n",
            "Train:  24%|██▍       | 2250/9200 [16:58<48:42,  2.38it/s, Average Loss=0.0223, Epoch=4]\u001b[A\n",
            "Train:  25%|██▍       | 2260/9200 [17:02<48:42,  2.37it/s, Average Loss=0.0223, Epoch=4]\u001b[A\n",
            "Train:  25%|██▍       | 2260/9200 [17:02<48:42,  2.37it/s, Average Loss=0.0272, Epoch=4]\u001b[A\n",
            "Train:  25%|██▍       | 2270/9200 [17:06<48:31,  2.38it/s, Average Loss=0.0272, Epoch=4]\u001b[A\n",
            "Train:  25%|██▍       | 2270/9200 [17:06<48:31,  2.38it/s, Average Loss=0.0196, Epoch=4]\u001b[A\n",
            "Train:  25%|██▍       | 2280/9200 [17:11<48:25,  2.38it/s, Average Loss=0.0196, Epoch=4]\u001b[A\n",
            "Train:  25%|██▍       | 2280/9200 [17:11<48:25,  2.38it/s, Average Loss=0.0418, Epoch=4]\u001b[A\n",
            "Train:  25%|██▍       | 2290/9200 [17:15<48:32,  2.37it/s, Average Loss=0.0418, Epoch=4]\u001b[A\n",
            "Train:  25%|██▍       | 2290/9200 [17:15<48:32,  2.37it/s, Average Loss=0.0114, Epoch=4]\u001b[A\n",
            "Train:  25%|██▌       | 2300/9200 [17:19<48:12,  2.39it/s, Average Loss=0.0114, Epoch=4]\u001b[A\n",
            "Train:  25%|██▌       | 2300/9200 [17:19<48:12,  2.39it/s, Average Loss=0.00396, Epoch=4]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: [Epoch: 4, Macro F1: 0.6621032013007698, Validation Loss: 0.3958282575287401, Time per Epoch: 203.5732457637787]\n",
            "Begin Epoch 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Train:  25%|██▌       | 2310/9200 [17:42<1:51:04,  1.03it/s, Average Loss=0.00396, Epoch=4]\u001b[A\n",
            "Train:  25%|██▌       | 2310/9200 [17:42<1:51:04,  1.03it/s, Average Loss=0.00304, Epoch=5]\u001b[A\n",
            "Train:  25%|██▌       | 2320/9200 [17:46<1:32:10,  1.24it/s, Average Loss=0.00304, Epoch=5]\u001b[A\n",
            "Train:  25%|██▌       | 2320/9200 [17:46<1:32:10,  1.24it/s, Average Loss=0.000885, Epoch=5]\u001b[A\n",
            "Train:  25%|██▌       | 2330/9200 [17:50<1:18:53,  1.45it/s, Average Loss=0.000885, Epoch=5]\u001b[A\n",
            "Train:  25%|██▌       | 2330/9200 [17:50<1:18:53,  1.45it/s, Average Loss=0.00341, Epoch=5] \u001b[A\n",
            "Train:  25%|██▌       | 2340/9200 [17:54<1:09:37,  1.64it/s, Average Loss=0.00341, Epoch=5]\u001b[A\n",
            "Train:  25%|██▌       | 2340/9200 [17:54<1:09:37,  1.64it/s, Average Loss=0.00209, Epoch=5]\u001b[A\n",
            "Train:  26%|██▌       | 2350/9200 [17:58<1:03:23,  1.80it/s, Average Loss=0.00209, Epoch=5]\u001b[A\n",
            "Train:  26%|██▌       | 2350/9200 [17:58<1:03:23,  1.80it/s, Average Loss=0.000331, Epoch=5]\u001b[A\n",
            "Train:  26%|██▌       | 2360/9200 [18:03<59:10,  1.93it/s, Average Loss=0.000331, Epoch=5]  \u001b[A\n",
            "Train:  26%|██▌       | 2360/9200 [18:03<59:10,  1.93it/s, Average Loss=0.00145, Epoch=5] \u001b[A\n",
            "Train:  26%|██▌       | 2370/9200 [18:07<56:03,  2.03it/s, Average Loss=0.00145, Epoch=5]\u001b[A\n",
            "Train:  26%|██▌       | 2370/9200 [18:07<56:03,  2.03it/s, Average Loss=0.034, Epoch=5]  \u001b[A\n",
            "Train:  26%|██▌       | 2380/9200 [18:11<53:45,  2.11it/s, Average Loss=0.034, Epoch=5]\u001b[A\n",
            "Train:  26%|██▌       | 2380/9200 [18:11<53:45,  2.11it/s, Average Loss=0.0213, Epoch=5]\u001b[A\n",
            "Train:  26%|██▌       | 2390/9200 [18:16<52:13,  2.17it/s, Average Loss=0.0213, Epoch=5]\u001b[A\n",
            "Train:  26%|██▌       | 2390/9200 [18:16<52:13,  2.17it/s, Average Loss=0.0471, Epoch=5]\u001b[A\n",
            "Train:  26%|██▌       | 2400/9200 [18:20<50:56,  2.22it/s, Average Loss=0.0471, Epoch=5]\u001b[A\n",
            "Train:  26%|██▌       | 2400/9200 [18:20<50:56,  2.22it/s, Average Loss=0.0136, Epoch=5]\u001b[A\n",
            "Train:  26%|██▌       | 2410/9200 [18:24<49:53,  2.27it/s, Average Loss=0.0136, Epoch=5]\u001b[A\n",
            "Train:  26%|██▌       | 2410/9200 [18:24<49:53,  2.27it/s, Average Loss=0.00159, Epoch=5]\u001b[A\n",
            "Train:  26%|██▋       | 2420/9200 [18:28<49:11,  2.30it/s, Average Loss=0.00159, Epoch=5]\u001b[A\n",
            "Train:  26%|██▋       | 2420/9200 [18:28<49:11,  2.30it/s, Average Loss=0.0223, Epoch=5] \u001b[A\n",
            "Train:  26%|██▋       | 2430/9200 [18:33<48:42,  2.32it/s, Average Loss=0.0223, Epoch=5]\u001b[A\n",
            "Train:  26%|██▋       | 2430/9200 [18:33<48:42,  2.32it/s, Average Loss=0.0103, Epoch=5]\u001b[A\n",
            "Train:  27%|██▋       | 2440/9200 [18:37<48:10,  2.34it/s, Average Loss=0.0103, Epoch=5]\u001b[A\n",
            "Train:  27%|██▋       | 2440/9200 [18:37<48:10,  2.34it/s, Average Loss=0.00272, Epoch=5]\u001b[A\n",
            "Train:  27%|██▋       | 2450/9200 [18:41<47:43,  2.36it/s, Average Loss=0.00272, Epoch=5]\u001b[A\n",
            "Train:  27%|██▋       | 2450/9200 [18:41<47:43,  2.36it/s, Average Loss=0.000555, Epoch=5]\u001b[A\n",
            "Train:  27%|██▋       | 2460/9200 [18:45<47:30,  2.36it/s, Average Loss=0.000555, Epoch=5]\u001b[A\n",
            "Train:  27%|██▋       | 2460/9200 [18:45<47:30,  2.36it/s, Average Loss=0.00168, Epoch=5] \u001b[A\n",
            "Train:  27%|██▋       | 2470/9200 [18:49<47:17,  2.37it/s, Average Loss=0.00168, Epoch=5]\u001b[A\n",
            "Train:  27%|██▋       | 2470/9200 [18:49<47:17,  2.37it/s, Average Loss=0.0268, Epoch=5] \u001b[A\n",
            "Train:  27%|██▋       | 2480/9200 [18:53<47:01,  2.38it/s, Average Loss=0.0268, Epoch=5]\u001b[A\n",
            "Train:  27%|██▋       | 2480/9200 [18:54<47:01,  2.38it/s, Average Loss=0.0133, Epoch=5]\u001b[A\n",
            "Train:  27%|██▋       | 2490/9200 [18:58<46:51,  2.39it/s, Average Loss=0.0133, Epoch=5]\u001b[A\n",
            "Train:  27%|██▋       | 2490/9200 [18:58<46:51,  2.39it/s, Average Loss=0.00616, Epoch=5]\u001b[A\n",
            "Train:  27%|██▋       | 2500/9200 [19:02<46:53,  2.38it/s, Average Loss=0.00616, Epoch=5]\u001b[A\n",
            "Train:  27%|██▋       | 2500/9200 [19:02<46:53,  2.38it/s, Average Loss=0.0194, Epoch=5] \u001b[A\n",
            "Train:  27%|██▋       | 2510/9200 [19:06<46:46,  2.38it/s, Average Loss=0.0194, Epoch=5]\u001b[A\n",
            "Train:  27%|██▋       | 2510/9200 [19:06<46:46,  2.38it/s, Average Loss=0.0199, Epoch=5]\u001b[A\n",
            "Train:  27%|██▋       | 2520/9200 [19:10<46:42,  2.38it/s, Average Loss=0.0199, Epoch=5]\u001b[A\n",
            "Train:  27%|██▋       | 2520/9200 [19:10<46:42,  2.38it/s, Average Loss=0.0123, Epoch=5]\u001b[A\n",
            "Train:  28%|██▊       | 2530/9200 [19:14<46:42,  2.38it/s, Average Loss=0.0123, Epoch=5]\u001b[A\n",
            "Train:  28%|██▊       | 2530/9200 [19:15<46:42,  2.38it/s, Average Loss=0.00263, Epoch=5]\u001b[A\n",
            "Train:  28%|██▊       | 2540/9200 [19:19<46:47,  2.37it/s, Average Loss=0.00263, Epoch=5]\u001b[A\n",
            "Train:  28%|██▊       | 2540/9200 [19:19<46:47,  2.37it/s, Average Loss=0.0106, Epoch=5] \u001b[A\n",
            "Train:  28%|██▊       | 2550/9200 [19:23<46:40,  2.37it/s, Average Loss=0.0106, Epoch=5]\u001b[A\n",
            "Train:  28%|██▊       | 2550/9200 [19:23<46:40,  2.37it/s, Average Loss=0.0245, Epoch=5]\u001b[A\n",
            "Train:  28%|██▊       | 2560/9200 [19:27<46:37,  2.37it/s, Average Loss=0.0245, Epoch=5]\u001b[A\n",
            "Train:  28%|██▊       | 2560/9200 [19:27<46:37,  2.37it/s, Average Loss=0.000398, Epoch=5]\u001b[A\n",
            "Train:  28%|██▊       | 2570/9200 [19:31<46:44,  2.36it/s, Average Loss=0.000398, Epoch=5]\u001b[A\n",
            "Train:  28%|██▊       | 2570/9200 [19:31<46:44,  2.36it/s, Average Loss=0.0266, Epoch=5]  \u001b[A\n",
            "Train:  28%|██▊       | 2580/9200 [19:36<46:38,  2.37it/s, Average Loss=0.0266, Epoch=5]\u001b[A\n",
            "Train:  28%|██▊       | 2580/9200 [19:36<46:38,  2.37it/s, Average Loss=0.0871, Epoch=5]\u001b[A\n",
            "Train:  28%|██▊       | 2590/9200 [19:40<46:28,  2.37it/s, Average Loss=0.0871, Epoch=5]\u001b[A\n",
            "Train:  28%|██▊       | 2590/9200 [19:40<46:28,  2.37it/s, Average Loss=0.0163, Epoch=5]\u001b[A\n",
            "Train:  28%|██▊       | 2600/9200 [19:44<46:25,  2.37it/s, Average Loss=0.0163, Epoch=5]\u001b[A\n",
            "Train:  28%|██▊       | 2600/9200 [19:44<46:25,  2.37it/s, Average Loss=0.0432, Epoch=5]\u001b[A\n",
            "Train:  28%|██▊       | 2610/9200 [19:48<46:24,  2.37it/s, Average Loss=0.0432, Epoch=5]\u001b[A\n",
            "Train:  28%|██▊       | 2610/9200 [19:48<46:24,  2.37it/s, Average Loss=0.0306, Epoch=5]\u001b[A\n",
            "Train:  28%|██▊       | 2620/9200 [19:52<46:14,  2.37it/s, Average Loss=0.0306, Epoch=5]\u001b[A\n",
            "Train:  28%|██▊       | 2620/9200 [19:53<46:14,  2.37it/s, Average Loss=0.00511, Epoch=5]\u001b[A\n",
            "Train:  29%|██▊       | 2630/9200 [19:57<46:04,  2.38it/s, Average Loss=0.00511, Epoch=5]\u001b[A\n",
            "Train:  29%|██▊       | 2630/9200 [19:57<46:04,  2.38it/s, Average Loss=0.0129, Epoch=5] \u001b[A\n",
            "Train:  29%|██▊       | 2640/9200 [20:01<46:06,  2.37it/s, Average Loss=0.0129, Epoch=5]\u001b[A\n",
            "Train:  29%|██▊       | 2640/9200 [20:01<46:06,  2.37it/s, Average Loss=0.00223, Epoch=5]\u001b[A\n",
            "Train:  29%|██▉       | 2650/9200 [20:05<46:00,  2.37it/s, Average Loss=0.00223, Epoch=5]\u001b[A\n",
            "Train:  29%|██▉       | 2650/9200 [20:05<46:00,  2.37it/s, Average Loss=0.0392, Epoch=5] \u001b[A\n",
            "Train:  29%|██▉       | 2660/9200 [20:09<45:48,  2.38it/s, Average Loss=0.0392, Epoch=5]\u001b[A\n",
            "Train:  29%|██▉       | 2660/9200 [20:09<45:48,  2.38it/s, Average Loss=0.0174, Epoch=5]\u001b[A\n",
            "Train:  29%|██▉       | 2670/9200 [20:13<45:40,  2.38it/s, Average Loss=0.0174, Epoch=5]\u001b[A\n",
            "Train:  29%|██▉       | 2670/9200 [20:14<45:40,  2.38it/s, Average Loss=0.00158, Epoch=5]\u001b[A\n",
            "Train:  29%|██▉       | 2680/9200 [20:18<45:46,  2.37it/s, Average Loss=0.00158, Epoch=5]\u001b[A\n",
            "Train:  29%|██▉       | 2680/9200 [20:18<45:46,  2.37it/s, Average Loss=0.01, Epoch=5]   \u001b[A\n",
            "Train:  29%|██▉       | 2690/9200 [20:22<45:39,  2.38it/s, Average Loss=0.01, Epoch=5]\u001b[A\n",
            "Train:  29%|██▉       | 2690/9200 [20:22<45:39,  2.38it/s, Average Loss=0.0175, Epoch=5]\u001b[A\n",
            "Train:  29%|██▉       | 2700/9200 [20:26<45:29,  2.38it/s, Average Loss=0.0175, Epoch=5]\u001b[A\n",
            "Train:  29%|██▉       | 2700/9200 [20:26<45:29,  2.38it/s, Average Loss=0.0157, Epoch=5]\u001b[A\n",
            "Train:  29%|██▉       | 2710/9200 [20:30<45:26,  2.38it/s, Average Loss=0.0157, Epoch=5]\u001b[A\n",
            "Train:  29%|██▉       | 2710/9200 [20:30<45:26,  2.38it/s, Average Loss=0.0186, Epoch=5]\u001b[A\n",
            "Train:  30%|██▉       | 2720/9200 [20:35<45:28,  2.38it/s, Average Loss=0.0186, Epoch=5]\u001b[A\n",
            "Train:  30%|██▉       | 2720/9200 [20:35<45:28,  2.38it/s, Average Loss=0.00503, Epoch=5]\u001b[A\n",
            "Train:  30%|██▉       | 2730/9200 [20:39<45:17,  2.38it/s, Average Loss=0.00503, Epoch=5]\u001b[A\n",
            "Train:  30%|██▉       | 2730/9200 [20:39<45:17,  2.38it/s, Average Loss=0.00043, Epoch=5]\u001b[A\n",
            "Train:  30%|██▉       | 2740/9200 [20:43<45:08,  2.39it/s, Average Loss=0.00043, Epoch=5]\u001b[A\n",
            "Train:  30%|██▉       | 2740/9200 [20:43<45:08,  2.39it/s, Average Loss=0.0153, Epoch=5] \u001b[A\n",
            "Train:  30%|██▉       | 2750/9200 [20:47<45:12,  2.38it/s, Average Loss=0.0153, Epoch=5]\u001b[A\n",
            "Train:  30%|██▉       | 2750/9200 [20:47<45:12,  2.38it/s, Average Loss=0.00427, Epoch=5]\u001b[A\n",
            "Train:  30%|███       | 2760/9200 [20:51<44:53,  2.39it/s, Average Loss=0.00427, Epoch=5]\u001b[A\n",
            "Train:  30%|███       | 2760/9200 [20:51<44:53,  2.39it/s, Average Loss=0.0387, Epoch=5] \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: [Epoch: 5, Macro F1: 0.660647694098823, Validation Loss: 0.49123652660671, Time per Epoch: 203.55997729301453]\n",
            "Begin Epoch 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Train:  30%|███       | 2770/9200 [21:05<1:15:49,  1.41it/s, Average Loss=0.0387, Epoch=5]\u001b[A\n",
            "Train:  30%|███       | 2770/9200 [21:05<1:15:49,  1.41it/s, Average Loss=0.00827, Epoch=6]\u001b[A\n",
            "Train:  30%|███       | 2780/9200 [21:09<1:06:23,  1.61it/s, Average Loss=0.00827, Epoch=6]\u001b[A\n",
            "Train:  30%|███       | 2780/9200 [21:09<1:06:23,  1.61it/s, Average Loss=0.00427, Epoch=6]\u001b[A\n",
            "Train:  30%|███       | 2790/9200 [21:13<59:50,  1.79it/s, Average Loss=0.00427, Epoch=6]  \u001b[A\n",
            "Train:  30%|███       | 2790/9200 [21:13<59:50,  1.79it/s, Average Loss=0.0148, Epoch=6] \u001b[A\n",
            "Train:  30%|███       | 2800/9200 [21:18<55:26,  1.92it/s, Average Loss=0.0148, Epoch=6]\u001b[A\n",
            "Train:  30%|███       | 2800/9200 [21:18<55:26,  1.92it/s, Average Loss=0.0202, Epoch=6]\u001b[A\n",
            "Train:  31%|███       | 2810/9200 [21:22<52:08,  2.04it/s, Average Loss=0.0202, Epoch=6]\u001b[A\n",
            "Train:  31%|███       | 2810/9200 [21:22<52:08,  2.04it/s, Average Loss=0.00823, Epoch=6]\u001b[A\n",
            "Train:  31%|███       | 2820/9200 [21:26<49:49,  2.13it/s, Average Loss=0.00823, Epoch=6]\u001b[A\n",
            "Train:  31%|███       | 2820/9200 [21:26<49:49,  2.13it/s, Average Loss=0.00155, Epoch=6]\u001b[A\n",
            "Train:  31%|███       | 2830/9200 [21:30<48:16,  2.20it/s, Average Loss=0.00155, Epoch=6]\u001b[A\n",
            "Train:  31%|███       | 2830/9200 [21:30<48:16,  2.20it/s, Average Loss=0.00166, Epoch=6]\u001b[A\n",
            "Train:  31%|███       | 2840/9200 [21:35<47:12,  2.25it/s, Average Loss=0.00166, Epoch=6]\u001b[A\n",
            "Train:  31%|███       | 2840/9200 [21:35<47:12,  2.25it/s, Average Loss=0.00127, Epoch=6]\u001b[A\n",
            "Train:  31%|███       | 2850/9200 [21:39<46:16,  2.29it/s, Average Loss=0.00127, Epoch=6]\u001b[A\n",
            "Train:  31%|███       | 2850/9200 [21:39<46:16,  2.29it/s, Average Loss=0.00498, Epoch=6]\u001b[A\n",
            "Train:  31%|███       | 2860/9200 [21:43<45:36,  2.32it/s, Average Loss=0.00498, Epoch=6]\u001b[A\n",
            "Train:  31%|███       | 2860/9200 [21:43<45:36,  2.32it/s, Average Loss=0.002, Epoch=6]  \u001b[A\n",
            "Train:  31%|███       | 2870/9200 [21:47<45:18,  2.33it/s, Average Loss=0.002, Epoch=6]\u001b[A\n",
            "Train:  31%|███       | 2870/9200 [21:47<45:18,  2.33it/s, Average Loss=0.0532, Epoch=6]\u001b[A\n",
            "Train:  31%|███▏      | 2880/9200 [21:51<44:57,  2.34it/s, Average Loss=0.0532, Epoch=6]\u001b[A\n",
            "Train:  31%|███▏      | 2880/9200 [21:51<44:57,  2.34it/s, Average Loss=0.0111, Epoch=6]\u001b[A\n",
            "Train:  31%|███▏      | 2890/9200 [21:56<44:40,  2.35it/s, Average Loss=0.0111, Epoch=6]\u001b[A\n",
            "Train:  31%|███▏      | 2890/9200 [21:56<44:40,  2.35it/s, Average Loss=0.0166, Epoch=6]\u001b[A\n",
            "Train:  32%|███▏      | 2900/9200 [22:00<44:30,  2.36it/s, Average Loss=0.0166, Epoch=6]\u001b[A\n",
            "Train:  32%|███▏      | 2900/9200 [22:00<44:30,  2.36it/s, Average Loss=0.0219, Epoch=6]\u001b[A\n",
            "Train:  32%|███▏      | 2910/9200 [22:04<44:25,  2.36it/s, Average Loss=0.0219, Epoch=6]\u001b[A\n",
            "Train:  32%|███▏      | 2910/9200 [22:04<44:25,  2.36it/s, Average Loss=0.000516, Epoch=6]\u001b[A\n",
            "Train:  32%|███▏      | 2920/9200 [22:08<44:11,  2.37it/s, Average Loss=0.000516, Epoch=6]\u001b[A\n",
            "Train:  32%|███▏      | 2920/9200 [22:08<44:11,  2.37it/s, Average Loss=0.00781, Epoch=6] \u001b[A\n",
            "Train:  32%|███▏      | 2930/9200 [22:12<44:00,  2.37it/s, Average Loss=0.00781, Epoch=6]\u001b[A\n",
            "Train:  32%|███▏      | 2930/9200 [22:12<44:00,  2.37it/s, Average Loss=0.000383, Epoch=6]\u001b[A\n",
            "Train:  32%|███▏      | 2940/9200 [22:17<43:59,  2.37it/s, Average Loss=0.000383, Epoch=6]\u001b[A\n",
            "Train:  32%|███▏      | 2940/9200 [22:17<43:59,  2.37it/s, Average Loss=0.00467, Epoch=6] \u001b[A\n",
            "Train:  32%|███▏      | 2950/9200 [22:21<43:54,  2.37it/s, Average Loss=0.00467, Epoch=6]\u001b[A\n",
            "Train:  32%|███▏      | 2950/9200 [22:21<43:54,  2.37it/s, Average Loss=0.00706, Epoch=6]\u001b[A\n",
            "Train:  32%|███▏      | 2960/9200 [22:25<43:47,  2.38it/s, Average Loss=0.00706, Epoch=6]\u001b[A\n",
            "Train:  32%|███▏      | 2960/9200 [22:25<43:47,  2.38it/s, Average Loss=0.000783, Epoch=6]\u001b[A\n",
            "Train:  32%|███▏      | 2970/9200 [22:29<43:43,  2.37it/s, Average Loss=0.000783, Epoch=6]\u001b[A\n",
            "Train:  32%|███▏      | 2970/9200 [22:29<43:43,  2.37it/s, Average Loss=0.000184, Epoch=6]\u001b[A\n",
            "Train:  32%|███▏      | 2980/9200 [22:34<43:45,  2.37it/s, Average Loss=0.000184, Epoch=6]\u001b[A\n",
            "Train:  32%|███▏      | 2980/9200 [22:34<43:45,  2.37it/s, Average Loss=0.00117, Epoch=6] \u001b[A\n",
            "Train:  32%|███▎      | 2990/9200 [22:38<43:36,  2.37it/s, Average Loss=0.00117, Epoch=6]\u001b[A\n",
            "Train:  32%|███▎      | 2990/9200 [22:38<43:36,  2.37it/s, Average Loss=0.00468, Epoch=6]\u001b[A\n",
            "Train:  33%|███▎      | 3000/9200 [22:42<43:26,  2.38it/s, Average Loss=0.00468, Epoch=6]\u001b[A\n",
            "Train:  33%|███▎      | 3000/9200 [22:42<43:26,  2.38it/s, Average Loss=8.09e-5, Epoch=6]\u001b[A\n",
            "Train:  33%|███▎      | 3010/9200 [22:46<43:28,  2.37it/s, Average Loss=8.09e-5, Epoch=6]\u001b[A\n",
            "Train:  33%|███▎      | 3010/9200 [22:46<43:28,  2.37it/s, Average Loss=0.0134, Epoch=6] \u001b[A\n",
            "Train:  33%|███▎      | 3020/9200 [22:50<43:22,  2.37it/s, Average Loss=0.0134, Epoch=6]\u001b[A\n",
            "Train:  33%|███▎      | 3020/9200 [22:50<43:22,  2.37it/s, Average Loss=0.00572, Epoch=6]\u001b[A\n",
            "Train:  33%|███▎      | 3030/9200 [22:55<43:14,  2.38it/s, Average Loss=0.00572, Epoch=6]\u001b[A\n",
            "Train:  33%|███▎      | 3030/9200 [22:55<43:14,  2.38it/s, Average Loss=0.00757, Epoch=6]\u001b[A\n",
            "Train:  33%|███▎      | 3040/9200 [22:59<43:09,  2.38it/s, Average Loss=0.00757, Epoch=6]\u001b[A\n",
            "Train:  33%|███▎      | 3040/9200 [22:59<43:09,  2.38it/s, Average Loss=0.00588, Epoch=6]\u001b[A\n",
            "Train:  33%|███▎      | 3050/9200 [23:03<43:12,  2.37it/s, Average Loss=0.00588, Epoch=6]\u001b[A\n",
            "Train:  33%|███▎      | 3050/9200 [23:03<43:12,  2.37it/s, Average Loss=0.00919, Epoch=6]\u001b[A\n",
            "Train:  33%|███▎      | 3060/9200 [23:07<43:03,  2.38it/s, Average Loss=0.00919, Epoch=6]\u001b[A\n",
            "Train:  33%|███▎      | 3060/9200 [23:07<43:03,  2.38it/s, Average Loss=0.0248, Epoch=6] \u001b[A\n",
            "Train:  33%|███▎      | 3070/9200 [23:11<42:56,  2.38it/s, Average Loss=0.0248, Epoch=6]\u001b[A\n",
            "Train:  33%|███▎      | 3070/9200 [23:11<42:56,  2.38it/s, Average Loss=0.00553, Epoch=6]\u001b[A\n",
            "Train:  33%|███▎      | 3080/9200 [23:16<42:58,  2.37it/s, Average Loss=0.00553, Epoch=6]\u001b[A\n",
            "Train:  33%|███▎      | 3080/9200 [23:16<42:58,  2.37it/s, Average Loss=0.00207, Epoch=6]\u001b[A\n",
            "Train:  34%|███▎      | 3090/9200 [23:20<42:52,  2.38it/s, Average Loss=0.00207, Epoch=6]\u001b[A\n",
            "Train:  34%|███▎      | 3090/9200 [23:20<42:52,  2.38it/s, Average Loss=0.041, Epoch=6]  \u001b[A\n",
            "Train:  34%|███▎      | 3100/9200 [23:24<42:47,  2.38it/s, Average Loss=0.041, Epoch=6]\u001b[A\n",
            "Train:  34%|███▎      | 3100/9200 [23:24<42:47,  2.38it/s, Average Loss=0.0308, Epoch=6]\u001b[A\n",
            "Train:  34%|███▍      | 3110/9200 [23:28<42:42,  2.38it/s, Average Loss=0.0308, Epoch=6]\u001b[A\n",
            "Train:  34%|███▍      | 3110/9200 [23:28<42:42,  2.38it/s, Average Loss=0.000766, Epoch=6]\u001b[A\n",
            "Train:  34%|███▍      | 3120/9200 [23:32<42:45,  2.37it/s, Average Loss=0.000766, Epoch=6]\u001b[A\n",
            "Train:  34%|███▍      | 3120/9200 [23:32<42:45,  2.37it/s, Average Loss=0.0456, Epoch=6]  \u001b[A\n",
            "Train:  34%|███▍      | 3130/9200 [23:37<42:35,  2.37it/s, Average Loss=0.0456, Epoch=6]\u001b[A\n",
            "Train:  34%|███▍      | 3130/9200 [23:37<42:35,  2.37it/s, Average Loss=0.017, Epoch=6] \u001b[A\n",
            "Train:  34%|███▍      | 3140/9200 [23:41<42:27,  2.38it/s, Average Loss=0.017, Epoch=6]\u001b[A\n",
            "Train:  34%|███▍      | 3140/9200 [23:41<42:27,  2.38it/s, Average Loss=0.025, Epoch=6]\u001b[A\n",
            "Train:  34%|███▍      | 3150/9200 [23:45<42:26,  2.38it/s, Average Loss=0.025, Epoch=6]\u001b[A\n",
            "Train:  34%|███▍      | 3150/9200 [23:45<42:26,  2.38it/s, Average Loss=0.0424, Epoch=6]\u001b[A\n",
            "Train:  34%|███▍      | 3160/9200 [23:49<42:25,  2.37it/s, Average Loss=0.0424, Epoch=6]\u001b[A\n",
            "Train:  34%|███▍      | 3160/9200 [23:49<42:25,  2.37it/s, Average Loss=0.00041, Epoch=6]\u001b[A\n",
            "Train:  34%|███▍      | 3170/9200 [23:53<42:15,  2.38it/s, Average Loss=0.00041, Epoch=6]\u001b[A\n",
            "Train:  34%|███▍      | 3170/9200 [23:53<42:15,  2.38it/s, Average Loss=0.0232, Epoch=6] \u001b[A\n",
            "Train:  35%|███▍      | 3180/9200 [23:58<42:09,  2.38it/s, Average Loss=0.0232, Epoch=6]\u001b[A\n",
            "Train:  35%|███▍      | 3180/9200 [23:58<42:09,  2.38it/s, Average Loss=0.0276, Epoch=6]\u001b[A\n",
            "Train:  35%|███▍      | 3190/9200 [24:02<42:13,  2.37it/s, Average Loss=0.0276, Epoch=6]\u001b[A\n",
            "Train:  35%|███▍      | 3190/9200 [24:02<42:13,  2.37it/s, Average Loss=0.0208, Epoch=6]\u001b[A\n",
            "Train:  35%|███▍      | 3200/9200 [24:06<42:06,  2.37it/s, Average Loss=0.0208, Epoch=6]\u001b[A\n",
            "Train:  35%|███▍      | 3200/9200 [24:06<42:06,  2.37it/s, Average Loss=0.00177, Epoch=6]\u001b[A\n",
            "Train:  35%|███▍      | 3210/9200 [24:10<41:57,  2.38it/s, Average Loss=0.00177, Epoch=6]\u001b[A\n",
            "Train:  35%|███▍      | 3210/9200 [24:10<41:57,  2.38it/s, Average Loss=0.0148, Epoch=6] \u001b[A\n",
            "Train:  35%|███▌      | 3220/9200 [24:14<41:40,  2.39it/s, Average Loss=0.0148, Epoch=6]\u001b[A\n",
            "Train:  35%|███▌      | 3220/9200 [24:14<41:40,  2.39it/s, Average Loss=0.0019, Epoch=6]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: [Epoch: 6, Macro F1: 0.7108489893506181, Validation Loss: 0.4322301432866668, Time per Epoch: 203.11307740211487]\n",
            "Begin Epoch 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Train:  35%|███▌      | 3230/9200 [24:33<1:24:53,  1.17it/s, Average Loss=0.0019, Epoch=6]\u001b[A\n",
            "Train:  35%|███▌      | 3230/9200 [24:33<1:24:53,  1.17it/s, Average Loss=0.000369, Epoch=7]\u001b[A\n",
            "Train:  35%|███▌      | 3240/9200 [24:37<1:11:43,  1.38it/s, Average Loss=0.000369, Epoch=7]\u001b[A\n",
            "Train:  35%|███▌      | 3240/9200 [24:37<1:11:43,  1.38it/s, Average Loss=0.00119, Epoch=7] \u001b[A\n",
            "Train:  35%|███▌      | 3250/9200 [24:41<1:02:32,  1.59it/s, Average Loss=0.00119, Epoch=7]\u001b[A\n",
            "Train:  35%|███▌      | 3250/9200 [24:41<1:02:32,  1.59it/s, Average Loss=0.00157, Epoch=7]\u001b[A\n",
            "Train:  35%|███▌      | 3260/9200 [24:46<56:18,  1.76it/s, Average Loss=0.00157, Epoch=7]  \u001b[A\n",
            "Train:  35%|███▌      | 3260/9200 [24:46<56:18,  1.76it/s, Average Loss=0.0071, Epoch=7] \u001b[A\n",
            "Train:  36%|███▌      | 3270/9200 [24:50<51:57,  1.90it/s, Average Loss=0.0071, Epoch=7]\u001b[A\n",
            "Train:  36%|███▌      | 3270/9200 [24:50<51:57,  1.90it/s, Average Loss=0.000955, Epoch=7]\u001b[A\n",
            "Train:  36%|███▌      | 3280/9200 [24:54<48:55,  2.02it/s, Average Loss=0.000955, Epoch=7]\u001b[A\n",
            "Train:  36%|███▌      | 3280/9200 [24:54<48:55,  2.02it/s, Average Loss=0.00902, Epoch=7] \u001b[A\n",
            "Train:  36%|███▌      | 3290/9200 [24:58<46:45,  2.11it/s, Average Loss=0.00902, Epoch=7]\u001b[A\n",
            "Train:  36%|███▌      | 3290/9200 [24:58<46:45,  2.11it/s, Average Loss=0.0536, Epoch=7] \u001b[A\n",
            "Train:  36%|███▌      | 3300/9200 [25:03<45:18,  2.17it/s, Average Loss=0.0536, Epoch=7]\u001b[A\n",
            "Train:  36%|███▌      | 3300/9200 [25:03<45:18,  2.17it/s, Average Loss=0.000481, Epoch=7]\u001b[A\n",
            "Train:  36%|███▌      | 3310/9200 [25:07<44:05,  2.23it/s, Average Loss=0.000481, Epoch=7]\u001b[A\n",
            "Train:  36%|███▌      | 3310/9200 [25:07<44:05,  2.23it/s, Average Loss=0.00312, Epoch=7] \u001b[A\n",
            "Train:  36%|███▌      | 3320/9200 [25:11<43:10,  2.27it/s, Average Loss=0.00312, Epoch=7]\u001b[A\n",
            "Train:  36%|███▌      | 3320/9200 [25:11<43:10,  2.27it/s, Average Loss=0.000356, Epoch=7]\u001b[A\n",
            "Train:  36%|███▌      | 3330/9200 [25:15<42:33,  2.30it/s, Average Loss=0.000356, Epoch=7]\u001b[A\n",
            "Train:  36%|███▌      | 3330/9200 [25:15<42:33,  2.30it/s, Average Loss=0.0182, Epoch=7]  \u001b[A\n",
            "Train:  36%|███▋      | 3340/9200 [25:20<42:06,  2.32it/s, Average Loss=0.0182, Epoch=7]\u001b[A\n",
            "Train:  36%|███▋      | 3340/9200 [25:20<42:06,  2.32it/s, Average Loss=0.00416, Epoch=7]\u001b[A\n",
            "Train:  36%|███▋      | 3350/9200 [25:24<41:37,  2.34it/s, Average Loss=0.00416, Epoch=7]\u001b[A\n",
            "Train:  36%|███▋      | 3350/9200 [25:24<41:37,  2.34it/s, Average Loss=0.025, Epoch=7]  \u001b[A\n",
            "Train:  37%|███▋      | 3360/9200 [25:28<41:16,  2.36it/s, Average Loss=0.025, Epoch=7]\u001b[A\n",
            "Train:  37%|███▋      | 3360/9200 [25:28<41:16,  2.36it/s, Average Loss=0.00917, Epoch=7]\u001b[A\n",
            "Train:  37%|███▋      | 3370/9200 [25:32<41:10,  2.36it/s, Average Loss=0.00917, Epoch=7]\u001b[A\n",
            "Train:  37%|███▋      | 3370/9200 [25:32<41:10,  2.36it/s, Average Loss=0.00348, Epoch=7]\u001b[A\n",
            "Train:  37%|███▋      | 3380/9200 [25:36<40:57,  2.37it/s, Average Loss=0.00348, Epoch=7]\u001b[A\n",
            "Train:  37%|███▋      | 3380/9200 [25:36<40:57,  2.37it/s, Average Loss=0.00553, Epoch=7]\u001b[A\n",
            "Train:  37%|███▋      | 3390/9200 [25:41<40:43,  2.38it/s, Average Loss=0.00553, Epoch=7]\u001b[A\n",
            "Train:  37%|███▋      | 3390/9200 [25:41<40:43,  2.38it/s, Average Loss=0.00508, Epoch=7]\u001b[A\n",
            "Train:  37%|███▋      | 3400/9200 [25:45<40:37,  2.38it/s, Average Loss=0.00508, Epoch=7]\u001b[A\n",
            "Train:  37%|███▋      | 3400/9200 [25:45<40:37,  2.38it/s, Average Loss=0.0187, Epoch=7] \u001b[A\n",
            "Train:  37%|███▋      | 3410/9200 [25:49<40:37,  2.38it/s, Average Loss=0.0187, Epoch=7]\u001b[A\n",
            "Train:  37%|███▋      | 3410/9200 [25:49<40:37,  2.38it/s, Average Loss=0.000354, Epoch=7]\u001b[A\n",
            "Train:  37%|███▋      | 3420/9200 [25:53<40:26,  2.38it/s, Average Loss=0.000354, Epoch=7]\u001b[A\n",
            "Train:  37%|███▋      | 3420/9200 [25:53<40:26,  2.38it/s, Average Loss=0.00854, Epoch=7] \u001b[A\n",
            "Train:  37%|███▋      | 3430/9200 [25:57<40:21,  2.38it/s, Average Loss=0.00854, Epoch=7]\u001b[A\n",
            "Train:  37%|███▋      | 3430/9200 [25:57<40:21,  2.38it/s, Average Loss=0.0021, Epoch=7] \u001b[A\n",
            "Train:  37%|███▋      | 3440/9200 [26:02<40:24,  2.38it/s, Average Loss=0.0021, Epoch=7]\u001b[A\n",
            "Train:  37%|███▋      | 3440/9200 [26:02<40:24,  2.38it/s, Average Loss=0.000296, Epoch=7]\u001b[A\n",
            "Train:  38%|███▊      | 3450/9200 [26:06<40:21,  2.37it/s, Average Loss=0.000296, Epoch=7]\u001b[A\n",
            "Train:  38%|███▊      | 3450/9200 [26:06<40:21,  2.37it/s, Average Loss=0.016, Epoch=7]   \u001b[A\n",
            "Train:  38%|███▊      | 3460/9200 [26:10<40:13,  2.38it/s, Average Loss=0.016, Epoch=7]\u001b[A\n",
            "Train:  38%|███▊      | 3460/9200 [26:10<40:13,  2.38it/s, Average Loss=0.00133, Epoch=7]\u001b[A\n",
            "Train:  38%|███▊      | 3470/9200 [26:14<40:13,  2.37it/s, Average Loss=0.00133, Epoch=7]\u001b[A\n",
            "Train:  38%|███▊      | 3470/9200 [26:14<40:13,  2.37it/s, Average Loss=0.00597, Epoch=7]\u001b[A\n",
            "Train:  38%|███▊      | 3480/9200 [26:18<40:15,  2.37it/s, Average Loss=0.00597, Epoch=7]\u001b[A\n",
            "Train:  38%|███▊      | 3480/9200 [26:18<40:15,  2.37it/s, Average Loss=0.00732, Epoch=7]\u001b[A\n",
            "Train:  38%|███▊      | 3490/9200 [26:23<40:06,  2.37it/s, Average Loss=0.00732, Epoch=7]\u001b[A\n",
            "Train:  38%|███▊      | 3490/9200 [26:23<40:06,  2.37it/s, Average Loss=0.0303, Epoch=7] \u001b[A\n",
            "Train:  38%|███▊      | 3500/9200 [26:27<40:01,  2.37it/s, Average Loss=0.0303, Epoch=7]\u001b[A\n",
            "Train:  38%|███▊      | 3500/9200 [26:27<40:01,  2.37it/s, Average Loss=0.00899, Epoch=7]\u001b[A\n",
            "Train:  38%|███▊      | 3510/9200 [26:31<40:01,  2.37it/s, Average Loss=0.00899, Epoch=7]\u001b[A\n",
            "Train:  38%|███▊      | 3510/9200 [26:31<40:01,  2.37it/s, Average Loss=0.0148, Epoch=7] \u001b[A\n",
            "Train:  38%|███▊      | 3520/9200 [26:35<39:56,  2.37it/s, Average Loss=0.0148, Epoch=7]\u001b[A\n",
            "Train:  38%|███▊      | 3520/9200 [26:35<39:56,  2.37it/s, Average Loss=0.0696, Epoch=7]\u001b[A\n",
            "Train:  38%|███▊      | 3530/9200 [26:39<39:47,  2.37it/s, Average Loss=0.0696, Epoch=7]\u001b[A\n",
            "Train:  38%|███▊      | 3530/9200 [26:39<39:47,  2.37it/s, Average Loss=0.0223, Epoch=7]\u001b[A\n",
            "Train:  38%|███▊      | 3540/9200 [26:44<39:41,  2.38it/s, Average Loss=0.0223, Epoch=7]\u001b[A\n",
            "Train:  38%|███▊      | 3540/9200 [26:44<39:41,  2.38it/s, Average Loss=0.0151, Epoch=7]\u001b[A\n",
            "Train:  39%|███▊      | 3550/9200 [26:48<39:43,  2.37it/s, Average Loss=0.0151, Epoch=7]\u001b[A\n",
            "Train:  39%|███▊      | 3550/9200 [26:48<39:43,  2.37it/s, Average Loss=0.00158, Epoch=7]\u001b[A\n",
            "Train:  39%|███▊      | 3560/9200 [26:52<39:36,  2.37it/s, Average Loss=0.00158, Epoch=7]\u001b[A\n",
            "Train:  39%|███▊      | 3560/9200 [26:52<39:36,  2.37it/s, Average Loss=0.0196, Epoch=7] \u001b[A\n",
            "Train:  39%|███▉      | 3570/9200 [26:56<39:28,  2.38it/s, Average Loss=0.0196, Epoch=7]\u001b[A\n",
            "Train:  39%|███▉      | 3570/9200 [26:56<39:28,  2.38it/s, Average Loss=0.000994, Epoch=7]\u001b[A\n",
            "Train:  39%|███▉      | 3580/9200 [27:01<39:26,  2.38it/s, Average Loss=0.000994, Epoch=7]\u001b[A\n",
            "Train:  39%|███▉      | 3580/9200 [27:01<39:26,  2.38it/s, Average Loss=0.00418, Epoch=7] \u001b[A\n",
            "Train:  39%|███▉      | 3590/9200 [27:05<39:24,  2.37it/s, Average Loss=0.00418, Epoch=7]\u001b[A\n",
            "Train:  39%|███▉      | 3590/9200 [27:05<39:24,  2.37it/s, Average Loss=0.000637, Epoch=7]\u001b[A\n",
            "Train:  39%|███▉      | 3600/9200 [27:09<39:16,  2.38it/s, Average Loss=0.000637, Epoch=7]\u001b[A\n",
            "Train:  39%|███▉      | 3600/9200 [27:09<39:16,  2.38it/s, Average Loss=0.0201, Epoch=7]  \u001b[A\n",
            "Train:  39%|███▉      | 3610/9200 [27:13<39:10,  2.38it/s, Average Loss=0.0201, Epoch=7]\u001b[A\n",
            "Train:  39%|███▉      | 3610/9200 [27:13<39:10,  2.38it/s, Average Loss=0.00137, Epoch=7]\u001b[A\n",
            "Train:  39%|███▉      | 3620/9200 [27:17<39:11,  2.37it/s, Average Loss=0.00137, Epoch=7]\u001b[A\n",
            "Train:  39%|███▉      | 3620/9200 [27:17<39:11,  2.37it/s, Average Loss=0.000231, Epoch=7]\u001b[A\n",
            "Train:  39%|███▉      | 3630/9200 [27:22<39:06,  2.37it/s, Average Loss=0.000231, Epoch=7]\u001b[A\n",
            "Train:  39%|███▉      | 3630/9200 [27:22<39:06,  2.37it/s, Average Loss=0.00037, Epoch=7] \u001b[A\n",
            "Train:  40%|███▉      | 3640/9200 [27:26<38:58,  2.38it/s, Average Loss=0.00037, Epoch=7]\u001b[A\n",
            "Train:  40%|███▉      | 3640/9200 [27:26<38:58,  2.38it/s, Average Loss=0.000738, Epoch=7]\u001b[A\n",
            "Train:  40%|███▉      | 3650/9200 [27:30<38:55,  2.38it/s, Average Loss=0.000738, Epoch=7]\u001b[A\n",
            "Train:  40%|███▉      | 3650/9200 [27:30<38:55,  2.38it/s, Average Loss=0.00014, Epoch=7] \u001b[A\n",
            "Train:  40%|███▉      | 3660/9200 [27:34<38:56,  2.37it/s, Average Loss=0.00014, Epoch=7]\u001b[A\n",
            "Train:  40%|███▉      | 3660/9200 [27:34<38:56,  2.37it/s, Average Loss=6.73e-5, Epoch=7]\u001b[A\n",
            "Train:  40%|███▉      | 3670/9200 [27:38<38:46,  2.38it/s, Average Loss=6.73e-5, Epoch=7]\u001b[A\n",
            "Train:  40%|███▉      | 3670/9200 [27:38<38:46,  2.38it/s, Average Loss=0.0338, Epoch=7] \u001b[A\n",
            "Train:  40%|████      | 3680/9200 [27:43<38:26,  2.39it/s, Average Loss=0.0338, Epoch=7]\u001b[A\n",
            "Train:  40%|████      | 3680/9200 [27:43<38:26,  2.39it/s, Average Loss=0.0546, Epoch=7]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: [Epoch: 7, Macro F1: 0.633056716216245, Validation Loss: 0.5334291520840178, Time per Epoch: 203.17141723632812]\n",
            "Begin Epoch 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Train:  40%|████      | 3690/9200 [27:56<1:04:28,  1.42it/s, Average Loss=0.0546, Epoch=7]\u001b[A\n",
            "Train:  40%|████      | 3690/9200 [27:56<1:04:28,  1.42it/s, Average Loss=0.0225, Epoch=8]\u001b[A\n",
            "Train:  40%|████      | 3700/9200 [28:00<56:40,  1.62it/s, Average Loss=0.0225, Epoch=8]  \u001b[A\n",
            "Train:  40%|████      | 3700/9200 [28:00<56:40,  1.62it/s, Average Loss=0.0383, Epoch=8]\u001b[A\n",
            "Train:  40%|████      | 3710/9200 [28:05<51:10,  1.79it/s, Average Loss=0.0383, Epoch=8]\u001b[A\n",
            "Train:  40%|████      | 3710/9200 [28:05<51:10,  1.79it/s, Average Loss=0.00164, Epoch=8]\u001b[A\n",
            "Train:  40%|████      | 3720/9200 [28:09<47:15,  1.93it/s, Average Loss=0.00164, Epoch=8]\u001b[A\n",
            "Train:  40%|████      | 3720/9200 [28:09<47:15,  1.93it/s, Average Loss=0.00642, Epoch=8]\u001b[A\n",
            "Train:  41%|████      | 3730/9200 [28:13<44:27,  2.05it/s, Average Loss=0.00642, Epoch=8]\u001b[A\n",
            "Train:  41%|████      | 3730/9200 [28:13<44:27,  2.05it/s, Average Loss=0.0188, Epoch=8] \u001b[A\n",
            "Train:  41%|████      | 3740/9200 [28:17<42:39,  2.13it/s, Average Loss=0.0188, Epoch=8]\u001b[A\n",
            "Train:  41%|████      | 3740/9200 [28:17<42:39,  2.13it/s, Average Loss=0.0371, Epoch=8]\u001b[A\n",
            "Train:  41%|████      | 3750/9200 [28:21<41:16,  2.20it/s, Average Loss=0.0371, Epoch=8]\u001b[A\n",
            "Train:  41%|████      | 3750/9200 [28:21<41:16,  2.20it/s, Average Loss=0.00134, Epoch=8]\u001b[A\n",
            "Train:  41%|████      | 3760/9200 [28:26<40:14,  2.25it/s, Average Loss=0.00134, Epoch=8]\u001b[A\n",
            "Train:  41%|████      | 3760/9200 [28:26<40:14,  2.25it/s, Average Loss=0.0161, Epoch=8] \u001b[A\n",
            "Train:  41%|████      | 3770/9200 [28:30<39:33,  2.29it/s, Average Loss=0.0161, Epoch=8]\u001b[A\n",
            "Train:  41%|████      | 3770/9200 [28:30<39:33,  2.29it/s, Average Loss=0.0189, Epoch=8]\u001b[A\n",
            "Train:  41%|████      | 3780/9200 [28:34<39:07,  2.31it/s, Average Loss=0.0189, Epoch=8]\u001b[A\n",
            "Train:  41%|████      | 3780/9200 [28:34<39:07,  2.31it/s, Average Loss=0.00531, Epoch=8]\u001b[A\n",
            "Train:  41%|████      | 3790/9200 [28:38<38:39,  2.33it/s, Average Loss=0.00531, Epoch=8]\u001b[A\n",
            "Train:  41%|████      | 3790/9200 [28:38<38:39,  2.33it/s, Average Loss=0.0349, Epoch=8] \u001b[A\n",
            "Train:  41%|████▏     | 3800/9200 [28:42<38:21,  2.35it/s, Average Loss=0.0349, Epoch=8]\u001b[A\n",
            "Train:  41%|████▏     | 3800/9200 [28:43<38:21,  2.35it/s, Average Loss=0.0375, Epoch=8]\u001b[A\n",
            "Train:  41%|████▏     | 3810/9200 [28:47<38:15,  2.35it/s, Average Loss=0.0375, Epoch=8]\u001b[A\n",
            "Train:  41%|████▏     | 3810/9200 [28:47<38:15,  2.35it/s, Average Loss=0.0214, Epoch=8]\u001b[A\n",
            "Train:  42%|████▏     | 3820/9200 [28:51<38:03,  2.36it/s, Average Loss=0.0214, Epoch=8]\u001b[A\n",
            "Train:  42%|████▏     | 3820/9200 [28:51<38:03,  2.36it/s, Average Loss=0.00361, Epoch=8]\u001b[A\n",
            "Train:  42%|████▏     | 3830/9200 [28:55<37:51,  2.36it/s, Average Loss=0.00361, Epoch=8]\u001b[A\n",
            "Train:  42%|████▏     | 3830/9200 [28:55<37:51,  2.36it/s, Average Loss=0.0192, Epoch=8] \u001b[A\n",
            "Train:  42%|████▏     | 3840/9200 [28:59<37:43,  2.37it/s, Average Loss=0.0192, Epoch=8]\u001b[A\n",
            "Train:  42%|████▏     | 3840/9200 [28:59<37:43,  2.37it/s, Average Loss=0.000863, Epoch=8]\u001b[A\n",
            "Train:  42%|████▏     | 3850/9200 [29:04<37:42,  2.36it/s, Average Loss=0.000863, Epoch=8]\u001b[A\n",
            "Train:  42%|████▏     | 3850/9200 [29:04<37:42,  2.36it/s, Average Loss=0.00852, Epoch=8] \u001b[A\n",
            "Train:  42%|████▏     | 3860/9200 [29:08<37:31,  2.37it/s, Average Loss=0.00852, Epoch=8]\u001b[A\n",
            "Train:  42%|████▏     | 3860/9200 [29:08<37:31,  2.37it/s, Average Loss=0.000134, Epoch=8]\u001b[A\n",
            "Train:  42%|████▏     | 3870/9200 [29:12<37:23,  2.38it/s, Average Loss=0.000134, Epoch=8]\u001b[A\n",
            "Train:  42%|████▏     | 3870/9200 [29:12<37:23,  2.38it/s, Average Loss=0.000784, Epoch=8]\u001b[A\n",
            "Train:  42%|████▏     | 3880/9200 [29:16<37:24,  2.37it/s, Average Loss=0.000784, Epoch=8]\u001b[A\n",
            "Train:  42%|████▏     | 3880/9200 [29:16<37:24,  2.37it/s, Average Loss=0.0365, Epoch=8]  \u001b[A\n",
            "Train:  42%|████▏     | 3890/9200 [29:20<37:22,  2.37it/s, Average Loss=0.0365, Epoch=8]\u001b[A\n",
            "Train:  42%|████▏     | 3890/9200 [29:20<37:22,  2.37it/s, Average Loss=0.000972, Epoch=8]\u001b[A\n",
            "Train:  42%|████▏     | 3900/9200 [29:25<37:12,  2.37it/s, Average Loss=0.000972, Epoch=8]\u001b[A\n",
            "Train:  42%|████▏     | 3900/9200 [29:25<37:12,  2.37it/s, Average Loss=0.000479, Epoch=8]\u001b[A\n",
            "Train:  42%|████▎     | 3910/9200 [29:29<37:06,  2.38it/s, Average Loss=0.000479, Epoch=8]\u001b[A\n",
            "Train:  42%|████▎     | 3910/9200 [29:29<37:06,  2.38it/s, Average Loss=0.00102, Epoch=8] \u001b[A\n",
            "Train:  43%|████▎     | 3920/9200 [29:33<37:09,  2.37it/s, Average Loss=0.00102, Epoch=8]\u001b[A\n",
            "Train:  43%|████▎     | 3920/9200 [29:33<37:09,  2.37it/s, Average Loss=0.0493, Epoch=8] \u001b[A\n",
            "Train:  43%|████▎     | 3930/9200 [29:37<37:01,  2.37it/s, Average Loss=0.0493, Epoch=8]\u001b[A\n",
            "Train:  43%|████▎     | 3930/9200 [29:37<37:01,  2.37it/s, Average Loss=0.0142, Epoch=8]\u001b[A\n",
            "Train:  43%|████▎     | 3940/9200 [29:41<36:52,  2.38it/s, Average Loss=0.0142, Epoch=8]\u001b[A\n",
            "Train:  43%|████▎     | 3940/9200 [29:41<36:52,  2.38it/s, Average Loss=0.00131, Epoch=8]\u001b[A\n",
            "Train:  43%|████▎     | 3950/9200 [29:46<36:50,  2.38it/s, Average Loss=0.00131, Epoch=8]\u001b[A\n",
            "Train:  43%|████▎     | 3950/9200 [29:46<36:50,  2.38it/s, Average Loss=0.00231, Epoch=8]\u001b[A\n",
            "Train:  43%|████▎     | 3960/9200 [29:50<36:47,  2.37it/s, Average Loss=0.00231, Epoch=8]\u001b[A\n",
            "Train:  43%|████▎     | 3960/9200 [29:50<36:47,  2.37it/s, Average Loss=0.0209, Epoch=8] \u001b[A\n",
            "Train:  43%|████▎     | 3970/9200 [29:54<36:41,  2.38it/s, Average Loss=0.0209, Epoch=8]\u001b[A\n",
            "Train:  43%|████▎     | 3970/9200 [29:54<36:41,  2.38it/s, Average Loss=0.00726, Epoch=8]\u001b[A\n",
            "Train:  43%|████▎     | 3980/9200 [29:58<36:34,  2.38it/s, Average Loss=0.00726, Epoch=8]\u001b[A\n",
            "Train:  43%|████▎     | 3980/9200 [29:58<36:34,  2.38it/s, Average Loss=0.0126, Epoch=8] \u001b[A\n",
            "Train:  43%|████▎     | 3990/9200 [30:03<36:38,  2.37it/s, Average Loss=0.0126, Epoch=8]\u001b[A\n",
            "Train:  43%|████▎     | 3990/9200 [30:03<36:38,  2.37it/s, Average Loss=0.014, Epoch=8] \u001b[A\n",
            "Train:  43%|████▎     | 4000/9200 [30:07<36:32,  2.37it/s, Average Loss=0.014, Epoch=8]\u001b[A\n",
            "Train:  43%|████▎     | 4000/9200 [30:07<36:32,  2.37it/s, Average Loss=0.000844, Epoch=8]\u001b[A\n",
            "Train:  44%|████▎     | 4010/9200 [30:11<36:23,  2.38it/s, Average Loss=0.000844, Epoch=8]\u001b[A\n",
            "Train:  44%|████▎     | 4010/9200 [30:11<36:23,  2.38it/s, Average Loss=0.00371, Epoch=8] \u001b[A\n",
            "Train:  44%|████▎     | 4020/9200 [30:15<36:19,  2.38it/s, Average Loss=0.00371, Epoch=8]\u001b[A\n",
            "Train:  44%|████▎     | 4020/9200 [30:15<36:19,  2.38it/s, Average Loss=0.00356, Epoch=8]\u001b[A\n",
            "Train:  44%|████▍     | 4030/9200 [30:19<36:17,  2.37it/s, Average Loss=0.00356, Epoch=8]\u001b[A\n",
            "Train:  44%|████▍     | 4030/9200 [30:19<36:17,  2.37it/s, Average Loss=0.0342, Epoch=8] \u001b[A\n",
            "Train:  44%|████▍     | 4040/9200 [30:24<36:11,  2.38it/s, Average Loss=0.0342, Epoch=8]\u001b[A\n",
            "Train:  44%|████▍     | 4040/9200 [30:24<36:11,  2.38it/s, Average Loss=9.98e-5, Epoch=8]\u001b[A\n",
            "Train:  44%|████▍     | 4050/9200 [30:28<36:04,  2.38it/s, Average Loss=9.98e-5, Epoch=8]\u001b[A\n",
            "Train:  44%|████▍     | 4050/9200 [30:28<36:04,  2.38it/s, Average Loss=0.015, Epoch=8]  \u001b[A\n",
            "Train:  44%|████▍     | 4060/9200 [30:32<36:07,  2.37it/s, Average Loss=0.015, Epoch=8]\u001b[A\n",
            "Train:  44%|████▍     | 4060/9200 [30:32<36:07,  2.37it/s, Average Loss=0.000367, Epoch=8]\u001b[A\n",
            "Train:  44%|████▍     | 4070/9200 [30:36<36:02,  2.37it/s, Average Loss=0.000367, Epoch=8]\u001b[A\n",
            "Train:  44%|████▍     | 4070/9200 [30:36<36:02,  2.37it/s, Average Loss=0.000657, Epoch=8]\u001b[A\n",
            "Train:  44%|████▍     | 4080/9200 [30:40<35:53,  2.38it/s, Average Loss=0.000657, Epoch=8]\u001b[A\n",
            "Train:  44%|████▍     | 4080/9200 [30:40<35:53,  2.38it/s, Average Loss=0.0103, Epoch=8]  \u001b[A\n",
            "Train:  44%|████▍     | 4090/9200 [30:45<35:49,  2.38it/s, Average Loss=0.0103, Epoch=8]\u001b[A\n",
            "Train:  44%|████▍     | 4090/9200 [30:45<35:49,  2.38it/s, Average Loss=0.000296, Epoch=8]\u001b[A\n",
            "Train:  45%|████▍     | 4100/9200 [30:49<35:51,  2.37it/s, Average Loss=0.000296, Epoch=8]\u001b[A\n",
            "Train:  45%|████▍     | 4100/9200 [30:49<35:51,  2.37it/s, Average Loss=0.000156, Epoch=8]\u001b[A\n",
            "Train:  45%|████▍     | 4110/9200 [30:53<35:43,  2.37it/s, Average Loss=0.000156, Epoch=8]\u001b[A\n",
            "Train:  45%|████▍     | 4110/9200 [30:53<35:43,  2.37it/s, Average Loss=0.0107, Epoch=8]  \u001b[A\n",
            "Train:  45%|████▍     | 4120/9200 [30:57<35:36,  2.38it/s, Average Loss=0.0107, Epoch=8]\u001b[A\n",
            "Train:  45%|████▍     | 4120/9200 [30:57<35:36,  2.38it/s, Average Loss=0.000205, Epoch=8]\u001b[A\n",
            "Train:  45%|████▍     | 4130/9200 [31:02<35:36,  2.37it/s, Average Loss=0.000205, Epoch=8]\u001b[A\n",
            "Train:  45%|████▍     | 4130/9200 [31:02<35:36,  2.37it/s, Average Loss=0.000162, Epoch=8]\u001b[A\n",
            "Train:  45%|████▌     | 4140/9200 [31:06<35:20,  2.39it/s, Average Loss=0.000162, Epoch=8]\u001b[A\n",
            "Train:  45%|████▌     | 4140/9200 [31:06<35:20,  2.39it/s, Average Loss=9.02e-5, Epoch=8] \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: [Epoch: 8, Macro F1: 0.6118803123595457, Validation Loss: 0.5532740780971687, Time per Epoch: 203.34804725646973]\n",
            "Begin Epoch 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Train:  45%|████▌     | 4150/9200 [31:20<59:53,  1.41it/s, Average Loss=9.02e-5, Epoch=8]\u001b[A\n",
            "Train:  45%|████▌     | 4150/9200 [31:20<59:53,  1.41it/s, Average Loss=0.000124, Epoch=9]\u001b[A\n",
            "Train:  45%|████▌     | 4160/9200 [31:24<52:21,  1.60it/s, Average Loss=0.000124, Epoch=9]\u001b[A\n",
            "Train:  45%|████▌     | 4160/9200 [31:24<52:21,  1.60it/s, Average Loss=0.00065, Epoch=9] \u001b[A\n",
            "Train:  45%|████▌     | 4170/9200 [31:28<47:08,  1.78it/s, Average Loss=0.00065, Epoch=9]\u001b[A\n",
            "Train:  45%|████▌     | 4170/9200 [31:28<47:08,  1.78it/s, Average Loss=0.011, Epoch=9]  \u001b[A\n",
            "Train:  45%|████▌     | 4180/9200 [31:32<43:33,  1.92it/s, Average Loss=0.011, Epoch=9]\u001b[A\n",
            "Train:  45%|████▌     | 4180/9200 [31:32<43:33,  1.92it/s, Average Loss=0.000536, Epoch=9]\u001b[A\n",
            "Train:  46%|████▌     | 4190/9200 [31:36<40:57,  2.04it/s, Average Loss=0.000536, Epoch=9]\u001b[A\n",
            "Train:  46%|████▌     | 4190/9200 [31:36<40:57,  2.04it/s, Average Loss=0.000705, Epoch=9]\u001b[A\n",
            "Train:  46%|████▌     | 4200/9200 [31:41<39:03,  2.13it/s, Average Loss=0.000705, Epoch=9]\u001b[A\n",
            "Train:  46%|████▌     | 4200/9200 [31:41<39:03,  2.13it/s, Average Loss=7.05e-5, Epoch=9] \u001b[A\n",
            "Train:  46%|████▌     | 4210/9200 [31:45<37:47,  2.20it/s, Average Loss=7.05e-5, Epoch=9]\u001b[A\n",
            "Train:  46%|████▌     | 4210/9200 [31:45<37:47,  2.20it/s, Average Loss=4.24e-5, Epoch=9]\u001b[A\n",
            "Train:  46%|████▌     | 4220/9200 [31:49<36:56,  2.25it/s, Average Loss=4.24e-5, Epoch=9]\u001b[A\n",
            "Train:  46%|████▌     | 4220/9200 [31:49<36:56,  2.25it/s, Average Loss=0.00469, Epoch=9]\u001b[A\n",
            "Train:  46%|████▌     | 4230/9200 [31:53<36:10,  2.29it/s, Average Loss=0.00469, Epoch=9]\u001b[A\n",
            "Train:  46%|████▌     | 4230/9200 [31:53<36:10,  2.29it/s, Average Loss=0.000108, Epoch=9]\u001b[A\n",
            "Train:  46%|████▌     | 4240/9200 [31:57<35:38,  2.32it/s, Average Loss=0.000108, Epoch=9]\u001b[A\n",
            "Train:  46%|████▌     | 4240/9200 [31:57<35:38,  2.32it/s, Average Loss=0.0112, Epoch=9]  \u001b[A\n",
            "Train:  46%|████▌     | 4250/9200 [32:02<35:21,  2.33it/s, Average Loss=0.0112, Epoch=9]\u001b[A\n",
            "Train:  46%|████▌     | 4250/9200 [32:02<35:21,  2.33it/s, Average Loss=0.00889, Epoch=9]\u001b[A\n",
            "Train:  46%|████▋     | 4260/9200 [32:06<35:05,  2.35it/s, Average Loss=0.00889, Epoch=9]\u001b[A\n",
            "Train:  46%|████▋     | 4260/9200 [32:06<35:05,  2.35it/s, Average Loss=0.0183, Epoch=9] \u001b[A\n",
            "Train:  46%|████▋     | 4270/9200 [32:10<34:49,  2.36it/s, Average Loss=0.0183, Epoch=9]\u001b[A\n",
            "Train:  46%|████▋     | 4270/9200 [32:10<34:49,  2.36it/s, Average Loss=0.000272, Epoch=9]\u001b[A\n",
            "Train:  47%|████▋     | 4280/9200 [32:14<34:40,  2.36it/s, Average Loss=0.000272, Epoch=9]\u001b[A\n",
            "Train:  47%|████▋     | 4280/9200 [32:14<34:40,  2.36it/s, Average Loss=8.84e-5, Epoch=9] \u001b[A\n",
            "Train:  47%|████▋     | 4290/9200 [32:18<34:37,  2.36it/s, Average Loss=8.84e-5, Epoch=9]\u001b[A\n",
            "Train:  47%|████▋     | 4290/9200 [32:18<34:37,  2.36it/s, Average Loss=8.13e-5, Epoch=9]\u001b[A\n",
            "Train:  47%|████▋     | 4300/9200 [32:23<34:25,  2.37it/s, Average Loss=8.13e-5, Epoch=9]\u001b[A\n",
            "Train:  47%|████▋     | 4300/9200 [32:23<34:25,  2.37it/s, Average Loss=3.63e-5, Epoch=9]\u001b[A\n",
            "Train:  47%|████▋     | 4310/9200 [32:27<34:16,  2.38it/s, Average Loss=3.63e-5, Epoch=9]\u001b[A\n",
            "Train:  47%|████▋     | 4310/9200 [32:27<34:16,  2.38it/s, Average Loss=0.0068, Epoch=9] \u001b[A\n",
            "Train:  47%|████▋     | 4320/9200 [32:31<34:15,  2.37it/s, Average Loss=0.0068, Epoch=9]\u001b[A\n",
            "Train:  47%|████▋     | 4320/9200 [32:31<34:15,  2.37it/s, Average Loss=0.00025, Epoch=9]\u001b[A\n",
            "Train:  47%|████▋     | 4330/9200 [32:35<34:10,  2.37it/s, Average Loss=0.00025, Epoch=9]\u001b[A\n",
            "Train:  47%|████▋     | 4330/9200 [32:35<34:10,  2.37it/s, Average Loss=3.06e-5, Epoch=9]\u001b[A\n",
            "Train:  47%|████▋     | 4340/9200 [32:39<34:03,  2.38it/s, Average Loss=3.06e-5, Epoch=9]\u001b[A\n",
            "Train:  47%|████▋     | 4340/9200 [32:39<34:03,  2.38it/s, Average Loss=0.000128, Epoch=9]\u001b[A\n",
            "Train:  47%|████▋     | 4350/9200 [32:44<33:56,  2.38it/s, Average Loss=0.000128, Epoch=9]\u001b[A\n",
            "Train:  47%|████▋     | 4350/9200 [32:44<33:56,  2.38it/s, Average Loss=3.16e-5, Epoch=9] \u001b[A\n",
            "Train:  47%|████▋     | 4360/9200 [32:48<33:59,  2.37it/s, Average Loss=3.16e-5, Epoch=9]\u001b[A\n",
            "Train:  47%|████▋     | 4360/9200 [32:48<33:59,  2.37it/s, Average Loss=3.8e-5, Epoch=9] \u001b[A\n",
            "Train:  48%|████▊     | 4370/9200 [32:52<33:51,  2.38it/s, Average Loss=3.8e-5, Epoch=9]\u001b[A\n",
            "Train:  48%|████▊     | 4370/9200 [32:52<33:51,  2.38it/s, Average Loss=4.01e-5, Epoch=9]\u001b[A\n",
            "Train:  48%|████▊     | 4380/9200 [32:56<33:44,  2.38it/s, Average Loss=4.01e-5, Epoch=9]\u001b[A\n",
            "Train:  48%|████▊     | 4380/9200 [32:56<33:44,  2.38it/s, Average Loss=0.00253, Epoch=9]\u001b[A\n",
            "Train:  48%|████▊     | 4390/9200 [33:00<33:40,  2.38it/s, Average Loss=0.00253, Epoch=9]\u001b[A\n",
            "Train:  48%|████▊     | 4390/9200 [33:00<33:40,  2.38it/s, Average Loss=0.000437, Epoch=9]\u001b[A\n",
            "Train:  48%|████▊     | 4400/9200 [33:05<33:37,  2.38it/s, Average Loss=0.000437, Epoch=9]\u001b[A\n",
            "Train:  48%|████▊     | 4400/9200 [33:05<33:37,  2.38it/s, Average Loss=0.0045, Epoch=9]  \u001b[A\n",
            "Train:  48%|████▊     | 4410/9200 [33:09<33:28,  2.39it/s, Average Loss=0.0045, Epoch=9]\u001b[A\n",
            "Train:  48%|████▊     | 4410/9200 [33:09<33:28,  2.39it/s, Average Loss=0.00486, Epoch=9]\u001b[A\n",
            "Train:  48%|████▊     | 4420/9200 [33:13<33:23,  2.39it/s, Average Loss=0.00486, Epoch=9]\u001b[A\n",
            "Train:  48%|████▊     | 4420/9200 [33:13<33:23,  2.39it/s, Average Loss=5.32e-5, Epoch=9]\u001b[A\n",
            "Train:  48%|████▊     | 4430/9200 [33:17<33:27,  2.38it/s, Average Loss=5.32e-5, Epoch=9]\u001b[A\n",
            "Train:  48%|████▊     | 4430/9200 [33:17<33:27,  2.38it/s, Average Loss=0.000165, Epoch=9]\u001b[A\n",
            "Train:  48%|████▊     | 4440/9200 [33:21<33:22,  2.38it/s, Average Loss=0.000165, Epoch=9]\u001b[A\n",
            "Train:  48%|████▊     | 4440/9200 [33:21<33:22,  2.38it/s, Average Loss=2.31e-5, Epoch=9] \u001b[A\n",
            "Train:  48%|████▊     | 4450/9200 [33:26<33:14,  2.38it/s, Average Loss=2.31e-5, Epoch=9]\u001b[A\n",
            "Train:  48%|████▊     | 4450/9200 [33:26<33:14,  2.38it/s, Average Loss=0.000288, Epoch=9]\u001b[A\n",
            "Train:  48%|████▊     | 4460/9200 [33:30<33:10,  2.38it/s, Average Loss=0.000288, Epoch=9]\u001b[A\n",
            "Train:  48%|████▊     | 4460/9200 [33:30<33:10,  2.38it/s, Average Loss=3.56e-5, Epoch=9] \u001b[A\n",
            "Train:  49%|████▊     | 4470/9200 [33:34<33:09,  2.38it/s, Average Loss=3.56e-5, Epoch=9]\u001b[A\n",
            "Train:  49%|████▊     | 4470/9200 [33:34<33:09,  2.38it/s, Average Loss=1.81e-5, Epoch=9]\u001b[A\n",
            "Train:  49%|████▊     | 4480/9200 [33:38<33:01,  2.38it/s, Average Loss=1.81e-5, Epoch=9]\u001b[A\n",
            "Train:  49%|████▊     | 4480/9200 [33:38<33:01,  2.38it/s, Average Loss=1.88e-5, Epoch=9]\u001b[A\n",
            "Train:  49%|████▉     | 4490/9200 [33:42<32:56,  2.38it/s, Average Loss=1.88e-5, Epoch=9]\u001b[A\n",
            "Train:  49%|████▉     | 4490/9200 [33:42<32:56,  2.38it/s, Average Loss=2.71e-5, Epoch=9]\u001b[A\n",
            "Train:  49%|████▉     | 4500/9200 [33:47<32:57,  2.38it/s, Average Loss=2.71e-5, Epoch=9]\u001b[A\n",
            "Train:  49%|████▉     | 4500/9200 [33:47<32:57,  2.38it/s, Average Loss=0.00518, Epoch=9]\u001b[A\n",
            "Train:  49%|████▉     | 4510/9200 [33:51<32:51,  2.38it/s, Average Loss=0.00518, Epoch=9]\u001b[A\n",
            "Train:  49%|████▉     | 4510/9200 [33:51<32:51,  2.38it/s, Average Loss=0.00242, Epoch=9]\u001b[A\n",
            "Train:  49%|████▉     | 4520/9200 [33:55<32:45,  2.38it/s, Average Loss=0.00242, Epoch=9]\u001b[A\n",
            "Train:  49%|████▉     | 4520/9200 [33:55<32:45,  2.38it/s, Average Loss=5.87e-5, Epoch=9]\u001b[A\n",
            "Train:  49%|████▉     | 4530/9200 [33:59<32:42,  2.38it/s, Average Loss=5.87e-5, Epoch=9]\u001b[A\n",
            "Train:  49%|████▉     | 4530/9200 [33:59<32:42,  2.38it/s, Average Loss=0.00356, Epoch=9]\u001b[A\n",
            "Train:  49%|████▉     | 4540/9200 [34:03<32:41,  2.38it/s, Average Loss=0.00356, Epoch=9]\u001b[A\n",
            "Train:  49%|████▉     | 4540/9200 [34:03<32:41,  2.38it/s, Average Loss=2.83e-5, Epoch=9]\u001b[A\n",
            "Train:  49%|████▉     | 4550/9200 [34:08<32:35,  2.38it/s, Average Loss=2.83e-5, Epoch=9]\u001b[A\n",
            "Train:  49%|████▉     | 4550/9200 [34:08<32:35,  2.38it/s, Average Loss=0.0255, Epoch=9] \u001b[A\n",
            "Train:  50%|████▉     | 4560/9200 [34:12<32:28,  2.38it/s, Average Loss=0.0255, Epoch=9]\u001b[A\n",
            "Train:  50%|████▉     | 4560/9200 [34:12<32:28,  2.38it/s, Average Loss=9.72e-5, Epoch=9]\u001b[A\n",
            "Train:  50%|████▉     | 4570/9200 [34:16<32:29,  2.38it/s, Average Loss=9.72e-5, Epoch=9]\u001b[A\n",
            "Train:  50%|████▉     | 4570/9200 [34:16<32:29,  2.38it/s, Average Loss=0.000798, Epoch=9]\u001b[A\n",
            "Train:  50%|████▉     | 4580/9200 [34:20<32:26,  2.37it/s, Average Loss=0.000798, Epoch=9]\u001b[A\n",
            "Train:  50%|████▉     | 4580/9200 [34:20<32:26,  2.37it/s, Average Loss=2.31e-5, Epoch=9] \u001b[A\n",
            "Train:  50%|████▉     | 4590/9200 [34:24<32:17,  2.38it/s, Average Loss=2.31e-5, Epoch=9]\u001b[A\n",
            "Train:  50%|████▉     | 4590/9200 [34:24<32:17,  2.38it/s, Average Loss=0.00511, Epoch=9]\u001b[A\n",
            "Train:  50%|█████     | 4600/9200 [34:29<32:04,  2.39it/s, Average Loss=0.00511, Epoch=9]\u001b[A\n",
            "Train:  50%|█████     | 4600/9200 [34:29<32:04,  2.39it/s, Average Loss=2.44e-5, Epoch=9]\u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: [Epoch: 9, Macro F1: 0.6185641961110891, Validation Loss: 0.6698396470805333, Time per Epoch: 202.7252733707428]\n",
            "Begin Epoch 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Train:  50%|█████     | 4610/9200 [34:42<53:41,  1.42it/s, Average Loss=2.44e-5, Epoch=9]\u001b[A\n",
            "Train:  50%|█████     | 4610/9200 [34:42<53:41,  1.42it/s, Average Loss=3.82e-5, Epoch=10]\u001b[A\n",
            "Train:  50%|█████     | 4620/9200 [34:46<47:13,  1.62it/s, Average Loss=3.82e-5, Epoch=10]\u001b[A\n",
            "Train:  50%|█████     | 4620/9200 [34:47<47:13,  1.62it/s, Average Loss=4.68e-5, Epoch=10]\u001b[A\n",
            "Train:  50%|█████     | 4630/9200 [34:51<42:36,  1.79it/s, Average Loss=4.68e-5, Epoch=10]\u001b[A\n",
            "Train:  50%|█████     | 4630/9200 [34:51<42:36,  1.79it/s, Average Loss=0.0149, Epoch=10] \u001b[A\n",
            "Train:  50%|█████     | 4640/9200 [34:55<39:18,  1.93it/s, Average Loss=0.0149, Epoch=10]\u001b[A\n",
            "Train:  50%|█████     | 4640/9200 [34:55<39:18,  1.93it/s, Average Loss=0.0195, Epoch=10]\u001b[A\n",
            "Train:  51%|█████     | 4650/9200 [34:59<37:01,  2.05it/s, Average Loss=0.0195, Epoch=10]\u001b[A\n",
            "Train:  51%|█████     | 4650/9200 [34:59<37:01,  2.05it/s, Average Loss=0.00248, Epoch=10]\u001b[A\n",
            "Train:  51%|█████     | 4660/9200 [35:03<35:31,  2.13it/s, Average Loss=0.00248, Epoch=10]\u001b[A\n",
            "Train:  51%|█████     | 4660/9200 [35:03<35:31,  2.13it/s, Average Loss=0.00293, Epoch=10]\u001b[A\n",
            "Train:  51%|█████     | 4670/9200 [35:08<34:19,  2.20it/s, Average Loss=0.00293, Epoch=10]\u001b[A\n",
            "Train:  51%|█████     | 4670/9200 [35:08<34:19,  2.20it/s, Average Loss=0.0236, Epoch=10] \u001b[A\n",
            "Train:  51%|█████     | 4680/9200 [35:12<33:26,  2.25it/s, Average Loss=0.0236, Epoch=10]\u001b[A\n",
            "Train:  51%|█████     | 4680/9200 [35:12<33:26,  2.25it/s, Average Loss=0.00172, Epoch=10]\u001b[A\n",
            "Train:  51%|█████     | 4690/9200 [35:16<32:54,  2.28it/s, Average Loss=0.00172, Epoch=10]\u001b[A\n",
            "Train:  51%|█████     | 4690/9200 [35:16<32:54,  2.28it/s, Average Loss=2.12e-5, Epoch=10]\u001b[A\n",
            "Train:  51%|█████     | 4700/9200 [35:20<32:28,  2.31it/s, Average Loss=2.12e-5, Epoch=10]\u001b[A\n",
            "Train:  51%|█████     | 4700/9200 [35:20<32:28,  2.31it/s, Average Loss=0.0186, Epoch=10] \u001b[A\n",
            "Train:  51%|█████     | 4710/9200 [35:24<32:06,  2.33it/s, Average Loss=0.0186, Epoch=10]\u001b[A\n",
            "Train:  51%|█████     | 4710/9200 [35:24<32:06,  2.33it/s, Average Loss=1.63e-5, Epoch=10]\u001b[A\n",
            "Train:  51%|█████▏    | 4720/9200 [35:29<31:50,  2.35it/s, Average Loss=1.63e-5, Epoch=10]\u001b[A\n",
            "Train:  51%|█████▏    | 4720/9200 [35:29<31:50,  2.35it/s, Average Loss=4.08e-5, Epoch=10]\u001b[A\n",
            "Train:  51%|█████▏    | 4730/9200 [35:33<31:44,  2.35it/s, Average Loss=4.08e-5, Epoch=10]\u001b[A\n",
            "Train:  51%|█████▏    | 4730/9200 [35:33<31:44,  2.35it/s, Average Loss=1.69e-5, Epoch=10]\u001b[A\n",
            "Train:  52%|█████▏    | 4740/9200 [35:37<31:31,  2.36it/s, Average Loss=1.69e-5, Epoch=10]\u001b[A\n",
            "Train:  52%|█████▏    | 4740/9200 [35:37<31:31,  2.36it/s, Average Loss=1.63e-5, Epoch=10]\u001b[A\n",
            "Train:  52%|█████▏    | 4750/9200 [35:41<31:20,  2.37it/s, Average Loss=1.63e-5, Epoch=10]\u001b[A\n",
            "Train:  52%|█████▏    | 4750/9200 [35:41<31:20,  2.37it/s, Average Loss=0.00488, Epoch=10]\u001b[A\n",
            "Train:  52%|█████▏    | 4760/9200 [35:45<31:16,  2.37it/s, Average Loss=0.00488, Epoch=10]\u001b[A\n",
            "Train:  52%|█████▏    | 4760/9200 [35:45<31:16,  2.37it/s, Average Loss=0.000204, Epoch=10]\u001b[A\n",
            "Train:  52%|█████▏    | 4770/9200 [35:50<31:11,  2.37it/s, Average Loss=0.000204, Epoch=10]\u001b[A\n",
            "Train:  52%|█████▏    | 4770/9200 [35:50<31:11,  2.37it/s, Average Loss=2.23e-5, Epoch=10] \u001b[A\n",
            "Train:  52%|█████▏    | 4780/9200 [35:54<31:04,  2.37it/s, Average Loss=2.23e-5, Epoch=10]\u001b[A\n",
            "Train:  52%|█████▏    | 4780/9200 [35:54<31:04,  2.37it/s, Average Loss=1.41e-5, Epoch=10]\u001b[A\n",
            "Train:  52%|█████▏    | 4790/9200 [35:58<30:57,  2.37it/s, Average Loss=1.41e-5, Epoch=10]\u001b[A\n",
            "Train:  52%|█████▏    | 4790/9200 [35:58<30:57,  2.37it/s, Average Loss=1.67e-5, Epoch=10]\u001b[A\n",
            "Train:  52%|█████▏    | 4800/9200 [36:02<30:59,  2.37it/s, Average Loss=1.67e-5, Epoch=10]\u001b[A\n",
            "Train:  52%|█████▏    | 4800/9200 [36:02<30:59,  2.37it/s, Average Loss=1.22e-5, Epoch=10]\u001b[A\n",
            "Train:  52%|█████▏    | 4810/9200 [36:07<30:52,  2.37it/s, Average Loss=1.22e-5, Epoch=10]\u001b[A\n",
            "Train:  52%|█████▏    | 4810/9200 [36:07<30:52,  2.37it/s, Average Loss=0.00112, Epoch=10]\u001b[A\n",
            "Train:  52%|█████▏    | 4820/9200 [36:11<30:42,  2.38it/s, Average Loss=0.00112, Epoch=10]\u001b[A\n",
            "Train:  52%|█████▏    | 4820/9200 [36:11<30:42,  2.38it/s, Average Loss=0.0024, Epoch=10] \u001b[A\n",
            "Train:  52%|█████▎    | 4830/9200 [36:15<30:40,  2.37it/s, Average Loss=0.0024, Epoch=10]\u001b[A\n",
            "Train:  52%|█████▎    | 4830/9200 [36:15<30:40,  2.37it/s, Average Loss=0.00945, Epoch=10]\u001b[A\n",
            "Train:  53%|█████▎    | 4840/9200 [36:19<30:39,  2.37it/s, Average Loss=0.00945, Epoch=10]\u001b[A\n",
            "Train:  53%|█████▎    | 4840/9200 [36:19<30:39,  2.37it/s, Average Loss=1.56e-5, Epoch=10]\u001b[A\n",
            "Train:  53%|█████▎    | 4850/9200 [36:23<30:31,  2.37it/s, Average Loss=1.56e-5, Epoch=10]\u001b[A\n",
            "Train:  53%|█████▎    | 4850/9200 [36:23<30:31,  2.37it/s, Average Loss=1.95e-5, Epoch=10]\u001b[A\n",
            "Train:  53%|█████▎    | 4860/9200 [36:28<30:24,  2.38it/s, Average Loss=1.95e-5, Epoch=10]\u001b[A\n",
            "Train:  53%|█████▎    | 4860/9200 [36:28<30:24,  2.38it/s, Average Loss=2.91e-5, Epoch=10]\u001b[A\n",
            "Train:  53%|█████▎    | 4870/9200 [36:32<30:23,  2.37it/s, Average Loss=2.91e-5, Epoch=10]\u001b[A\n",
            "Train:  53%|█████▎    | 4870/9200 [36:32<30:23,  2.37it/s, Average Loss=0.00117, Epoch=10]\u001b[A\n",
            "Train:  53%|█████▎    | 4880/9200 [36:36<30:17,  2.38it/s, Average Loss=0.00117, Epoch=10]\u001b[A\n",
            "Train:  53%|█████▎    | 4880/9200 [36:36<30:17,  2.38it/s, Average Loss=3.5e-5, Epoch=10] \u001b[A\n",
            "Train:  53%|█████▎    | 4890/9200 [36:40<30:09,  2.38it/s, Average Loss=3.5e-5, Epoch=10]\u001b[A\n",
            "Train:  53%|█████▎    | 4890/9200 [36:40<30:09,  2.38it/s, Average Loss=0.00872, Epoch=10]\u001b[A\n",
            "Train:  53%|█████▎    | 4900/9200 [36:44<30:08,  2.38it/s, Average Loss=0.00872, Epoch=10]\u001b[A\n",
            "Train:  53%|█████▎    | 4900/9200 [36:44<30:08,  2.38it/s, Average Loss=0.0156, Epoch=10] \u001b[A\n",
            "Train:  53%|█████▎    | 4910/9200 [36:49<30:06,  2.38it/s, Average Loss=0.0156, Epoch=10]\u001b[A\n",
            "Train:  53%|█████▎    | 4910/9200 [36:49<30:06,  2.38it/s, Average Loss=0.000769, Epoch=10]\u001b[A\n",
            "Train:  53%|█████▎    | 4920/9200 [36:53<29:58,  2.38it/s, Average Loss=0.000769, Epoch=10]\u001b[A\n",
            "Train:  53%|█████▎    | 4920/9200 [36:53<29:58,  2.38it/s, Average Loss=0.00106, Epoch=10] \u001b[A\n",
            "Train:  54%|█████▎    | 4930/9200 [36:57<29:52,  2.38it/s, Average Loss=0.00106, Epoch=10]\u001b[A\n",
            "Train:  54%|█████▎    | 4930/9200 [36:57<29:52,  2.38it/s, Average Loss=0.0205, Epoch=10] \u001b[A\n",
            "Train:  54%|█████▎    | 4940/9200 [37:01<29:51,  2.38it/s, Average Loss=0.0205, Epoch=10]\u001b[A\n",
            "Train:  54%|█████▎    | 4940/9200 [37:01<29:51,  2.38it/s, Average Loss=2.4e-5, Epoch=10]\u001b[A\n",
            "Train:  54%|█████▍    | 4950/9200 [37:05<29:47,  2.38it/s, Average Loss=2.4e-5, Epoch=10]\u001b[A\n",
            "Train:  54%|█████▍    | 4950/9200 [37:05<29:47,  2.38it/s, Average Loss=2.77e-5, Epoch=10]\u001b[A\n",
            "Train:  54%|█████▍    | 4960/9200 [37:10<29:39,  2.38it/s, Average Loss=2.77e-5, Epoch=10]\u001b[A\n",
            "Train:  54%|█████▍    | 4960/9200 [37:10<29:39,  2.38it/s, Average Loss=9.99e-5, Epoch=10]\u001b[A\n",
            "Train:  54%|█████▍    | 4970/9200 [37:14<29:35,  2.38it/s, Average Loss=9.99e-5, Epoch=10]\u001b[A\n",
            "Train:  54%|█████▍    | 4970/9200 [37:14<29:35,  2.38it/s, Average Loss=5.66e-5, Epoch=10]\u001b[A\n",
            "Train:  54%|█████▍    | 4980/9200 [37:18<29:36,  2.38it/s, Average Loss=5.66e-5, Epoch=10]\u001b[A\n",
            "Train:  54%|█████▍    | 4980/9200 [37:18<29:36,  2.38it/s, Average Loss=0.000223, Epoch=10]\u001b[A\n",
            "Train:  54%|█████▍    | 4990/9200 [37:22<29:29,  2.38it/s, Average Loss=0.000223, Epoch=10]\u001b[A\n",
            "Train:  54%|█████▍    | 4990/9200 [37:22<29:29,  2.38it/s, Average Loss=0.00028, Epoch=10] \u001b[A\n",
            "Train:  54%|█████▍    | 5000/9200 [37:26<29:22,  2.38it/s, Average Loss=0.00028, Epoch=10]\u001b[A\n",
            "Train:  54%|█████▍    | 5000/9200 [37:26<29:22,  2.38it/s, Average Loss=9.19e-5, Epoch=10]\u001b[A\n",
            "Train:  54%|█████▍    | 5010/9200 [37:31<29:22,  2.38it/s, Average Loss=9.19e-5, Epoch=10]\u001b[A\n",
            "Train:  54%|█████▍    | 5010/9200 [37:31<29:22,  2.38it/s, Average Loss=4.65e-5, Epoch=10]\u001b[A\n",
            "Train:  55%|█████▍    | 5020/9200 [37:35<29:20,  2.37it/s, Average Loss=4.65e-5, Epoch=10]\u001b[A\n",
            "Train:  55%|█████▍    | 5020/9200 [37:35<29:20,  2.37it/s, Average Loss=0.00665, Epoch=10]\u001b[A\n",
            "Train:  55%|█████▍    | 5030/9200 [37:39<29:12,  2.38it/s, Average Loss=0.00665, Epoch=10]\u001b[A\n",
            "Train:  55%|█████▍    | 5030/9200 [37:39<29:12,  2.38it/s, Average Loss=0.033, Epoch=10]  \u001b[A\n",
            "Train:  55%|█████▍    | 5040/9200 [37:43<29:08,  2.38it/s, Average Loss=0.033, Epoch=10]\u001b[A\n",
            "Train:  55%|█████▍    | 5040/9200 [37:43<29:08,  2.38it/s, Average Loss=0.0359, Epoch=10]\u001b[A\n",
            "Train:  55%|█████▍    | 5050/9200 [37:47<29:10,  2.37it/s, Average Loss=0.0359, Epoch=10]\u001b[A\n",
            "Train:  55%|█████▍    | 5050/9200 [37:48<29:10,  2.37it/s, Average Loss=6.07e-5, Epoch=10]\u001b[A\n",
            "Train:  55%|█████▌    | 5060/9200 [37:52<28:56,  2.38it/s, Average Loss=6.07e-5, Epoch=10]\u001b[A\n",
            "Train:  55%|█████▌    | 5060/9200 [37:52<28:56,  2.38it/s, Average Loss=0.0391, Epoch=10] \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: [Epoch: 10, Macro F1: 0.625240941227094, Validation Loss: 0.6355267750142619, Time per Epoch: 203.33682990074158]\n",
            "Begin Epoch 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "Train:  55%|█████▌    | 5070/9200 [38:06<49:03,  1.40it/s, Average Loss=0.0391, Epoch=10]\u001b[A\n",
            "Train:  55%|█████▌    | 5070/9200 [38:06<49:03,  1.40it/s, Average Loss=0.000306, Epoch=11]\u001b[A\n",
            "Train:  55%|█████▌    | 5080/9200 [38:10<42:51,  1.60it/s, Average Loss=0.000306, Epoch=11]\u001b[A\n",
            "Train:  55%|█████▌    | 5080/9200 [38:10<42:51,  1.60it/s, Average Loss=0.00269, Epoch=11] \u001b[A\n",
            "Train:  55%|█████▌    | 5090/9200 [38:14<38:33,  1.78it/s, Average Loss=0.00269, Epoch=11]\u001b[A\n",
            "Train:  55%|█████▌    | 5090/9200 [38:14<38:33,  1.78it/s, Average Loss=0.000392, Epoch=11]\u001b[A\n",
            "Train:  55%|█████▌    | 5100/9200 [38:18<35:37,  1.92it/s, Average Loss=0.000392, Epoch=11]\u001b[A\n",
            "Train:  55%|█████▌    | 5100/9200 [38:18<35:37,  1.92it/s, Average Loss=3.46e-5, Epoch=11] \u001b[A\n",
            "Train:  56%|█████▌    | 5110/9200 [38:22<33:26,  2.04it/s, Average Loss=3.46e-5, Epoch=11]\u001b[A\n",
            "Train:  56%|█████▌    | 5110/9200 [38:22<33:26,  2.04it/s, Average Loss=0.00022, Epoch=11]\u001b[A\n",
            "Train:  56%|█████▌    | 5120/9200 [38:27<31:54,  2.13it/s, Average Loss=0.00022, Epoch=11]\u001b[A\n",
            "Train:  56%|█████▌    | 5120/9200 [38:27<31:54,  2.13it/s, Average Loss=7.24e-5, Epoch=11]\u001b[A\n",
            "Train:  56%|█████▌    | 5130/9200 [38:31<30:52,  2.20it/s, Average Loss=7.24e-5, Epoch=11]\u001b[A\n",
            "Train:  56%|█████▌    | 5130/9200 [38:31<30:52,  2.20it/s, Average Loss=0.014, Epoch=11]  \u001b[A\n",
            "Train:  56%|█████▌    | 5140/9200 [38:35<30:06,  2.25it/s, Average Loss=0.014, Epoch=11]\u001b[A\n",
            "Train:  56%|█████▌    | 5140/9200 [38:35<30:06,  2.25it/s, Average Loss=4.51e-5, Epoch=11]\u001b[A\n",
            "Train:  56%|█████▌    | 5150/9200 [38:39<29:31,  2.29it/s, Average Loss=4.51e-5, Epoch=11]\u001b[A\n",
            "Train:  56%|█████▌    | 5150/9200 [38:39<29:31,  2.29it/s, Average Loss=4.53e-5, Epoch=11]\u001b[A\n",
            "Train:  56%|█████▌    | 5160/9200 [38:43<29:07,  2.31it/s, Average Loss=4.53e-5, Epoch=11]\u001b[A\n",
            "Train:  56%|█████▌    | 5160/9200 [38:43<29:07,  2.31it/s, Average Loss=6.35e-5, Epoch=11]\u001b[A\n",
            "Train:  56%|█████▌    | 5170/9200 [38:48<28:53,  2.32it/s, Average Loss=6.35e-5, Epoch=11]\u001b[A\n",
            "Train:  56%|█████▌    | 5170/9200 [38:48<28:53,  2.32it/s, Average Loss=6.05e-5, Epoch=11]\u001b[A\n",
            "Train:  56%|█████▋    | 5180/9200 [38:52<28:36,  2.34it/s, Average Loss=6.05e-5, Epoch=11]\u001b[A\n",
            "Train:  56%|█████▋    | 5180/9200 [38:52<28:36,  2.34it/s, Average Loss=3.59e-5, Epoch=11]\u001b[A\n",
            "Train:  56%|█████▋    | 5190/9200 [38:56<28:22,  2.36it/s, Average Loss=3.59e-5, Epoch=11]\u001b[A\n",
            "Train:  56%|█████▋    | 5190/9200 [38:56<28:22,  2.36it/s, Average Loss=5.13e-5, Epoch=11]\u001b[A\n",
            "Train:  57%|█████▋    | 5200/9200 [39:00<28:16,  2.36it/s, Average Loss=5.13e-5, Epoch=11]\u001b[A\n",
            "Train:  57%|█████▋    | 5200/9200 [39:00<28:16,  2.36it/s, Average Loss=0.00131, Epoch=11]\u001b[A\n",
            "Train:  57%|█████▋    | 5210/9200 [39:05<28:10,  2.36it/s, Average Loss=0.00131, Epoch=11]\u001b[A\n",
            "Train:  57%|█████▋    | 5210/9200 [39:05<28:10,  2.36it/s, Average Loss=0.0193, Epoch=11] \u001b[A\n",
            "Train:  57%|█████▋    | 5220/9200 [39:09<28:00,  2.37it/s, Average Loss=0.0193, Epoch=11]\u001b[A\n",
            "Train:  57%|█████▋    | 5220/9200 [39:09<28:00,  2.37it/s, Average Loss=2.57e-5, Epoch=11]\u001b[A\n",
            "Train:  57%|█████▋    | 5230/9200 [39:13<27:52,  2.37it/s, Average Loss=2.57e-5, Epoch=11]\u001b[A\n",
            "Train:  57%|█████▋    | 5230/9200 [39:13<27:52,  2.37it/s, Average Loss=0.000271, Epoch=11]\u001b[A\n",
            "Train:  57%|█████▋    | 5240/9200 [39:17<27:53,  2.37it/s, Average Loss=0.000271, Epoch=11]\u001b[A\n",
            "Train:  57%|█████▋    | 5240/9200 [39:17<27:53,  2.37it/s, Average Loss=1.97e-5, Epoch=11] \u001b[A\n",
            "Train:  57%|█████▋    | 5250/9200 [39:21<27:47,  2.37it/s, Average Loss=1.97e-5, Epoch=11]\u001b[A\n",
            "Train:  57%|█████▋    | 5250/9200 [39:21<27:47,  2.37it/s, Average Loss=0.00972, Epoch=11]\u001b[A\n",
            "Train:  57%|█████▋    | 5260/9200 [39:26<27:40,  2.37it/s, Average Loss=0.00972, Epoch=11]\u001b[A\n",
            "Train:  57%|█████▋    | 5260/9200 [39:26<27:40,  2.37it/s, Average Loss=0.0219, Epoch=11] \u001b[A\n",
            "Train:  57%|█████▋    | 5270/9200 [39:30<27:37,  2.37it/s, Average Loss=0.0219, Epoch=11]\u001b[A\n",
            "Train:  57%|█████▋    | 5270/9200 [39:30<27:37,  2.37it/s, Average Loss=0.000948, Epoch=11]\u001b[A\n",
            "Train:  57%|█████▋    | 5280/9200 [39:34<27:35,  2.37it/s, Average Loss=0.000948, Epoch=11]\u001b[A\n",
            "Train:  57%|█████▋    | 5280/9200 [39:34<27:35,  2.37it/s, Average Loss=3.02e-5, Epoch=11] \u001b[A\n",
            "Train:  57%|█████▊    | 5290/9200 [39:38<27:28,  2.37it/s, Average Loss=3.02e-5, Epoch=11]\u001b[A\n",
            "Train:  57%|█████▊    | 5290/9200 [39:38<27:28,  2.37it/s, Average Loss=0.00014, Epoch=11]\u001b[A\n",
            "Train:  58%|█████▊    | 5300/9200 [39:42<27:21,  2.38it/s, Average Loss=0.00014, Epoch=11]\u001b[A\n",
            "Train:  58%|█████▊    | 5300/9200 [39:42<27:21,  2.38it/s, Average Loss=2.14e-5, Epoch=11]\u001b[A\n",
            "Train:  58%|█████▊    | 5310/9200 [39:47<27:21,  2.37it/s, Average Loss=2.14e-5, Epoch=11]\u001b[A\n",
            "Train:  58%|█████▊    | 5310/9200 [39:47<27:21,  2.37it/s, Average Loss=0.000457, Epoch=11]\u001b[A\n",
            "Train:  58%|█████▊    | 5320/9200 [39:51<27:17,  2.37it/s, Average Loss=0.000457, Epoch=11]\u001b[A\n",
            "Train:  58%|█████▊    | 5320/9200 [39:51<27:17,  2.37it/s, Average Loss=0.000108, Epoch=11]\u001b[A\n",
            "Train:  58%|█████▊    | 5330/9200 [39:55<27:10,  2.37it/s, Average Loss=0.000108, Epoch=11]\u001b[A\n",
            "Train:  58%|█████▊    | 5330/9200 [39:55<27:10,  2.37it/s, Average Loss=0.00372, Epoch=11] \u001b[A\n",
            "Train:  58%|█████▊    | 5340/9200 [39:59<27:07,  2.37it/s, Average Loss=0.00372, Epoch=11]\u001b[A\n",
            "Train:  58%|█████▊    | 5340/9200 [39:59<27:07,  2.37it/s, Average Loss=0.0216, Epoch=11] \u001b[A\n",
            "Train:  58%|█████▊    | 5350/9200 [40:04<27:05,  2.37it/s, Average Loss=0.0216, Epoch=11]\u001b[A\n",
            "Train:  58%|█████▊    | 5350/9200 [40:04<27:05,  2.37it/s, Average Loss=0.000211, Epoch=11]\u001b[A\n",
            "Train:  58%|█████▊    | 5360/9200 [40:08<26:58,  2.37it/s, Average Loss=0.000211, Epoch=11]\u001b[A\n",
            "Train:  58%|█████▊    | 5360/9200 [40:08<26:58,  2.37it/s, Average Loss=0.00322, Epoch=11] \u001b[A\n",
            "Train:  58%|█████▊    | 5370/9200 [40:12<26:51,  2.38it/s, Average Loss=0.00322, Epoch=11]\u001b[A\n",
            "Train:  58%|█████▊    | 5370/9200 [40:12<26:51,  2.38it/s, Average Loss=0.025, Epoch=11]  \u001b[A\n",
            "Train:  58%|█████▊    | 5380/9200 [40:16<26:50,  2.37it/s, Average Loss=0.025, Epoch=11]\u001b[A\n",
            "Train:  58%|█████▊    | 5380/9200 [40:16<26:50,  2.37it/s, Average Loss=0.017, Epoch=11]\u001b[A\n",
            "Train:  59%|█████▊    | 5390/9200 [40:20<26:47,  2.37it/s, Average Loss=0.017, Epoch=11]\u001b[A\n",
            "Train:  59%|█████▊    | 5390/9200 [40:20<26:47,  2.37it/s, Average Loss=7.73e-5, Epoch=11]\u001b[A\n",
            "Train:  59%|█████▊    | 5400/9200 [40:25<26:39,  2.38it/s, Average Loss=7.73e-5, Epoch=11]\u001b[A\n",
            "Train:  59%|█████▊    | 5400/9200 [40:25<26:39,  2.38it/s, Average Loss=0.000534, Epoch=11]\u001b[A\n",
            "Train:  59%|█████▉    | 5410/9200 [40:29<26:36,  2.37it/s, Average Loss=0.000534, Epoch=11]\u001b[A\n",
            "Train:  59%|█████▉    | 5410/9200 [40:29<26:36,  2.37it/s, Average Loss=0.000581, Epoch=11]\u001b[A\n",
            "Train:  59%|█████▉    | 5420/9200 [40:33<26:34,  2.37it/s, Average Loss=0.000581, Epoch=11]\u001b[A\n",
            "Train:  59%|█████▉    | 5420/9200 [40:33<26:34,  2.37it/s, Average Loss=3.41e-5, Epoch=11] \u001b[A\n",
            "Train:  59%|█████▉    | 5430/9200 [40:37<26:28,  2.37it/s, Average Loss=3.41e-5, Epoch=11]\u001b[A\n",
            "Train:  59%|█████▉    | 5430/9200 [40:37<26:28,  2.37it/s, Average Loss=0.000153, Epoch=11]\u001b[A\n",
            "Train:  59%|█████▉    | 5440/9200 [40:41<26:21,  2.38it/s, Average Loss=0.000153, Epoch=11]\u001b[A\n",
            "Train:  59%|█████▉    | 5440/9200 [40:41<26:21,  2.38it/s, Average Loss=6.47e-5, Epoch=11] \u001b[A\n",
            "Train:  59%|█████▉    | 5450/9200 [40:46<26:20,  2.37it/s, Average Loss=6.47e-5, Epoch=11]\u001b[A\n",
            "Train:  59%|█████▉    | 5450/9200 [40:46<26:20,  2.37it/s, Average Loss=0.00564, Epoch=11]\u001b[A\n",
            "Train:  59%|█████▉    | 5460/9200 [40:50<26:16,  2.37it/s, Average Loss=0.00564, Epoch=11]\u001b[A\n",
            "Train:  59%|█████▉    | 5460/9200 [40:50<26:16,  2.37it/s, Average Loss=0.0027, Epoch=11] \u001b[A\n",
            "Train:  59%|█████▉    | 5470/9200 [40:54<26:09,  2.38it/s, Average Loss=0.0027, Epoch=11]\u001b[A\n",
            "Train:  59%|█████▉    | 5470/9200 [40:54<26:09,  2.38it/s, Average Loss=0.0338, Epoch=11]\u001b[A\n",
            "Train:  60%|█████▉    | 5480/9200 [40:58<26:05,  2.38it/s, Average Loss=0.0338, Epoch=11]\u001b[A\n",
            "Train:  60%|█████▉    | 5480/9200 [40:58<26:05,  2.38it/s, Average Loss=0.0242, Epoch=11]\u001b[A\n",
            "Train:  60%|█████▉    | 5490/9200 [41:03<26:06,  2.37it/s, Average Loss=0.0242, Epoch=11]\u001b[A\n",
            "Train:  60%|█████▉    | 5490/9200 [41:03<26:06,  2.37it/s, Average Loss=0.0462, Epoch=11]\u001b[A\n",
            "Train:  60%|█████▉    | 5500/9200 [41:07<25:57,  2.38it/s, Average Loss=0.0462, Epoch=11]\u001b[A\n",
            "Train:  60%|█████▉    | 5500/9200 [41:07<25:57,  2.38it/s, Average Loss=0.0068, Epoch=11]\u001b[A\n",
            "Train:  60%|█████▉    | 5510/9200 [41:11<25:51,  2.38it/s, Average Loss=0.0068, Epoch=11]\u001b[A\n",
            "Train:  60%|█████▉    | 5510/9200 [41:11<25:51,  2.38it/s, Average Loss=0.000417, Epoch=11]\u001b[A\n",
            "Train:  60%|██████    | 5520/9200 [41:15<25:40,  2.39it/s, Average Loss=0.000417, Epoch=11]\u001b[A\n",
            "Train:  60%|██████    | 5520/9200 [41:15<25:40,  2.39it/s, Average Loss=0.00298, Epoch=11] \u001b[A"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Validation: [Epoch: 11, Macro F1: 0.653722134969624, Validation Loss: 0.4572947931321619, Time per Epoch: 203.09367775917053]\n",
            "Training stopped early at Epoch: 11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.load_state_dict(torch.load(f\"best_model.ckpt\"))\n",
        "model.cuda()\n",
        "print(\"Done\")"
      ],
      "metadata": {
        "id": "hzB2Rn4-GXSS",
        "outputId": "3887dc34-9ac0-432a-f5de-c03d1c48da2e",
        "execution": {
          "iopub.status.busy": "2023-06-12T05:19:39.535586Z",
          "iopub.status.idle": "2023-06-12T05:19:39.536182Z",
          "shell.execute_reply.started": "2023-06-12T05:19:39.535932Z",
          "shell.execute_reply": "2023-06-12T05:19:39.535959Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(model, validation_loader)"
      ],
      "metadata": {
        "id": "9U5FrKYZGZnZ",
        "outputId": "9bb9f877-8bca-41c5-d9bf-19a3c90c74cc",
        "execution": {
          "iopub.status.busy": "2023-06-12T05:19:39.538171Z",
          "iopub.status.idle": "2023-06-12T05:19:39.538634Z",
          "shell.execute_reply.started": "2023-06-12T05:19:39.538401Z",
          "shell.execute_reply": "2023-06-12T05:19:39.538423Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.9297337278106509,\n",
              " 'precision': 0.928907935764243,\n",
              " 'recall': 0.9297337278106509,\n",
              " 'f1': 0.9292593516550545,\n",
              " 'macro_precision': 0.7125410920245927,\n",
              " 'macro_recall': 0.7099205851245003,\n",
              " 'macro_f1': 0.7108489893506181}"
            ]
          },
          "metadata": {},
          "execution_count": 87
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(len(epoch_traces)), acc_traces)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Macro F1-Score')\n",
        "plt.title('Epoch vs Validation Macro F1-Score')\n",
        "plt.xticks(range(len(epoch_traces)), epoch_traces)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "zE3UzWNHGcnM",
        "outputId": "caf70d57-8d4d-47ae-8834-e0291ee60dfa",
        "execution": {
          "iopub.status.busy": "2023-06-12T05:19:39.540226Z",
          "iopub.status.idle": "2023-06-12T05:19:39.540707Z",
          "shell.execute_reply.started": "2023-06-12T05:19:39.540473Z",
          "shell.execute_reply": "2023-06-12T05:19:39.540497Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(range(len(epoch_traces)), validation_loss_traces)\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.title('Epoch vs Validation Loss')\n",
        "plt.xticks(range(len(epoch_traces)), epoch_traces)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "y1y6enP6GewI",
        "outputId": "515deb59-8652-44ca-b052-3b8d3a449e74",
        "execution": {
          "iopub.status.busy": "2023-06-12T05:19:39.541937Z",
          "iopub.status.idle": "2023-06-12T05:19:39.542938Z",
          "shell.execute_reply.started": "2023-06-12T05:19:39.542673Z",
          "shell.execute_reply": "2023-06-12T05:19:39.542700Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(model, test_loader)"
      ],
      "metadata": {
        "id": "q9Aw8Z2vGgyh",
        "outputId": "5be97333-35ac-4302-f910-b4f9f6c6dd27",
        "execution": {
          "iopub.status.busy": "2023-06-12T05:19:39.546187Z",
          "iopub.status.idle": "2023-06-12T05:19:39.546646Z",
          "shell.execute_reply.started": "2023-06-12T05:19:39.546414Z",
          "shell.execute_reply": "2023-06-12T05:19:39.546435Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.9297337278106509,\n",
              " 'precision': 0.9233808139798733,\n",
              " 'recall': 0.9297337278106509,\n",
              " 'f1': 0.9258521187617258,\n",
              " 'macro_precision': 0.6960233614909873,\n",
              " 'macro_recall': 0.6257318537905813,\n",
              " 'macro_f1': 0.6564493437375565}"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(model, test_loader_latin)"
      ],
      "metadata": {
        "id": "dNMicbCTGi7_",
        "outputId": "9d6917ae-a9f8-43fb-b4bf-2f529194ca3b",
        "execution": {
          "iopub.status.busy": "2023-06-12T05:19:39.548230Z",
          "iopub.status.idle": "2023-06-12T05:19:39.548692Z",
          "shell.execute_reply.started": "2023-06-12T05:19:39.548458Z",
          "shell.execute_reply": "2023-06-12T05:19:39.548479Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.9366420274551215,\n",
              " 'precision': 0.9351758032132486,\n",
              " 'recall': 0.9366420274551215,\n",
              " 'f1': 0.9349979657106733,\n",
              " 'macro_precision': 0.6450478568456096,\n",
              " 'macro_recall': 0.6234194097616345,\n",
              " 'macro_f1': 0.6270256310701203}"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(model, test_loader_Sinhala)"
      ],
      "metadata": {
        "id": "C0_4LABCGk91",
        "outputId": "32541b84-71bf-47bf-e292-515d6484e77a",
        "execution": {
          "iopub.status.busy": "2023-06-12T05:19:39.550060Z",
          "iopub.status.idle": "2023-06-12T05:19:39.550917Z",
          "shell.execute_reply.started": "2023-06-12T05:19:39.550657Z",
          "shell.execute_reply": "2023-06-12T05:19:39.550679Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.8844221105527639,\n",
              " 'precision': 0.8469553650605971,\n",
              " 'recall': 0.8844221105527639,\n",
              " 'f1': 0.8650950730756661,\n",
              " 'macro_precision': 0.5539215686274509,\n",
              " 'macro_recall': 0.5622902834297138,\n",
              " 'macro_f1': 0.5577993321672762}"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(model, test_loader_Mixed)"
      ],
      "metadata": {
        "id": "5xfCBwDKGm9M",
        "outputId": "92f070e6-8457-492f-b603-9ae71f54a73a",
        "execution": {
          "iopub.status.busy": "2023-06-12T05:19:39.552385Z",
          "iopub.status.idle": "2023-06-12T05:19:39.552852Z",
          "shell.execute_reply.started": "2023-06-12T05:19:39.552603Z",
          "shell.execute_reply": "2023-06-12T05:19:39.552624Z"
        },
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 93,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.941747572815534,\n",
              " 'precision': 0.9404361307375592,\n",
              " 'recall': 0.941747572815534,\n",
              " 'f1': 0.9364354221829948,\n",
              " 'macro_precision': 0.8842931937172774,\n",
              " 'macro_recall': 0.6908212560386473,\n",
              " 'macro_f1': 0.75789898989899}"
            ]
          },
          "metadata": {},
          "execution_count": 93
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FZjKnNRK_dDo"
      },
      "execution_count": 93,
      "outputs": []
    }
  ]
}